{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIy3kWEbCsy0",
    "outputId": "74451d9f-fc8b-4807-905c-e4d59fe0f26a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 17 09:34:55 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nwld9WGza6p_",
    "outputId": "38085566-f897-4916-b570-2a6f2d337608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simpletransformers\n",
      "  Downloading simpletransformers-0.63.6-py3-none-any.whl (249 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |█▎                              | 10 kB 28.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 20 kB 24.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 30 kB 18.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 40 kB 15.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 51 kB 7.5 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 61 kB 8.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 71 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 81 kB 8.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 92 kB 9.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 102 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 112 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 122 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 133 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 143 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 153 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 163 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 174 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 184 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 194 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 204 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 215 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 225 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 235 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 245 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 249 kB 8.1 MB/s \n",
      "\u001b[?25hCollecting streamlit\n",
      "  Downloading streamlit-1.8.1-py2.py3-none-any.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 59.2 MB/s \n",
      "\u001b[?25hCollecting tokenizers\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 49.7 MB/s \n",
      "\u001b[?25hCollecting transformers>=4.6.0\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 64.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.3.5)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 62.6 MB/s \n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
      "\u001b[K     |████████████████████████████████| 325 kB 74.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (4.64.0)\n",
      "Collecting wandb>=0.10.32\n",
      "  Downloading wandb-0.12.14-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 52.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.0.2)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2.8.0)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.21.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2.23.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 60.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 8.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (3.6.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (4.11.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 72.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers>=4.6.0->simpletransformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.6.0->simpletransformers) (3.0.8)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 69.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (3.17.3)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (1.15.0)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.5.10-py2.py3-none-any.whl (144 kB)\n",
      "\u001b[K     |████████████████████████████████| 144 kB 75.6 MB/s \n",
      "\u001b[?25hCollecting setproctitle\n",
      "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (7.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (2.8.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (5.4.8)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (2.3)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (3.0.4)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
      "\u001b[K     |████████████████████████████████| 136 kB 51.6 MB/s \n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 55.8 MB/s \n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[K     |████████████████████████████████| 212 kB 75.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (0.3.4)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (0.70.12.2)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (6.0.1)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 59.5 MB/s \n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[K     |████████████████████████████████| 144 kB 52.3 MB/s \n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 3.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers) (21.4.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 72.1 MB/s \n",
      "\u001b[?25hCollecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers) (2.0.12)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.6.0->simpletransformers) (3.8.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->simpletransformers) (2022.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.6.0->simpletransformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->simpletransformers) (3.1.0)\n",
      "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (1.5.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (7.1.2)\n",
      "Collecting validators\n",
      "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
      "Collecting pympler>=0.9\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "\u001b[K     |████████████████████████████████| 164 kB 58.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (4.2.4)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (5.1.1)\n",
      "Collecting blinker\n",
      "  Downloading blinker-1.4.tar.gz (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 75.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (4.2.0)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 45.4 MB/s \n",
      "\u001b[?25hCollecting watchdog\n",
      "  Downloading watchdog-2.1.7-py3-none-manylinux2014_x86_64.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 6.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (2.13.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (4.3.3)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (2.11.3)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.11.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (5.7.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (7.7.0)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (5.1.1)\n",
      "Collecting ipykernel>=5.1.2\n",
      "  Downloading ipykernel-6.13.0-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 75.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.0.0)\n",
      "Collecting jupyter-client>=6.1.12\n",
      "  Downloading jupyter_client-7.2.2-py3-none-any.whl (130 kB)\n",
      "\u001b[K     |████████████████████████████████| 130 kB 66.6 MB/s \n",
      "\u001b[?25hCollecting tornado>=5.0\n",
      "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
      "\u001b[K     |████████████████████████████████| 428 kB 71.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.5.5)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.1.3)\n",
      "Collecting ipython>=7.23.1\n",
      "  Downloading ipython-7.32.0-py3-none-any.whl (793 kB)\n",
      "\u001b[K     |████████████████████████████████| 793 kB 28.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (57.4.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.6.1)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Downloading prompt_toolkit-3.0.29-py3-none-any.whl (381 kB)\n",
      "\u001b[K     |████████████████████████████████| 381 kB 57.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.8.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.4.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.1.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.6.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.3.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit->simpletransformers) (2.0.1)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.9.2)\n",
      "Requirement already satisfied: pyzmq>=22.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (22.3.0)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.15.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.3.1)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.6.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.13.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.0.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.5.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (0.37.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.44.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.35.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (3.2.0)\n",
      "Building wheels for collected packages: pathtools, seqeval, blinker\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=9cd059742f3be89f68d3580253d4c30c4311c077f68ed46d8bdf352007a4571a\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=1371a5190b7fc0dd277b3822ca9a8d1aa9eae41078503bbaa4606dbc3a089908\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
      "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13478 sha256=19374cd74da640aa40a13fe45365a3dda0758cd8401b6db881c62fa1ffcfb696\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n",
      "Successfully built pathtools seqeval blinker\n",
      "Installing collected packages: tornado, prompt-toolkit, jupyter-client, ipython, ipykernel, urllib3, multidict, frozenlist, yarl, smmap, asynctest, async-timeout, aiosignal, pyyaml, gitdb, fsspec, aiohttp, xxhash, watchdog, validators, toml, tokenizers, shortuuid, setproctitle, sentry-sdk, sacremoses, responses, pympler, pydeck, pathtools, huggingface-hub, GitPython, docker-pycreds, blinker, wandb, transformers, streamlit, seqeval, sentencepiece, datasets, simpletransformers\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 5.1.1\n",
      "    Uninstalling tornado-5.1.1:\n",
      "      Successfully uninstalled tornado-5.1.1\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 1.0.18\n",
      "    Uninstalling prompt-toolkit-1.0.18:\n",
      "      Successfully uninstalled prompt-toolkit-1.0.18\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 5.3.5\n",
      "    Uninstalling jupyter-client-5.3.5:\n",
      "      Successfully uninstalled jupyter-client-5.3.5\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 5.5.0\n",
      "    Uninstalling ipython-5.5.0:\n",
      "      Successfully uninstalled ipython-5.5.0\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 4.10.1\n",
      "    Uninstalling ipykernel-4.10.1:\n",
      "      Successfully uninstalled ipykernel-4.10.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
      "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.13.0 which is incompatible.\n",
      "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed GitPython-3.1.27 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 blinker-1.4 datasets-2.1.0 docker-pycreds-0.4.0 frozenlist-1.3.0 fsspec-2022.3.0 gitdb-4.0.9 huggingface-hub-0.5.1 ipykernel-6.13.0 ipython-7.32.0 jupyter-client-7.2.2 multidict-6.0.2 pathtools-0.1.2 prompt-toolkit-3.0.29 pydeck-0.7.1 pympler-1.0.1 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.49 sentencepiece-0.1.96 sentry-sdk-1.5.10 seqeval-1.2.2 setproctitle-1.2.3 shortuuid-1.0.8 simpletransformers-0.63.6 smmap-5.0.0 streamlit-1.8.1 tokenizers-0.12.1 toml-0.10.2 tornado-6.1 transformers-4.18.0 urllib3-1.25.11 validators-0.18.2 wandb-0.12.14 watchdog-2.1.7 xxhash-3.0.0 yarl-1.7.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "IPython",
         "ipykernel",
         "jupyter_client",
         "prompt_toolkit",
         "tornado"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mA44ke2evlE"
   },
   "source": [
    "# Set Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RuyTiiTk6oHd",
    "outputId": "90a2d339-5c30-4e44-c390-971b03a7686b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_CKKQJrm7HSt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_training = pd.read_csv('/content/drive/MyDrive/Wysdom/public_data_grammarfixed.csv', encoding='unicode_escape')\n",
    "df_test = pd.read_csv('/content/drive/MyDrive/Wysdom/input_data_grammarfixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "Cw8kCUuM7due",
    "outputId": "cbe31fbf-1bb2-4213-be7a-7de09f74641e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d815a9ee-3ca2-467b-9e5a-18ddd11de963\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>kmeans_cluster</th>\n",
       "      <th>intent</th>\n",
       "      <th>message_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8793</td>\n",
       "      <td>hi i want change my address from my credit card</td>\n",
       "      <td>updateaddress</td>\n",
       "      <td>14</td>\n",
       "      <td>to change my address</td>\n",
       "      <td>Hi, I want to change my address from my credit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3083</td>\n",
       "      <td>i need 4 fruit maple oatmeal 3 cold brew froze...</td>\n",
       "      <td>orderdrinkintent</td>\n",
       "      <td>20</td>\n",
       "      <td>to eat breakfast</td>\n",
       "      <td>I need 4 fruit maple oatmeal 3 cold brew froze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5932</td>\n",
       "      <td>i wish to travel next month domestic airway</td>\n",
       "      <td>bookflight</td>\n",
       "      <td>13</td>\n",
       "      <td>to travel</td>\n",
       "      <td>I wish to travel next month domestic airway.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12077</td>\n",
       "      <td>i need reimbursement my expenses</td>\n",
       "      <td>expensereport</td>\n",
       "      <td>20</td>\n",
       "      <td>to be reimbursed</td>\n",
       "      <td>I need reimbursement for my expenses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6608</td>\n",
       "      <td>i need a copy of insurance for my car</td>\n",
       "      <td>getproofofinsurance</td>\n",
       "      <td>2</td>\n",
       "      <td>to be able to drive my car</td>\n",
       "      <td>I need a copy of insurance for my car.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d815a9ee-3ca2-467b-9e5a-18ddd11de963')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d815a9ee-3ca2-467b-9e5a-18ddd11de963 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d815a9ee-3ca2-467b-9e5a-18ddd11de963');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1     id  \\\n",
       "0           0             0   8793   \n",
       "1           1             1   3083   \n",
       "2           2             2   5932   \n",
       "3           3             3  12077   \n",
       "4           4             4   6608   \n",
       "\n",
       "                                             message                label  \\\n",
       "0    hi i want change my address from my credit card        updateaddress   \n",
       "1  i need 4 fruit maple oatmeal 3 cold brew froze...     orderdrinkintent   \n",
       "2        i wish to travel next month domestic airway           bookflight   \n",
       "3                   i need reimbursement my expenses        expensereport   \n",
       "4              i need a copy of insurance for my car  getproofofinsurance   \n",
       "\n",
       "   kmeans_cluster                      intent  \\\n",
       "0              14        to change my address   \n",
       "1              20            to eat breakfast   \n",
       "2              13                   to travel   \n",
       "3              20            to be reimbursed   \n",
       "4               2  to be able to drive my car   \n",
       "\n",
       "                                       message_clean  \n",
       "0  Hi, I want to change my address from my credit...  \n",
       "1  I need 4 fruit maple oatmeal 3 cold brew froze...  \n",
       "2       I wish to travel next month domestic airway.  \n",
       "3              I need reimbursement for my expenses.  \n",
       "4             I need a copy of insurance for my car.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-sRFZhQk8Bf8"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "encoded_labels = labelEncoder.fit_transform(df_training['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qsCxnloq9AHz",
    "outputId": "f9550fd2-7c51-4838-b930-36968848738e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9902bade-644b-46da-adfe-b20cc2740e02\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, I want to change my address from my credit...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I need 4 fruit maple oatmeal 3 cold brew froze...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wish to travel next month domestic airway.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I need reimbursement for my expenses.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I need a copy of insurance for my car.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9902bade-644b-46da-adfe-b20cc2740e02')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9902bade-644b-46da-adfe-b20cc2740e02 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9902bade-644b-46da-adfe-b20cc2740e02');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  Hi, I want to change my address from my credit...      34\n",
       "1  I need 4 fruit maple oatmeal 3 cold brew froze...      20\n",
       "2       I wish to travel next month domestic airway.       0\n",
       "3              I need reimbursement for my expenses.       9\n",
       "4             I need a copy of insurance for my car.      13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([df_training['message_clean'].rename('text'), pd.Series(encoded_labels, name='labels')], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VC3sNHumhmUk",
    "outputId": "de6a434f-a23a-4f20-d6d9-8fff1ac353a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labels = len(X.labels.value_counts())\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzqKDDRJe120"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bh2YgJ4p_aCe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val = train_test_split(X, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "referenced_widgets": [
      "fed0fe2c7dac46cba18efc9fe6a01d9f",
      "e1edd457f88b49c0b24a0e468af6bd25",
      "59136e423c044deab4a2443a849d8961",
      "6ba8cfab4eed4c7b9b8bba015aaee792",
      "f17f902cc7744efe9c28d1a4ef42b6c7",
      "ca7a73fbb5564181a1be79b44b790bcd",
      "20c72a8e7b2e48faa10b12af78055cc5",
      "9cb9c99ad64e42fe93de7382afae7d61",
      "96d61960ca22402a9bbba87ed4d9845c",
      "ca7118b1697d48c18c2c5a3308ff870c",
      "f2f0c7d453084230be093e1ac92f0f60",
      "eea46bbc9b364c97a1d000f27b670fe7",
      "aea1fbab33274ab8b79fcffac46d09ed",
      "c421f72d38f34df3ae12f0aab6afda07",
      "05b4632dece941fd93d497925114054b",
      "2fccc3ae651b465488d5f47cb4511287",
      "9c9f1c7c5fe7424882f2937528419e16",
      "2bbf85a31ecc47b39e6ca85be663d742",
      "e086665bfdc94132911d7fcc49f1511b",
      "5cbee9d90cce42149273401aeff4b38c",
      "608fbf19108a41ac885eacab829e6bc2",
      "8d2e8f24fce54029bb621759f4ad335e",
      "962c97cf2f09453d9e884a835962234f",
      "d2bd4b66e6fc4d4e9d063d8ae1159143",
      "cc29560af5934dea89dc0536a4d53faf",
      "6f0d84981efb4a0b957eeadc4ea9fae7",
      "554105eab9384ce4864a8e07bd0439e8",
      "71b6f4a6e6eb4ff4a24acf3646a492b5",
      "9e0a430cf6de4654873b15484022981a",
      "0dc37b3ba19f49fdbcd28ccc883f302a",
      "70d4f093a46b47efbc795c196760bf5c",
      "696163ff2cd94386aaaa1138fb24cd53",
      "8ebcc12aa17541d59f2a360c19fb0704",
      "6fd46cec1cb04875824b38d46599d51a",
      "1a6dc9640805437a9bef0c5d35fcddfe",
      "0286864f9a3c43d2bbae62d1e78c8f24",
      "8c9d9ae0d1f1412f89198ea612fde722",
      "8297b306e78b4693b1b723c3ee3e9531",
      "509c139585b5438dbcf1cd4f179abfdb",
      "8952ea48c17a49d38a82b677f953df3d",
      "d2c1c0e8ccf44f43b6edb344e9587624",
      "2c5e2e0922684969a3879a61c5466d3b",
      "af995d58ddea418da34001e5ec8b35fc",
      "28e4c889614746fe9a5bf0c221caaa13",
      "6be3927c236c4fc58bbc72b870831972",
      "231d3a6222154839aa550c1fd41b63a5",
      "d049207bda9b475895dfa761b03c3b56",
      "d2219dca87644658922f5e52c8af3199",
      "60616f7442954839bb2c1ba58d77f672",
      "a1fbbfea2bac4779956c8325cf88013d",
      "fc66a41c884744a49b912b53b237a815",
      "dce7531f71cc49cb882dca6e198522c6",
      "62109684c96c473eac50f204c85199aa",
      "4371c12d069d4e77bf9f6157e495a953",
      "3395928c442e45d78255139fd2327e1a"
     ]
    },
    "id": "6PZPsWRogRx_",
    "outputId": "215cd56a-6a29-4b42-ca06-07371710f0f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed0fe2c7dac46cba18efc9fe6a01d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea46bbc9b364c97a1d000f27b670fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962c97cf2f09453d9e884a835962234f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd46cec1cb04875824b38d46599d51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be3927c236c4fc58bbc72b870831972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "model_args = ClassificationArgs(num_train_epochs=7, train_batch_size=39, manual_seed=42, use_early_stopping=True, early_stopping_metric=\"mcc\",\n",
    "                                early_stopping_delta=0.003, early_stopping_metric_minimize=False, early_stopping_patience=5, evaluate_during_training_steps=1000,\n",
    "                                reprocess_input_data=True, overwrite_output_dir=True)\n",
    "\n",
    "model = ClassificationModel('roberta', 'roberta-base', use_cuda=True, num_labels=n_labels, args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379,
     "referenced_widgets": [
      "c605ebd3c1c24001a2a5bd6b0fe6b94b",
      "abdd1949b6084f9f95008a97bc4a7bc7",
      "db4a49d0a3734c26a100a7f5853aa29a",
      "826b92d0867d470790ea9d379431f240",
      "2bb758dec4604eafa1d81d252734229b",
      "8d96ceccc09944549bccfbd0bb7fd16c",
      "5b0d3ce5242a4c868c4bc88e696e8bfd",
      "019033f3aea64846b722f64fe183a370",
      "a39bca35110249f5885bc8b9570a0514",
      "5db173b7d7e54d6689903911800cfdb9",
      "8487e278a690479f898f1316b3895a89",
      "63c845c43e864afda879e83c39381191",
      "203baa4b24564a21889cb28585f6b9ee",
      "d63bef28595942d2b8ea06ae14763d4b",
      "5983dcf9f0a646b5a88b0383df165f6b",
      "a972ff1a8b0346f0a97b99c666122ed4",
      "c840eb68e6a746d08909d3fe47593af1",
      "29efc4e2848d45b89127098e7fffc0de",
      "4511d37085e14e1db6982eb049451d8f",
      "eec02ea31d16492c8cb77daec944e1cf",
      "b39114aae721447eb07ad7d9199d3ab1",
      "b6cfd99e5a054faeb28d87e6a3dba8df",
      "f8898812316a43efae897a5545535b2b",
      "77f5b2666b274d85bf4cdab8ad86a75c",
      "49b0ba6685aa4ffcb99ff732016090a7",
      "139b716f9fe943adb045755d85c4f09c",
      "7f5749fc787640d18090db7fc5bd3874",
      "ee848571b3624d19ae6ab14791233e75",
      "3ebe9834effd43db8b0c769886802228",
      "58b96bb6a265497e9c283ff87a14a833",
      "fb5468f680a64c4e9b3394722122980f",
      "90d19775328c49e1a416868c67f1c6cf",
      "d4b4ee2dd4ff4b3fb6b84f54a942aa79",
      "b58b67ac453d4db9b262f3be6d504f8b",
      "ba419d5af6d1495eb788aedbab09e854",
      "0e1adb46b023465f9c884805ab3cf0b0",
      "85cd84642dd24c099a5b5109f2eab1e7",
      "e855691689fd4e0b9806138df467664a",
      "1b6b833ce15648e695b7995db215f31c",
      "46f298e6727d4cb083a395ec7a6511ff",
      "16e5bae1a7a94db589d6ab382d9cf99d",
      "4e1813e8b363445888e95116a68193e8",
      "2ab8801496864683bb781cdc4df035d9",
      "ea5344394e124d94a868ade83249a5e1",
      "15c98b4b6db147f18e3fb3f8784a0d90",
      "8ada9c22e93e4caf953aa93ab226dc9b",
      "2dc8fda5522143588c8016fcdeefb574",
      "d268ae57eb614bdca736b92f22524dd2",
      "784f250c365846d79d240ee5cd243975",
      "306da5cd5eab47a7b8ef51bd71550a60",
      "e5117402ea49438494fd11bce4f013d0",
      "c648aa4ff66344b988f567f3612348f1",
      "f771f23fefd045c99bfd1c1155ae00b3",
      "9f370d0eaada44dc863b25bc1967a3ae",
      "71c8e88e58ff4298936a3d4d70002912",
      "ec71b2de0d234792bcc25abc43923892",
      "3fc158aec7d74f27b412b14e548b496a",
      "20c6952f1e704a61a9bf0cecf21cec62",
      "bcd46941bc2749a7953a5393f25a1b75",
      "1e8224ab88d647d0817717a92d8e7e29",
      "7f899b73dcc04882bc71f0770f06016c",
      "c5aa0c06b34c4f5d8aa1f0711d87fbe5",
      "50bf8c02afb94328a5879d4763b02747",
      "b2507bd0a69541958c13f0783597b4c4",
      "84b004004fc0495fbfc6af6ec4e1916c",
      "70bbc92f80a54406926ff350304ecf3c",
      "7a22d40c1b76496db6f8cac41f0d28aa",
      "3a28fc98a700477294dd4af2bcf18044",
      "6a00019bea6e419582f01a23951d2729",
      "0fa40c5b90f8485ca07260e9a3e167ab",
      "ffa6a26f4d944d8b96531eeef70d1504",
      "25cae9694044439496a774e4287493a1",
      "3d58924373ba4652b0317ad99dde7e3d",
      "b5e5d1e9f691428aaf2438f11f6dc6dd",
      "a10bae41ddb54143823365b01709451c",
      "8f8d31c1d4914722a2f9815b5803d440",
      "a5f9cd6f5d4247ed86da9aed9621c5d5",
      "0e7583cc1eaa400ebf0a1db043e1c15b",
      "aab02cceb71e416dac9c9a45572e438f",
      "144bfa25aca3440eac4397aec4c4e368",
      "2cebb2d3a24c42dbaffc43d81a6f5ab4",
      "2b1b0a55511a45b4a5bd4a4c6e00cdce",
      "abba8ddc062a4878a42703443e87b354",
      "1444d6f5b40343ebb4aa8bc3e2de3a73",
      "32a7b0eb8aeb4648958d1d0851c13418",
      "e1bf6faab2e341b8aab93c052f14460a",
      "00dbb7b589554b3aaeed89ae45cc2ee2",
      "d306427b0c9144859803fdd622b8a328",
      "d7ab4c5da3e04c59938d88de15f39ed9",
      "9bbf296d7f394929af1596c1116a0022",
      "cb59f2137a75436599da7fb4e1b014f2",
      "6ef057db0a0a4678a5d57fb162d5aac3",
      "d421bf9f5ce544b1a33bea908faba75d",
      "f15d96cd24d943ef82d6ce38eeed536d",
      "30606d901c034cfca23ecdd5e303a3d3",
      "55b2fdfce6d6425b85c64c5d3d0e3088",
      "11621b65683b439fac9ad91adccd4489",
      "d0d2d11904f34512a27e43d2bc187908",
      "9004aecee7114dd2888d7e2d9b8012ae"
     ]
    },
    "id": "CiMNjDJpgbAM",
    "outputId": "88d0fc66-aa6a-4c68-db8e-145302be65c9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c605ebd3c1c24001a2a5bd6b0fe6b94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c845c43e864afda879e83c39381191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8898812316a43efae897a5545535b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 7:   0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58b67ac453d4db9b262f3be6d504f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 7:   0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c98b4b6db147f18e3fb3f8784a0d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 7:   0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec71b2de0d234792bcc25abc43923892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 7:   0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a22d40c1b76496db6f8cac41f0d28aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 7:   0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7583cc1eaa400ebf0a1db043e1c15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 7:   0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ab4c5da3e04c59938d88de15f39ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 7:   0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1673, 0.2772071542052994)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(X_train)\n",
    "# model.train_model(X) # train with all data for production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNSfZtUk3vLi"
   },
   "source": [
    "# Evaluate model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "d8e13d6b436245b29d5cf01e2f2593a8",
      "201cc5e902c048be84cf0f142232f8fb",
      "4ec7d8dbbdff45019d8afcb17931cf3d",
      "a1740994621a45cc9c7bc115c1cfa3f0",
      "a8f3d646ec2f43a4923af6eda4be71ab",
      "c946390620224b2faa1a06dc8127c87a",
      "ac21771bdc6a49018620286a38eecab9",
      "7370486767174f6e9f6c76a5f7740b80",
      "3549d292ece748b1813f36302dbd2fa4",
      "16fe024d6f7e413cbe80000464f9039b",
      "5f69913e8d204d12b9f781d647778e47",
      "3701c37bac7c473e96d2e325010cd5d9",
      "e8225d707eb641d9ae16dbf47504e023",
      "27349be8f36d4e8ea23179b28cd9289b",
      "9503ca8ce74e4775965215a0f39f9f65",
      "9cc26a1bf4d64b06af60ce45dcb53636",
      "81714a268b8748c2af25ca60b223efbe",
      "325e0415cbad468eb0dc6095b5f2be71",
      "edf38b1615834bb7a653c8db07c2da2b",
      "77d95f6dcc0e49839bf9341ab3ca6b25",
      "1181725a203e4821ab4cd3da622dfb49",
      "1b5b781aeb174395a983ac3e0e4c5ba6"
     ]
    },
    "id": "m5MIk_SWj99F",
    "outputId": "9525d521-f4eb-424b-ecbb-b7c44ec99a86"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e13d6b436245b29d5cf01e2f2593a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3701c37bac7c473e96d2e325010cd5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "result, model_outputs, wrong_predictions = model.eval_model(X_val, ami=adjusted_mutual_info_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hkor8tYr3MuJ",
    "outputId": "f357c392-8622-4a89-c73a-bc2065460d0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ami': 0.9490728075005874,\n",
       " 'eval_loss': 0.18532876583309107,\n",
       " 'mcc': 0.9634311060930795}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZsDoduu0bki"
   },
   "source": [
    "# What did the model get wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mlrmUI_0bEK"
   },
   "outputs": [],
   "source": [
    "incorrect_predictions = []\n",
    "\n",
    "for prediction in wrong_predictions:\n",
    "  incorrect_predictions.append(prediction.label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uL4LZwhT4PW1"
   },
   "outputs": [],
   "source": [
    "incorrect_predictions_decoded = pd.Series(labelEncoder.inverse_transform(incorrect_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Y8eI5kf4k04"
   },
   "outputs": [],
   "source": [
    "incorrect_labels_counts = pd.Series(incorrect_predictions_decoded).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "id": "ph3RqPiL4uOr",
    "outputId": "ef2061ee-40ba-49c1-cf9a-97f27b7a9c66"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,3,2])\n",
    "labels = list(incorrect_labels_counts.index)\n",
    "count = incorrect_labels_counts.values\n",
    "ax.bar(labels, count, color='#68228B')\n",
    "ax.set_ylabel('Number of Incorrect Predictions', fontdict={'fontsize': 20})\n",
    "ax.set_xlabel('Labels', fontdict={'fontsize': 20})\n",
    "plt.xticks(rotation='vertical', fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.savefig(\"incorrect_val_preds_best.png\", dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJ_ry9R2Lmun"
   },
   "source": [
    "# Confusion Matrix with Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbG7y5PPSH-7"
   },
   "outputs": [],
   "source": [
    "# get predicted labels from model_outputs\n",
    "y_val = []\n",
    "\n",
    "for output in model_outputs:\n",
    "  y_val.append(output.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pskwpxdYS21B"
   },
   "outputs": [],
   "source": [
    "y_val_decoded = labelEncoder.inverse_transform(y_val)\n",
    "y_val_real = labelEncoder.inverse_transform(X_val['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79xzzLQILl22",
    "outputId": "2d6e5cb7-07e6-4fc0-dc0a-74bf1862236c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[329   0   0 ...   0   0   0]\n",
      " [  0 194   0 ...   0   0   0]\n",
      " [  0   0 189 ...   0   0   0]\n",
      " ...\n",
      " [  4   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   2   0]\n",
      " [  0   0   0 ...   0   0   3]]\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "           bookflight       1.00      1.00      1.00        42\n",
      "          changeorder       1.00      0.80      0.89         5\n",
      " changeseatassignment       0.91      0.91      0.91        57\n",
      "         checkbalance       1.00      1.00      1.00        50\n",
      "     checkclaimstatus       0.97      1.00      0.98        90\n",
      "checkoffereligibility       1.00      1.00      1.00         6\n",
      "    checkserverstatus       1.00      0.97      0.98        30\n",
      "         closeaccount       0.95      0.90      0.92        20\n",
      "        disputecharge       0.95      1.00      0.98        42\n",
      "        expensereport       0.96      0.96      0.96        77\n",
      "      getboardingpass       1.00      1.00      1.00       114\n",
      " getinformationintent       0.94      0.94      0.94        32\n",
      "        getpromotions       1.00      1.00      1.00         3\n",
      "  getproofofinsurance       1.00      0.98      0.99       192\n",
      "     getroutingnumber       1.00      1.00      1.00        14\n",
      "          getseatinfo       0.97      0.98      0.98       183\n",
      " orderbreakfastintent       1.00      0.50      0.67         6\n",
      "    orderburgerintent       0.98      0.85      0.91        60\n",
      "          orderchecks       1.00      0.88      0.93         8\n",
      "   orderdessertintent       0.92      0.97      0.94        59\n",
      "     orderdrinkintent       0.94      0.95      0.94       151\n",
      "     orderpizzaintent       0.94      0.97      0.95       201\n",
      "     ordersaladintent       0.85      1.00      0.92        52\n",
      "      ordersideintent       0.94      0.71      0.81        24\n",
      "       providereceipt       0.50      1.00      0.67         1\n",
      "          replacecard       0.86      0.80      0.83        15\n",
      "    reportbrokenphone       1.00      1.00      1.00        69\n",
      " reportbrokensoftware       0.99      0.99      0.99        69\n",
      "       reportlostcard       0.97      0.97      0.97        73\n",
      "       softwareupdate       0.96      0.98      0.97        55\n",
      "           startorder       0.96      0.90      0.93        58\n",
      "   startserviceintent       0.98      1.00      0.99       330\n",
      "            stoporder       1.00      0.67      0.80         3\n",
      "        transfermoney       0.98      1.00      0.99        43\n",
      "        updateaddress       0.99      1.00      0.99        69\n",
      " upgradeserviceintent       0.00      0.00      0.00         5\n",
      "      viewbillsintent       1.00      1.00      1.00        17\n",
      "\n",
      "             accuracy                           0.97      2325\n",
      "            macro avg       0.93      0.91      0.91      2325\n",
      "         weighted avg       0.97      0.97      0.96      2325\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Compare validation predictions with actual y_val\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "classes = list(df_training['label'].value_counts().index)\n",
    "\n",
    "cf_matrix = confusion_matrix(y_val_real, y_val_decoded, labels=classes)\n",
    "print(cf_matrix)\n",
    "print(classification_report(y_val_real, y_val_decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RzQQ7fw0T71I",
    "outputId": "fcd7cfd2-79a8-407a-f297-4489b5db62bb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate heat map\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,16))\n",
    "sns.heatmap(cf_matrix, annot=False, cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "ax.set_ylabel('Actual Text Classification', fontdict={'fontsize': 18})\n",
    "ax.set_xlabel('Predicted Text Classification', fontdict={'fontsize': 18})\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.savefig(\"cfmatrix_best.png\", dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KIFr_uwrM3I"
   },
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_Q3r-RYZUd5"
   },
   "source": [
    "### Bayes Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QjozZiGrPCa"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "sweep_config = {\n",
    "    \"name\": \"roberta-base batch32\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"adjusted_mutual_info_score\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"num_train_epochs\": {\"min\": 3, \"max\": 8},\n",
    "        \"learning_rate\": {\"min\": 0.0, \"max\": 9e-4},\n",
    "    },\n",
    "    \"early_terminate\": {\"type\": \"hyperband\", \"min_iter\": 6,},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qhHKfi-oZru8",
    "outputId": "1cdd5ece-ccb9-4b9b-f4f6-6d17cda27fc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500 response executing GraphQL.\n",
      "{\"errors\":[{\"message\":\"Error 1040: Too many connections\",\"path\":[\"upsertSweep\"]}],\"data\":{\"upsertSweep\":null}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: Error 1040: Too many connections (<Response [500]>)\n",
      "500 response executing GraphQL.\n",
      "{\"error\":\"Error 1040: Too many connections\"}\n",
      "500 response executing GraphQL.\n",
      "{\"error\":\"Error 1040: Too many connections\"}\n",
      "Retry attempt failed:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/lib/retry.py\", line 102, in __call__\n",
      "    result = self._call_fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/internal/internal_api.py\", line 147, in execute\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/internal/internal_api.py\", line 141, in execute\n",
      "    return self.client.execute(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 52, in execute\n",
      "    result = self._get_result(document, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 60, in _get_result\n",
      "    return self.transport.execute(document, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/wandb/vendor/gql-0.2.0/wandb_gql/transport/requests.py\", line 39, in execute\n",
      "    request.raise_for_status()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/requests/models.py\", line 941, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/graphql\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (HTTPError), entering retry loop.\n",
      "500 response executing GraphQL.\n",
      "{\"error\":\"Error 1040: Too many connections\"}\n",
      "500 response executing GraphQL.\n",
      "{\"error\":\"Error 1040: Too many connections\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: mrohyjpe\n",
      "Sweep URL: https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"roberta-base no-batch tuning\")\n",
    "\n",
    "tuning_model_args = ClassificationArgs(train_batch_size=32, manual_seed=42, \n",
    "                                       reprocess_input_data=True, overwrite_output_dir=True, wandb_project=\"roberta-base no-batch tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8b85fea186c94f06a51ee6de3fffe439",
      "76aa10aee61c44919b545cb076ad07f2",
      "e96791af3cca419f840648e606a2de61",
      "72dee2fcd6d841849b6068f577324108",
      "23624b19ae7e4fd28cd019df2b590849",
      "1ae295385a674371b25c7361e3d5a38d",
      "30990205917e4bc8a9e4701ea5234ee0",
      "403611bcb3704b9ea531317adf23d8f7",
      "eadfb113aee9457ead06dd00e418c082",
      "2587d2f5a4f748bbaa982712bc859e24",
      "b47c6552af9b4922bda8448378fd7a02",
      "969d2fcee63b4ae08106f771924be9d3",
      "ab064865a5ab4f95a4249cc58ee57b20",
      "3ff8c9d88e75406f9b22cc36700ce1ff",
      "c56851a7f58a4b9aa0daa70a5f9444d4",
      "5de008f066c3410d81e49b1d6c9e3a39",
      "ef04c21789ec488492417a591c0e3186",
      "aeab414613724c56a4b8c2059b67f850",
      "a01eb5d98c534499b373f3b6ce4c5af7",
      "6a430bca4be8415e9b4a1514d1190a69",
      "eb5fb57849bc42f08b688d577416379d",
      "27ec419dbe36475b805f8710b0476082",
      "2deac93e3e464469a6d028b476e77eff",
      "23962cab84414c07b5e7ebcc370a0b75",
      "1b93b43abf2648f6be1c703cedd64496",
      "fdb4b71461574b5491d088f575bcf9e3",
      "bf5061401fcc43dea40b1824c33644a3",
      "cc84e88d0f0245b6ab536f65f14b51ec",
      "c1aad07341c94b8e9bc6c4f45e45cddf",
      "f937a93c8c8a4986b4ac7fb082de8b6d",
      "5662235d91ce45ceb7ebd5920921b2c9",
      "3b20ba5556594c96ad61636e5cc23d0a",
      "77041298bda84e64afa0d610f88c7b49",
      "7bb52c4b90fb4d7ea956ee7ac5e1bb83",
      "83c74b423a7d4a04875611cc7425cca6",
      "b34795c6603c4358b923217070966ad0",
      "0be8ac8432e9451da44fa9cd8e9e8ec6",
      "6c1fdd495b81455499924a74588651e7",
      "56a2e630a6e447eca5188aa1330ec2b6",
      "cd4ac4ebf0494670a01c2996ad0c7abc",
      "d1beb63108bb4d04842e29970ec55bb8",
      "3fcae46c4d984001876adf306387655e",
      "b9d6f0994d464ba188bcbf07b8d1c1cb",
      "7fd52f2b9ab8409e81deb05659027f3e",
      "3bc9c9854d1e4e7d9bd04c9fa7a2d202",
      "fb0565e092d1441fbf4c628375d11b99",
      "af7dafb25e82465ab6550ac18188ad74",
      "95e7df53085a4bada26f8bcddccd90cd",
      "e0c9b231d193411d8a0b094332db8951",
      "e2b24aa1d0af433b941a60f3e050d0e3",
      "dce83ed7179d49e98d9ff55f3fa500b9",
      "1203aec965da400e96d2757fb337c435",
      "040f8aef22cc4914adfdb1cb25818b2b",
      "128fcce8a5654ec48f8d33acf64326c3",
      "8a5c02d14da44773bb2840d5b553f7cc",
      "ce02e377cbc6498d92f7b0e5004f3793",
      "12db7b9738e04b2aaa3ec02281113fa7",
      "700c2a7e96b94422ba1a221a82e71eb8",
      "a3eea35309d748dbabb6780ee29a2c27",
      "675b2f86a8174e8fb86ed9aac923856f",
      "ef4a4d0c20714c8db1b321c7a3c7524e",
      "e8ddead8ffd14bcb8e355cf63301bec0",
      "ffaccc2ba6e748c587fbe7bb8ec5056c",
      "78eddb9f7d974b2489094c57a1b46bbc",
      "eae3b506607044c6a0419d89cfb5cf6d",
      "8d978ee712f6431b817d4aa59ed55631",
      "45e3234e433c46c9a6f6359fd40d9e9a",
      "9e04c4a3116248b2831af723200b3c73",
      "3b53f5c572d245a2b4880a2a43bcefb7",
      "27f0bc66815049ff87fe5ffeb1177267",
      "37e148b532124721a700d37f210b2b14",
      "3fff37a8766442e394147903686900b7",
      "4d3ac0682b594ce694f77f9474911e10",
      "ac9725fe7e0b40ea97e96cdb18da57e8",
      "ddca72d27155416a8343afd9e3de7578",
      "89b61bfcd9e749a5aaac2dde10d58ebd",
      "665a0b056b41478ba5cbcec40d73594c",
      "250fe1dbf6f34692bc6e9e82a410ab84",
      "f7b401d436b34093afe57555d3a9f95f",
      "6f2dd443c1ab4f5d82a2822f1bc028b6",
      "a643e1429b3c4abca4a8334a025a40be",
      "8e4a214393414d8889bcade766246d6e",
      "55b1580533ed44cb8adaaf2112d699c7",
      "a863dab8c97f47ed8718ecc780464205",
      "977e7899b36744b280945020639346d3",
      "1b992b169914472c94ec9f04fa7ec75c",
      "ee6c46c06efb469db630f57fca01fcba",
      "f22f9484345040b9a50466763a2b5726",
      "8c01c55c2bbe41eeb067ff67239c744f",
      "0395ec7a947346d7b5b149bfe56adb7e",
      "ab10ce3c26b04f828fcf6193fc4944ef",
      "90614b809c36490a9083ed38248a1db3",
      "e190f1645aea498d9a97cbcb9386738c",
      "5e80ec9798d94ddeaa4d88d69fe8df38",
      "2275dd8d723c4e83b3ab18f12b152d08",
      "ea83509f113647eda3e8e3f600f0c67e",
      "772c23ccb4434f13870ab19fe6dcd1df",
      "f1e133712b654224a34aced2cc35f3aa",
      "57fcce7348f9412bb6ca531ba950b523",
      "16765a1297744a3baa55e50d57c370fa",
      "94c62a73c16443dfacccf1f7cdabcbd1",
      "162951ef7d0942009dc93d7d81c99d07",
      "caea9d6fa46d4c55a6f2b1947755c940",
      "4ee64a25fb384e13a1fbe7916208f942",
      "f393f807460a4b60a130fa58210098d6",
      "9c32c7751eb841ac8fd9b9c780c4dee6",
      "f6d89a92c6e248b589fd971c8bdcf091",
      "e7dc61f3c72441ab8587a50fca0a64d4",
      "3af316be06514497ae3e0ed5d109d1f6",
      "93ddacecae6f401f80827fa45998c2d2",
      "93577101e3a54c1881b237d9e6a39738",
      "4f9953089f214fcda1fbcc75955ad807",
      "d266dcd4e3ca488d9a5cc2778b04b53b",
      "77f8440174294a4b9cf208048e6cfcf2",
      "9792cdb70b7b455fb299236aa3ee8852",
      "4c485061fdb840e89bbe290a27ab08c1",
      "f78ad669fb25451ba2996e8d245c5663",
      "7667fcf30e9c4a8a80cba82dadf166e7",
      "7791f5be2e3641db8e795aa055401b66",
      "91aad30460344e6aa831f8b40228e777",
      "df8e8df60619448ebcdb496926a89be2",
      "cbb37c4c26164598a70828b87bb89197",
      "b06ed394fe294aa5a52d35b0e0865c73",
      "df55c0a391fd4c1bb9f6d637ffef51d8",
      "e87a3aeb16014cccb25f54fc2c8cd4bd",
      "40ab93e7f2b84ad5ab0d7ae7025420ce",
      "108e45a673a94387b6e217624c12b7f5",
      "fa2720ccc95d42b68e4e1dbccaae8fc4",
      "056ed3b1df74401ba6d90efaad524866",
      "21a09c0c1dfa4045ba56e45eef2bc9f1",
      "d164056880844434b0882c140d07ceae",
      "50da61f27cdb4acba43be4dc101dfaec",
      "149d3cfb550049148d63185bc2783c52",
      "56f02fa56aa8426eb0187d4574eddf68",
      "0dc37a51d4684f4392d08e9f7baf4a56",
      "54f4739453d24b258a40202673e92957",
      "20c0d8ee78714f8a9e46ee6de3469e52",
      "4cd06af021ec4280a4c76de8a624c002",
      "a8aba4d403d1485588666b932838d361",
      "5aec5d9112cc48b2bd90c4261978b75c",
      "487c48dd5ddc4aa68bb937d784d45cb9",
      "8741ecf06d6b4f2485e003e3b7fea779",
      "0e586e41eb8743aa9956664c06261c26",
      "92914d15f8e94ead9c51d7bbdb8a4fdc",
      "09e50db65e8b43a0951c723f946a2dd3",
      "14ce8661d3d244f39480bd06b552870c",
      "6e46638133084e32abf2d34b75c5d14f",
      "053b73639b2b438d95202f6def0dfee7",
      "f074ee59a52c451c858a6fdb4717a826",
      "ebe1461894f146d4bca4d6fc25af9d1a",
      "a68a384bb6584077b8d28fa61f6d3958",
      "678fbfc8fd7a4770a54552c2a74c0d35",
      "18a4eb5d509d422f9e78615a597030b5",
      "4bcfb992b322499b8185bcbe6b460280",
      "e8820f354938404abef13b55cfaf48f0",
      "f13105cf73c544338b072b67b91f9907",
      "f96fb7c50f864cc39e7d5c7f90a37125",
      "99ca1352deb2497eac36fc911a443c9a",
      "edfaae53265a48ab8548ecf432a327aa",
      "5b118d2e49ce43a0aaadd2865f992d5d",
      "499c656ca7804a6a8e835625a263b2af",
      "3baae600a99c49e88b3c0e402928393b",
      "594f48d71a82424187ad68712def3d71",
      "c17b958ca7794b7d93a06b68e987a15a",
      "ca9e4379854344fbb0d9f08fd7241aa1",
      "2cca8788c47b448e9d7a23e0f486a56e",
      "a390f2b64ca84e41aa42edb279b00d56",
      "6c6ad74844e14dbbb6f76a9c0c6fbd28",
      "f50b1c5e709d473a8b496429239978af",
      "2f76f33c239d49d197a1de8c1acdceb3",
      "099d47fe492844a582e2b85dc1b9b9ca",
      "b2a8f0aba47c40169fa474d8e1b8be7e",
      "2dd9dbf1aa734c838a6aaaf33a17dc77",
      "6fa9c666d1394636941642e12304ceed",
      "03e434133b2d4a1cb8798f82a5b040f1",
      "a31da41814f0487fb74c0d37f3a4471a",
      "12bf3d4f814142ba9053b7db5ecb7e67",
      "f4aaf7c16a274de5b2dd3dc804715cea",
      "9b00a1ca8a054abfbde675d34a51d268",
      "4f636ebb37be4762a5df241b8cff1ffd",
      "51e0a514fc9144c99caf4e2ff4f86e8c",
      "dec4fa25e81c44e1805d82bb990a105f",
      "a12aa0fda3c04ad384ef1ef09d6d8e0a",
      "f308dc43aa664fc8b9359d49846d5d90",
      "73b254187b214878a4c6567a29d56ff3",
      "e8b5bd2d18674010b9631ddae60888e1",
      "0437823142254527a4d1f16f19c2a1fd",
      "ec1b9cd085724357a9a346f71e7bf033",
      "fd346c32fc1d4cb594de0437340526be",
      "356bc3a9757f4bf988878b8f093a740a",
      "050265b654014020a3f910a898ce1067",
      "fd57495d7ec74adcaccddc5695446464",
      "48d04c5b819f4f0dab7aed32720bfb6f",
      "df365d06d53e438f81a63177e9ce42d5",
      "3821b4eb9cb5403984d902e485897e7f",
      "89c2d5ff61c54bb2b1b34ff1c4ee9bd0",
      "60574c2b92674eaabf2dc612e6c8cd0c",
      "551417e51c4f4d85b37cbc68a2cf4dae",
      "0584966646fd470a8ef0fbd8b97bebf3",
      "4e0b23bdacce463dae6fe6df104e6889",
      "6fabdca1112f4d63ab670556c66f8d7b",
      "37ab0b88cb13417887a9c2489a7dbbcf",
      "4a2ecc95f5254ee0be6d5b648c2ee1f6",
      "87db7aee902c47d6904d1374cdac1ec8",
      "d5da191f59e54caa82206570f2b31498",
      "99848abe304040fa9e4f739410551fb7",
      "2961a92b17bf4d9e972c08f3bad8187a",
      "009da53b2116414d8cee1caa35186088",
      "1199703dd95047a482ad289b59460bf5",
      "60356e6f9cea408b9e156fe02452278d",
      "2eb8756b9f004051a767b28f0d4f5a42",
      "0ffeb0d7c01d4eabb241bff7539b92d4",
      "6dc726265ba74522b4d904eadbb1694f",
      "af38da71b7c94d59b5e32356093e92be",
      "19cd508950c94963895c19a964976de9",
      "b8a481720fec44b58f859f52584da141",
      "54bdafbd70dc4210af1e6253e7a6691c",
      "63a1f4e3e58849ce9ba45d416b4f5836",
      "ef43f5dc92aa450abd04e892cde45136",
      "24493ad6b8124ef6a2f691ef8e0a0845",
      "e261b2c8e5214ad094449ef66140037a",
      "3749b3f4b7e247cd9de21656bcb11f10",
      "dcac79ba449c464cbd42eae772118eb9",
      "46c8aa1dacaf406387a3e57ccddc3473",
      "7cb29228186d4c1bb91f5b19ccd80655",
      "02744dd088c7411eb1ba87bdc762da19",
      "a968050019d044eabcb8cc8a17b7abff",
      "de0a3ad6d5314f9f86819225ac9317b8",
      "2c92b235438144849dd4224374147521",
      "6dbe32b0adbb407c9849cc1cf36ba15c",
      "71bce61993fe4463b471861b0127596d",
      "2706f625812847acadc069d04e4b31a4",
      "6735211c815e4e07b345189cc1305066",
      "901f672c24834a589d330024c138823c",
      "0c0eac958664432e86d37c25aa2c93f2",
      "2b8477ba5e224293ae1fd0a30fd85120",
      "8b18e432234f493d82aef1c552883c1c",
      "d830edafc9414e999731010accf58ed8",
      "57404e4dc1b049958ceea5e3344b0f3a",
      "9df939c79d664839af6bf274a690c652",
      "c69a82c82bbb4311b6d94c2e1723c345",
      "a7b8f788964445b5a905e7563682d94f",
      "3a1e17d9cb6e44e7ad8dbd6425a1c52b",
      "27dded6813e949e385ba9c790146d687",
      "fd0a40d6d844464389304c3ee77c03c9",
      "48a7a70e87f14b72a215ff190cf048ec",
      "da759a4402db46fea55d62062ef0311f",
      "17d0f1a00e844bf689066609e919d4bd",
      "936c8822077b41ce9e3aa317d6360d0d",
      "e2cc77a9db004f66869a424e9e6084c9",
      "4b96d7f290e6456394233d0f035bf3e6",
      "223be2fa9875471695ad34b3a42c97da",
      "559099314d2d45ec987d36cc1b7beca2",
      "a74e867701164fad9c3be66e085f2a94",
      "e7c8420f88134a61bde048b2aba475ed",
      "246bd5b8c06c428fb414839ef9e74d09",
      "c69cd769b03847beb0417ee2c1647160",
      "15051deb3c8f4180b1037b1204036350",
      "c8da338cfea44cb289d5fb2795de1d70",
      "38aa5d5a248749a9a97289d9317781be",
      "7f053a84e1164ae094e8005d538fd4a0",
      "644f99adf9874abab8ea929bb3ac2503",
      "451b143189af42f395bc2040f6cca89d",
      "89e1229b687f40cfac6eb74526939da0",
      "4a197a9d6a694bbb933d894ea6492640",
      "2fa97f2cbd7445af91f21c459e60f1e1",
      "ac953f06825e4bacb893cabe126b5865",
      "db9f099efb284abea453841c0373ac8d",
      "68ce251749f54e43b9a169d12c616561",
      "97a42bf4db324758a1cc4d08208f3f5b",
      "52538fbaed824fc498225f3d175085a0",
      "ff8466d0a81b4204b7b8cfe3f5969a12",
      "c6d45458f3a940b3a9606cf331a7cc52",
      "dd744680afaf46e38ed6a791ecd8e98f",
      "6e29c0cb77fc45539640228e246cd63d",
      "84320502ecf74b978129ee35f1987ddd",
      "702cd72a6c1d4c96b30e5e5ffa0a678a",
      "f65444cd3af94295b285df6e79a90a5d",
      "34c9688c6f4242aeaa500bb4f5ea1351",
      "61881eb372a14406930c39d0bd17da34",
      "171e314db6b6453bb258be49f6ece9d6",
      "c105d0344b514d7d9d0373e8b198a1b3",
      "ca814d0979c9474094ef6f68ded90c62",
      "b5441b2eea104554bf10737e1d0425b6",
      "1af15d1c8c4a4b7c97079cc7831d463d",
      "53a969de8dd74b4a8d70c9c24bc73bc9",
      "709278275b9341d69341dc09effaf50a",
      "4fcab70bad8f4fcb8381558b36aec3a6",
      "c2f06b37402c4bfcb7f132e9b2f249cc",
      "a5e618f0709d44689fd2ae9296319922",
      "e73fe232bfbd40b6b0095b4ed96fe693",
      "1a56c7fd4d0f4a31a59bbc0fc0139168",
      "8c7566007e004a98889ab24ede7a6072",
      "e5ca392b56fc4881be2d119f67f6de57",
      "3e374635c32145789cf551643dafe46d",
      "593a15a240244c9aa8326ac6cc753a7b",
      "1c5b9974b1654a40a7e9902d40521518",
      "9bcce30842a246ac9e0b01f4f10f33a8",
      "a0df09b77d424c55a95ca8787fbec8b1",
      "d7092e7bcf0740f1aee47dbdb814a782",
      "dcd6b50283104d189fc5cf4b2b42ce57",
      "3d32eaa705c54d0fbd889e419b359728",
      "d24bb8a2ad2545e7a943bab3a2f00119",
      "4957bbbb828c418581363f627f9ad444",
      "750c21b153f744d790303ecadca23a25",
      "58f625a9215946c48beb8e33f427eff0",
      "29b13f33ecbd4e7487220617329bde0a",
      "da69cb06699f4b119c1330e85ea15391",
      "1485f5efa37549eab09163c1cd614035",
      "6f703d96a85b4b0c8ce1fa4440069349",
      "4adc99f4d68545e1a4d484d40cdc2bfa",
      "6f8888a29bdd4569aab436f22c74a8eb",
      "b95f9ed0d0d24e8c918d45b7432f48f4",
      "b48613ef438f47acb79b8e62b5082edf",
      "9d99a0f18ac2434ab77e1c744e7cd5ad",
      "dacf528b80ee4f0c9e4df0964f2cf0eb",
      "32aa658e8f0c42348a3266fcf6dbc5c3",
      "ae4d2ed3215c472e97ba4aff5f552965",
      "b360472408a94628924610756977c7ac",
      "46abb922ac12406696a4040e6ce290e9",
      "ef71c273d0ee4a96b1697eb06ccdab20",
      "e80572c8d9924a66899f4950a2071fcd",
      "94fb1d7447cd4ea1b57fce0350a2a5aa",
      "f019cac72d334e819f9422b7c0d15908",
      "5d18829e56cb4cbcad9d79322ea372b5",
      "15f5703d08e44cf6bf7499123bc1bbb6",
      "15338592544a448cb33ad22286691613",
      "e29b17373c0a4d84a7648b38bf3a4863",
      "44505df2239b44aeb00a2c822ef581d4",
      "ba05d83e0cdc4559bf760cf11b442798",
      "fdaad1620bfb4162b9f7204b7a58e5f3",
      "4a5c07b5b22c44569d65170b22fc9a03",
      "e16f83d004324999a4a2881e801ee7cd",
      "0c9f6b002846415d947467d1055cb2e2",
      "123cb0a8dac745888329ef26a3176c2a",
      "2c39608fc9824131b09fbfd7a05a17fc",
      "870b1a886ae14bbf8344843e9be66973",
      "bac4e3b18b23499a9b13e4c05c245fe8",
      "616ffc561b5646649ea4dda1944e306c",
      "3ea41189f9a9496a911bc76360f4576f",
      "bae27a45e05a4057a19c886dc87cdec6",
      "d2dadf1003be40d1ac4fc38e39f63a59",
      "33c829d32cd5419cae6bc22d6cce19b1",
      "70a4eda13041494f87a31969c42a8693",
      "e018e6712dd9423bbb79c3c428795736",
      "73890b8cb12d470e90f4a216e60b92c5",
      "811b75e3c09e42dcae88bf0f29d232ca",
      "9267a7e981d24c2eb62ad633b091dc6d",
      "7020e0f52fe04dfdb87a867219de4026",
      "0c614329119f447aaf469ebe8d193ee0",
      "d0a36486b4da4dbdb83c4621bdd37fd9",
      "af5f69373b0140988c99a61742381de1",
      "77a9135c68904936b2d9aa0bb4303219",
      "b2ffcc3537c2497683f71538607bdd65",
      "922d7b26d3474bc986ed736428b57097",
      "96f2cb8354ad4638afb00cdb945c7483",
      "928adc247db64798beb5d4c4b8af23d2",
      "252a71f2332a48619d58a16f3c3b589e",
      "8489e40ce5c3417c8dd926bf24f7ef24",
      "407dd09bdaeb4c3aa749c3c17c653584",
      "b591c65263514e3584277fdeeb201d56",
      "1991ac7a52c24e3e9cc592b92f0c36b1",
      "514e2bfc60b149138cee7a163d777fd7",
      "96f55b64e6a849a993ed988212f7431d",
      "c1a2e298089745ce8e6a2933a5ae5677",
      "52ceff28857a4e7bb149c11f7c4f7930",
      "281c5c0801554a859acc604ea131c7d2",
      "9469470f228a4a98b2838bb42f85bdf1",
      "b34dfa851bfe4957a1c3ad365ecabc04",
      "a3e87d839c9e4bc98e7a303b0c3f34d3",
      "d0eb0fbb681e42229f1fea71dbad2457",
      "4b2e8e3b032c4c85be2bfb420cf777fc",
      "20bffe6de3c94c9a95711b4a3da5825e",
      "b0961a473c9c405eb3ea047b29f1fa22",
      "b1b8ad020d784d8b970e483bf88a07da",
      "87b6ec614d7a433a964198b617c59fd2",
      "d0c5ecd153db4d09a1e6eb73fdc22e9b",
      "4e930944952744d2b7ea3dbf2b341445",
      "6a98f5a694254befa8ac703c8f8a7091",
      "5882a5985eeb4509893460ac68237525",
      "077cad45ac24418e882d6491e86b730b",
      "70141335acaf4fa59eabb5ae1cecdd44",
      "d8ae68f34a3342f48d7a77b4e748223e",
      "c914ad3a9e9e4c7abc95a79b09c7c9f7",
      "52c52db1d2374275aa7116e8933224ad",
      "6126f0f434484787bc8c88f16d870644",
      "d68fda7a3e0e4ae4bc121bffa4ecf677",
      "7668072ad18d4d779e2a6d6a5d2f2ddc",
      "381149178b0b4f49b1c5a2e87c2c3ce9",
      "2a68c33598c54b30bb8b8629ba12a6fe",
      "e31b04e9448f4332bbb722d5a43a4bbb",
      "24aa696da0bd4c829d8166477a96e413",
      "dc71e096ecec4593afeb7c1f21c2d277",
      "6da2d2b38417469c9a75713ff2dc5e05",
      "1f9b0c30f3b64846b98404dca7e36912",
      "b8a8d2999fdf4221a1500229603194cc",
      "1f96529aa694494db540f607156fc344",
      "bc5bb7e51b9a492e9a81cbed76063868",
      "7f06a67c259243679fcc409ebb72f5d8",
      "658e2bd76fc04b1594abb381e5ce9b3a",
      "d856e5a873f2425eb85386270dfcba9d",
      "6cf7b47ee9194039b2907fa12b6c63b3",
      "1d730b6149e74d27acadd710d3de045a",
      "a541307457c24c58b01938489702bd4d",
      "6fc9c218ce154482b061efdc368caff2",
      "b0f934a1b1974eca88a53bebd5f141c4",
      "b7d4ade343534e2aae69c59c3d4ad765",
      "36392e9c71f841e3a9b8470d688f9f55",
      "0fa5291271794e7aa125d3ae6aaaec0d",
      "e36462bf2b34422aa5f3a904b8f669b8",
      "362444654f4c4a1584592954a69643e0",
      "c4afe60cd8e5470285013b9e2f0b0a9a",
      "e7e273bfdf1a4cb6b53416687664d286",
      "b74833b68bf749eb9997d13589f143e5",
      "5ff1b375e38d4428bcb69612b148b20d",
      "7abf0f4e62cf44219c49d9b6e08c11a0",
      "09b42321ff3d43699292e771bf359d4a",
      "590b393991c742418742b4cf0d7636bd",
      "629b8004838a4a9c92b4faf6e2ab3e9c",
      "d200e2d8b9d44f729e0efa4b8dd275df",
      "f10f632462e742c68a5fbd13e70ea02c",
      "f349f79444d14b169e648b34f8850bd1",
      "43dd9e20beaf48b5b434d8ebcd7cd4d1",
      "c7301233de3f48c1b8cf13510847939c",
      "217e94bb0df045c08584d55e057be5de",
      "975d3b69a97446fca6c5b214df4c665c",
      "427723e1c8cb41df93e686286777c95f",
      "8587d80347c64a06a1447c5799708064",
      "c6304b0f6d134da19e77f6136f251483",
      "2697b1e323544b808b8e7b2935860416",
      "a9285f533e0b4c3d8274b77f20b0596a",
      "ccb0f50ef46749199df30633c22227d2",
      "86e42cb5057946f8bde9a93856c16fbe",
      "10c1eeab54dd40e9bc62888ee05f6ec5",
      "e7629eb93790493c94b8f7e5ff4370b8",
      "9eb7beb8fe274bf1a3b8fda337d941d6",
      "b1a936a565b042eb99437820889d80e4",
      "796bbd7217154193b57742f106d149d5",
      "69dd0c267a8d4c009601e27fb9b5f2aa",
      "19389164e0d040fb965dd9fb13b85155",
      "acea83ed4c1f45808376cf599925611d",
      "cc110e22ae2b4aa68fa9a2900f720a4a",
      "24472b6fd4004e4a9d553032f196ebc1",
      "6f0be6fd5b4542c29582cdd537ae9d38",
      "8484ed5763eb4c15ac7461e9420839e1",
      "4da285c5bb05446dbde0aed19d9752cc",
      "3a579200c6fb415980ce0ed43fef0336",
      "60fbe58c217d4bd4a1e57b7ba0edfa2d",
      "7315a66e011345a3b3d90a77eed8ea91",
      "ea0e59b902ca4fc6803f1c2744218434",
      "ef137d8d8eb74f24b8aa1bccfeda837d",
      "1555d60512eb49bda98559885eed8b57",
      "eff5496d189c4d008f79a5be6a4bb42a",
      "f1672d904f71476d8cee437e355733fb",
      "ce25ba0684eb4dac8ad878d47a8bd8a8",
      "8fc58a80dc05406a82f3a3961df6f122",
      "c964f257dfd447b1b5944a460725a6f5",
      "3437ed448a9e4486bb337f2e70a999fa",
      "c4f09e0491da4bbd9b1291464b9beb2c",
      "f594a495deb64d59a9bee7ad06c4c612",
      "1336e6808bb0400baa62acb5d28925b0",
      "67a7ea3d78a54c17bc914b503b069b05",
      "1932de2adfeb426f8de4d514b7c98c86",
      "46cac2e9efa549e395f86766458e5296",
      "7b405c124d9140d7a3f929752fd4a066",
      "7033d93d33454708b6f29b8feea0d176",
      "95406db2de3b410bab5e65b70c9b324a",
      "f8e516e8d45048f59246e51652324d9b",
      "09a07f67645240609c6c97d69d16b21a",
      "ee369ce3d6fa4f9fb0c7d244fa997e24",
      "34e19948e9bf4044a1cfc13924841364",
      "0922df7a0aaa4da4b3d33e04241ac502",
      "8a5814753d0949f6aa9a16ef40e922fd",
      "3fb1bb520fdb43ab9a80503e4148c85e",
      "5b9a865545d643368d9afd69d46c69c0",
      "822985d5954e429f8145fc32df77b210",
      "f02fbc0d849c434ea9372aabdadd204b",
      "00bc389a95024adbb2d500cc0df6a079",
      "eab684b3b18c421fa32d680a276d2e2d",
      "90f79b57e0ff4a80b309405984866754",
      "1738454faf604bcbbc45502b03d5ec34",
      "5b05529cec4d47128740b594fcbb2ec1",
      "c46d86bf320a462da12a22d6f7accc09",
      "01cdedc638314410a2f714e4acc2f620",
      "92c11ac2241e46f0bbbe0aab02772916",
      "204335fb039649a9b7afc6707b60981c",
      "ac1781ec43cb4acbb45c79a59652d4d4",
      "32feefe7e5eb4116b40d97481c9ea743",
      "35504e18796f421cac417de076683d4a",
      "596e3d444c1549738878ccd38bd40e63",
      "33fbd640997e4bd9b1a451f887a3bb35",
      "88a70cb5fdb345868abd52c436f8b129",
      "0c4f3522d67947d6b284da1e92311f74",
      "dde3bdc4fea34d5ca0537814ebd824b6",
      "e6892ec3c4a34e148c89cd107b3f5300",
      "4a64353b407041d99030b8184f34872d",
      "93c75a3d2bcc4b9888289d18c536872a",
      "6091acfbd1a14700bf87b005d8c8de23",
      "ef2fa57c10d447409d1d1a613ce93b1c",
      "c63965fbf07a4fbfb3ccf613d0869e05",
      "610ff81edb49471ba1a55f57c0fb34db",
      "207e995b2e314ca394270f5659468f7f",
      "ce8e9d6015334936bd1bce2c85b86a0c",
      "b872dce7b5bd47c5ae940a01419263d1",
      "f081e97614ae4d9cbc5c336df6af563a",
      "4d6dc09cb66a41f8afab4f8a567a2e52",
      "5d03cf5e4afc43e3ab94603257739158",
      "24901f8558f5446987a02a80a6b16310",
      "2923cc05c7324fdca49309a96bd79f35",
      "bdd307ddfcc740a488b5b96934dda5bb",
      "ad5946e029204acd93ee449fe2135988",
      "fb571332c1194ae4b8820485d93b92c1",
      "65b5e45168bd478fb5c4aa063d117f3c",
      "e97e044e0f4d4165aa0a95adb6918d33",
      "f8b786c09f0e44e8a63f2a392f1baef3",
      "cae6517cf8464a7a808406873488a713",
      "836bdbd5f80a49acbfb54edf987673ef",
      "53fb1b12d4144306a227a927be7ceb7a",
      "bc89f959773e40b88225fbabe5c46c4e",
      "92d14fab91334c4ca485b39579c469bd",
      "f333f27947b44b14b069fb783b5394c5",
      "0f935166d1d443b2936f91a240e9fba4",
      "7520b4fb7640478fb28986c81a0eaae9",
      "3bb25720498145838f42dda150a10def",
      "a732117fb853465d9fe14eb395947917",
      "52710bf31d704752801bfd0eed02b18c",
      "381e66a8940c4fa5b69cfef440559743",
      "e49adc38eb984ead91057db261379112",
      "a1612ba0a4144bc69560ccc9fb29339a",
      "3011a0e8485d422e85f1209f0e1ca74c",
      "bbef066d16ab4031be9fe4273aae46a9",
      "e38584df1e7b428fb14cd41110eff560",
      "1bab8b310adc43cd9fb81b33ebd44a19",
      "9f8844838425473aba420a372ddb638c",
      "c710432044c345ef8071f85399f5faef",
      "48620bb9554b42a0ae0b6fba2706ae46",
      "4bcf3f77f21242588414ea778dc03b83",
      "75c123c2a7734dfc84db900f69fd8bfa",
      "d6e5ab3e43c34ec7a718b54d1e4f1bf6",
      "83dee5b3381846d5b8b1e9bb6f340ac6",
      "0798a52dbf624ab5ac7e3346d52bd635",
      "e28b08c9e86544f7a331e840ab1c4d4b",
      "a792cc892e244855a151a847cef61159",
      "6dda6512c5584b2aace87b783e0ef20d",
      "29a8224454d8419eb580728f4cb48890",
      "1251d5295a2d49fdb6a549b55be1e940",
      "5833da46bf304103ba7a861253649e20",
      "59bd9f85a59747e6b67bea4632b32a02",
      "8b797918756e488581cf9dbeec151829",
      "13f835ccd2c24dc9aabe9341f69ad48c",
      "4e9394c7c27a4cd9b1a777182038c6f1",
      "6985183dd0ad41b9a21aef4cd8aedfa0",
      "88f82dc101fb4ddc9640a5aaac9192ef",
      "84536db5f0f24c9da83fcbf0e3564372",
      "fc428276ec174de5a3521f4abe3ffe10",
      "0c9aedf3180e45dcb494858fab7cf6f2",
      "67452a5de13e40af8752006dbe09e747",
      "aa887a99170248cc9b76838d59e01490",
      "c90f8723af3248e480fea1fdd45fce4f",
      "f9e968c22f45468992290ad489bc339f",
      "83246b22e75248f99bfdecc0bd3ba1f4",
      "d7e4bcd691b441e1b6a54e14aab86c4c",
      "8be236f1f1ad4fdb8f1d10d273c97d10",
      "282c834515d442e592e6e3a1a928b686",
      "9ee3df7de9e44ec5b8994746fe1c783c",
      "b2d6967b7bdf4bac8ad81778561fca87",
      "47dd32ad020d4bcc93eb951099c4fba3",
      "7f9f325a374a416280dab1824a61abd7",
      "ea98fb56ffc54f9799be4c4ded4a2ddf",
      "02a48dd6add54eab9465c5c3667be7b2",
      "fe2e27650ae54f0583c6be5186338f95",
      "e8076744bdee4c328708eb54cecf9057",
      "9e00746eeaaf461fb4ed1cb2094b7928",
      "3978881b8abd4823aa339e440a8c7224",
      "0e1c366a740d422c8887a3d38e99d034",
      "df3cd1d027bd44ffbe1349e43903e7ab",
      "f06a01ca2ac145509f2625091af62ef1",
      "cf5be68803f3490e97ad62049387675e",
      "f947c663d97841b68fd91ac366d70150",
      "6ac5ca4be0ce47fe9b59edbbec2422f6",
      "3bb238187dce449aaac52bc73d4c4315",
      "7c3a024866a7402ebbda6cd23630af22",
      "0d7d0badc5f4494d9e7fde8e5963da5f",
      "f1a859d01952431eb4231f9d96dea08f",
      "5743c71e117a4da69c9d64191ec5fd11",
      "145b0a4071924f89bc32a471621d6abc",
      "329c124d46834835b38f5a5f2dcc8970",
      "48d4e2bf9bf94964a169d3e43ae28f76",
      "5e360cd452e84230bc197d1d4cee1e1b",
      "23684c7250634a66adae451cce1a6d6d",
      "aa2051d018ce4ed98a622d27e5f6c3a4",
      "40462daacb5b49b680b51dd6862bec82",
      "2708cb669c1c4bdba85be7c461af484c",
      "f5715b13c5de449aa175470d3830db54",
      "2210b0143c964b8fb99edf8c3385381c",
      "0456e1c661f148cdbc73ae3b8fe963a4",
      "e293bdb2acbd4450af2d21b0e622cf47",
      "9366f9d8db6f45179c11d8f6ee78fa4c",
      "a56964c5f8ce43558126f6025f87c664",
      "b010e986cee147f7a4a99e575a9fa297",
      "9cb861389524407c8118171c2ad53a2e",
      "986c16b3ab9e437abe04c1dd2adf6280",
      "1d2b510cea8e4df6af4814961d30d3b9",
      "73168c387b5f4de4a15977b5ad09f03c",
      "6376dfc6bd7c4e11b3ed99943142593d",
      "85cc9281ecd54a83b3f36b6c5692c755",
      "fc8dd1b169ee4b75bbb9ab2d3e59e9a0",
      "8af308b5619a48b994b89d659ed0e4ca",
      "b99909856f7b499089acb77534f2ec8f",
      "6d86dff405b84e08903157f987ba5dff",
      "4e53d0966f144314a48f2bd1da0f7d91",
      "0c13c630ebab47dd8500bfeeef630671",
      "fabefdf2fe2a43e3bd88be00f7b310c5",
      "ae9d94ad43414c269c2d07bbfb2c673a",
      "d0f4d7c9dfdf4b7ab7d72ed81611cfc0",
      "71b32a904a71422abfa97f6cf2f1e363",
      "7fb109344e6640d9a34a20d5ec033584",
      "28e2a9b7a2ce4ad496a326ca03edc4ff",
      "1598b849f49949f8a609694f3009fec0",
      "a470cd9fb01040d2af53d1ebf8b790d5",
      "ce56320fa2464295bbc33df2817cbb63",
      "c9e8e58c5a0642528b8ede2d75108101",
      "fc625d368d204b14888bfa5c114c4694",
      "7278f9744890433baee831dea739ea05",
      "556a6ae7bf7f4f0da5730ff9e481e1e4",
      "a13f67d98ebc490691c46d88f0969fc7",
      "8d8c7476867346e4b58c96743c077ab8",
      "ab0c90834b6f47ce8d7ca3cef45e337c",
      "f4418c4f45ed46ecb7fe517efaf87f6a",
      "88816936ff4942a5872c81ab54534836",
      "32410bdef98f4ab188bd2e76fdb07f58",
      "b6dfaee2599341198d7415dc3369b0c5",
      "83477df05601426b9dbed8731fb1c795",
      "b47adaea3ad24e6c96e39cf8027f9d1d",
      "f24df76975844351827241b773f66b53",
      "429a3f023f0e4b8287314c0218f60839",
      "e171c02412c84680899b2636177b4243",
      "5a1cb0fa61d84f8aa7527bfd92608931",
      "cccd86b838c741e2bc6df41d635de91b",
      "7c123cf37f624f809198005a6cb75af2",
      "52264e92e15044b581fa33f645fa08aa",
      "e73276e4088e4d1f92fbdf93799b0554",
      "1eb6ae85b06e43039e48e5496f43f733",
      "271c20f76cf442a29e01e54b6c67edef",
      "eb2f84c04dc34bf39177d840cc941f45",
      "485266499a64429b8ad5645c754b0185",
      "f231c2ce730d4230b79273ead2b7730e",
      "f29a0174bd5140f4b1e2f444986e7f46",
      "a7e75da661ea4c89b9ccb5023c5eec3e",
      "f697c4820f1d4b388d5e47c077e6cf5b",
      "14a30570356c493b84c18945bfc96081",
      "c9359addf7de44478a5308ce4bb3a319",
      "fbfceb2ddd6f470d8e9f85e87d20ad8e",
      "df5f9049cfd24b588cbc42242ad7186a",
      "d3fe2727d0a1453093cd51bd767b42cb",
      "c093da45e5a547998e1ae79d5a601ecc",
      "6d9c3c24beb5406589f233fd00adb56a",
      "cc6822d8a6c740d88138a730ab26c2a8",
      "3851079f6df7429dbff004cb3c58604a",
      "eda3918c7bd3489891178e5679adb18c",
      "a5acbe0b31644e1ca30d26e8cae4ad2f",
      "6de396a936174e3c902f9555b2498a28",
      "0e47fbc06d2d4f53aac0bd8f0383231d",
      "1279df1a125c4dd0a6b678b445445cd5",
      "606c08fe9bef4d70b4551e9fb8dc64ce",
      "4cb44e98cd944681b94a4f805a5d4583",
      "245307ecdda64cc98489eb2bc8666a95",
      "a8973c78fed740498dbe47909c96c9fe",
      "f6e9a44660354426988d26cb9f027bb2",
      "033f8dc7252a4133b8e45dd6f40c5022",
      "469b6ad83e7a4649a53962c8a07e6522",
      "0b49658b58824b618dccb030fa487e1e",
      "376b674a227648d1ada1211358acc70c",
      "d33ce9b9eaed4f82b2b2027c5d201bd6",
      "d504ee09293c419d90438e980340f280",
      "fa4718feaf7941689fc8c6fc05788cc1",
      "4529c40b47644f5885023ade38799bcf",
      "ba7c503cc7124f128bf76b41bd95ce98",
      "269e15a5c3d44bdd814edd989c5afcca",
      "8b9461e9bb66419bbcd5e1924d884cd2",
      "1e2bed14bafa489aa450742d329b797f",
      "c4588b66d5794cb79eeb227bfff0aa0d",
      "d4c6c2b7310144d78ddd761b39c4058c",
      "f926469e3d1b45b29e302d6af511bdf6",
      "28f0121729134fa6b0092a2255779ff6",
      "3c2f71d94583437594c3a9bd34efc2a6",
      "601f1d71785f40c5830128daf84d9898",
      "5492726a60844950927f613b1a491ec9",
      "48c69a17c37b4518afbbfc78e7f085d1",
      "154420e877bc43f6b9921cb0c9ef2c80",
      "3d5fe8fe44224daba4621994d4ab6631",
      "2dbc40f91cfd4dce959a6bfbd411e050",
      "64b8960d9a3c4fc98ac7c88d815c04bd",
      "f87b79c64d4246fa9d8ce22d2f4cf5ae",
      "44c43622e0a84b808b10ea4f7e5ceb3b",
      "c92fbfba7a76457db4024f47f9e6d585",
      "fad7ca202aac4143a59d5a80a2275d98",
      "d4f9afdabe094dbdbc7eef9b7bac28ab",
      "b5e8896ed5e9454e879ad55d878d54b6",
      "45b14497cdc74742a055310a843ed2d7",
      "9e9cf100e5464066b0ad81a2b9af0dc5",
      "feec59b317a54e348d5053b2871b3d0f",
      "4bd22fcd547c4c5689c039e215023b53",
      "7518ec265c754119b4338c4449115e47",
      "1e2d12776bea44ff9b15fa4f13a7e1f2",
      "626e458703fe4ecaac1835607da641c4",
      "dd3cf23ff0b44191b4a96a5552ad58af",
      "54d2925864294d01a4fa0f1f33c38a74",
      "904699dd93f54007bef6883ff6243a05",
      "4e12d36b0d6a474c87301ce0072a3c7e",
      "4329a24192d04e3ba94abe7ee8c53de7",
      "ad189f03da78405da70bc39e3659c608",
      "183dcbc4c22942bbb9b5e074a0103fad",
      "e800b65ce7834233b3dffebfe21b85ee",
      "8bd790667ff44bd2b61baf1b37f3fcbf",
      "39062737500a4d2abb3bdfbbfe537416",
      "99f844a3c65b4c8ca51300c16c77846d",
      "cb8c640a70b044e89564680dce194311",
      "51c2d1fb27fd4ef3898921a2f6bcd95b",
      "af510f05d2544ba6992f501910452561",
      "0e439a8e7feb4f24bccbf22980efba8c",
      "272e1f1a237b45f6af571636b3c7e774",
      "dbe89091983343d597fa9537d05db07e",
      "18ccd36328004c4abcf7d8467b6f47cc",
      "5e1c91d495df4ec4bf2d4212cbe30a15",
      "76815e7175b04528add386aa7598f8af",
      "d288dcb111054340befa3c711c614e24",
      "339446f44afa47189acc611f2d12a0c6",
      "21015e28ab2b4627a9b6d2386431418b",
      "79d3db471dcd476b8c98fd8bfcb54490",
      "42207647e4ce494197989b6b6a9e8e22",
      "c2b0ce3a4f2343bcaa4bee9ba0554f58",
      "4027e61356f74e18b2af88d0854077f9",
      "8af37245079a4268acd231cd142a8bb0",
      "7ce332484e1142fa8f2145bad7719ec6",
      "d989a2e334e2466fb1ce83015391ad23",
      "fa4bd67373fb48a6b67bc8cf6a787486",
      "d109318fc03e4e1a8d7ad94df758e25a",
      "a7b4b890d72446208c4e80e4a46a3814",
      "01ab23d9b89b43059ce91f703fcc4b65",
      "c323f9a604d243fdb3b3d25c2db82018",
      "bbad2afdf3d2455d87b7e7861f288b10",
      "dd62b3d590af47da92b6d8101c8d9a95",
      "933ae14eab2e416baff682e15501e1b3",
      "3de87396feab4218a1c97102df248910",
      "9413eb1bbcc04fe0858aec26f2492178",
      "d38df9af520f48919e7f52d7a9c31857",
      "ec768f6e5721408d88e9fad1a21e743d",
      "dfd48db8d57f4e30aed4f596e6c08c1e",
      "9ca906ae141744fd96fd07de4a26cab9",
      "298914d9e5594291b908d9b1dd6f0de1",
      "f1ded5dc0e85456ba863d83766c9a230",
      "842d5dd3a1b14a5ba97a07c48c4f9c32",
      "2be5e7bfc8e349a1a26a1776424f4f5e",
      "ae0d42173fe041a2bb169d5584c54af0",
      "235d01065eff41b9a6cafb9704e6c02b",
      "4dc8509746754c2282661b8e8bff1e97",
      "2487bc5e5d0a45a788866b6e781e247c",
      "70c6bfb4279e4e6999cdb12ca06513fe",
      "94c82839f32a469f974b038a50c37d2e",
      "f6b7cae46bfd479b96f5b9acf080029a",
      "9a9f730c1b254bef9ebffa2d6f9361cf",
      "c95004d54b2845e6aeefa27297f5bb93",
      "522294a20bca4d0984c213f2969926e2",
      "208af2668ce845649a99984121477659",
      "9cad1695714b4b49975a6b778727cb9a",
      "6c211d54f01a4828959da48dcd8ddacb",
      "3aa196b523344d1091f18b9350d9ac4c",
      "14db1696383a4edaab87176b252b7076",
      "1f65ba312ed94e549c9a3188ea0bef7b",
      "ccdac4fdb73b47a1a26b15148fd4bf9a",
      "fbc0398f6dab4c47a2cf2693345b4c91",
      "95b40b9eac614ff5a799c34c2a734c53",
      "302c01d70e0a4335bf3386cc3725bd3f",
      "80e9811992054169bc7e5922795a231a",
      "7915a0061d4246f298651b4e34b07abb",
      "5aa21adf8e1848cc9a58a91936ae2678",
      "16e1b08ffa95418aad60ca85b65f85af",
      "17dbe865744e4a9b86814d3b7c2576ba",
      "8205ed72c9d241cc881ddb8a738e3480",
      "0533bb8b0c9044f0bd28c4e8bb6e76d6",
      "7fb11a8ced8f4e21a446a50372329b09",
      "c7168d550fdc42f581e1c57da332b16c",
      "9e5cc6a5417f4817a6e94659f9ffd331",
      "4a2dc2dcfd734c89bdeb393b9136f5a7",
      "359af93cbf4144749ae5d3ed89be2341",
      "58969bef745b4e0da4ae8d228d4f7542",
      "e8b4b2a0c7154477bfde2ecf9fbc2404",
      "cabd305b02fd4a1bbd36836f868f2e6b",
      "dad869ae19d94fae80b627147b6ead78",
      "1f610b4fcd34445db10c76dedb94cb81",
      "cd80d73b93cb4419bfb0a26073567c7f",
      "53317cc821214219beba66ddaa63f4ae",
      "4c6bebe12a224d9d954924c3ed123c9b",
      "b58d984fa9d44eff8c89db9b43abc2fa",
      "057415bc7a85479e88ee28578fe1bbce",
      "be48cc119157461a8c9cb4b4058f1b39",
      "9df31c718a3340dab92321e716ffbd4b",
      "b76d858bc1a84d5d910060f21fdb8923",
      "bd43f4a962fc4702973b23bf606c0493",
      "9308845a799e4396ad5792f2d5862f7a",
      "4aaa993060d24baca6a8e62448955046",
      "45f68eddf0ab47aabbef64243f84ebbe",
      "d4d19ef7f5e3413a97b70910bbf8b941",
      "89f8bab59d8e4cb8a8d0a6c4e2457df5",
      "99ac7e62fdc74dcbbf35e62f0c94dd04",
      "99e0f24fd16a4f22831ace287d56c212",
      "52681717e5484e489716c75845adfeba",
      "a6fdea6ab3d8417e90b798651245063c",
      "3feed08637af4ff68e0bee648981aa25",
      "fd260132a693499e8f00d3c7463b10d6",
      "e4496c6269674be39e07553306b55642",
      "7f8c0b021fbc4bd7821b5940fe50c671",
      "66f4ae05372f42a593f0e92ac1f99ca4",
      "246a53d610d04edfb5eab76a57772f4d",
      "ef329aba75bb423b8c388bd2a43e96d1",
      "e88c48f5c955478cbd420f1ebdb33ba9",
      "0f9505260f1849bd924586d38022ea60",
      "7a22bf26a4bb49c79d54e73357d91080",
      "a27209ac7f6942ec93ccf37b4b51f6bd",
      "4d2a4f2fc83d43edb8d28adb9452ce25",
      "535bfcd7aecb44a7ad5ca078194822b6",
      "924ff42a4c244004bc10b4e83bb62f00",
      "9cd547c7970a459b882cbc66e95c700b",
      "3949269c90484a84bc672a829451b3db",
      "4536216affb8416f9b88e613f32b1483",
      "63d66aae407f46ae997bb384f92a6557",
      "4c32f0328f06482190f7c0eff700c5fb",
      "db6a6753b8ab454d9130dbd043a883b6",
      "c4bcea0a36f94d27b1403a5b59a6b06a",
      "c670d48b69de4c5790a3ebcb9d7dcf50",
      "c704dd27b3bc43e8a4e9564f3a75bf34",
      "0514437869c54403b4267e9d74eda25b",
      "bbba873f30d84ea7b290439c5297ca56"
     ]
    },
    "id": "kuSMdSC6ex5d",
    "outputId": "8ec06ee0-3ec7-4fc3-b1bc-52075645f2b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:wandb.agents.pyagent:Starting sweep agent: entity=None, project=None, count=None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: she6q1b7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003612154943221165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkqmdjoh\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_012324-she6q1b7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/she6q1b7\" target=\"_blank\">hopeful-sweep-1</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b85fea186c94f06a51ee6de3fffe439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76aa10aee61c44919b545cb076ad07f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96791af3cca419f840648e606a2de61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72dee2fcd6d841849b6068f577324108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23624b19ae7e4fd28cd019df2b590849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae295385a674371b25c7361e3d5a38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30990205917e4bc8a9e4701ea5234ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403611bcb3704b9ea531317adf23d8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadfb113aee9457ead06dd00e418c082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2587d2f5a4f748bbaa982712bc859e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47c6552af9b4922bda8448378fd7a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969d2fcee63b4ae08106f771924be9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb.plots.* functions are deprecated and will be removed in a future release. Please use wandb.plot.* instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8995052654421198, 'ami': 0.9081207138563379, 'eval_loss': 0.3708273056523292}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab064865a5ab4f95a4249cc58ee57b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.380 MB of 0.393 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966516…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▄▂▃▃▃▁▄▄█▇▅▄▂▂▄▃▃▃█▄▆▃▃▃▃▃▃▃▁▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.10839</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hopeful-sweep-1</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/she6q1b7\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/she6q1b7</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_012324-she6q1b7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mp66aava with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000617692295907866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_014045-mp66aava</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/mp66aava\" target=\"_blank\">expert-sweep-2</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff8c9d88e75406f9b22cc36700ce1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56851a7f58a4b9aa0daa70a5f9444d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de008f066c3410d81e49b1d6c9e3a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef04c21789ec488492417a591c0e3186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeab414613724c56a4b8c2059b67f850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01eb5d98c534499b373f3b6ce4c5af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a430bca4be8415e9b4a1514d1190a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5fb57849bc42f08b688d577416379d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ec419dbe36475b805f8710b0476082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2deac93e3e464469a6d028b476e77eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1372530067089905}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23962cab84414c07b5e7ebcc370a0b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.054 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.774474…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▁▂▂▄▆█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▆</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.00089</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">expert-sweep-2</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/mp66aava\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/mp66aava</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_014045-mp66aava/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: swid4ecc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.3910546563327363e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_015357-swid4ecc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/swid4ecc\" target=\"_blank\">major-sweep-3</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b93b43abf2648f6be1c703cedd64496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb4b71461574b5491d088f575bcf9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5061401fcc43dea40b1824c33644a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc84e88d0f0245b6ab536f65f14b51ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1aad07341c94b8e9bc6c4f45e45cddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f937a93c8c8a4986b4ac7fb082de8b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5662235d91ce45ceb7ebd5920921b2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9579507028663627, 'ami': 0.9441292092247556, 'eval_loss': 0.19451221714878}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b20ba5556594c96ad61636e5cc23d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.370 MB of 0.383 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966441…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▄▃▃▂▁▂▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▃▆█▇▇▆▆▅▅▄▄▃▃▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.12411</td></tr><tr><td>global_step</td><td>850</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">major-sweep-3</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/swid4ecc\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/swid4ecc</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_015357-swid4ecc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rlm35d19 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008976052775587532\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_020104-rlm35d19</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/rlm35d19\" target=\"_blank\">dashing-sweep-4</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77041298bda84e64afa0d610f88c7b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb52c4b90fb4d7ea956ee7ac5e1bb83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c74b423a7d4a04875611cc7425cca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34795c6603c4358b923217070966ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be8ac8432e9451da44fa9cd8e9e8ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1fdd495b81455499924a74588651e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a2e630a6e447eca5188aa1330ec2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.138114966068071}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4ac4ebf0494670a01c2996ad0c7abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.041 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁██▆▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▃▆█▇▇▆▆▅▅▄▄▃▃▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.10001</td></tr><tr><td>global_step</td><td>850</td></tr><tr><td>lr</td><td>3e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dashing-sweep-4</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/rlm35d19\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/rlm35d19</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_020104-rlm35d19/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zikauf3u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008582057107081806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_020807-zikauf3u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/zikauf3u\" target=\"_blank\">stellar-sweep-5</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1beb63108bb4d04842e29970ec55bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcae46c4d984001876adf306387655e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d6f0994d464ba188bcbf07b8d1c1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd52f2b9ab8409e81deb05659027f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc9c9854d1e4e7d9bd04c9fa7a2d202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0565e092d1441fbf4c628375d11b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7dafb25e82465ab6550ac18188ad74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e7df53085a4bada26f8bcddccd90cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1387770823187027}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c9b231d193411d8a0b094332db8951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.054 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.775033…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▁▃█▆▇▇▇▇▆▇▇▇▇▇▇▇▆▆▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.20709</td></tr><tr><td>global_step</td><td>1150</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">stellar-sweep-5</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/zikauf3u\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/zikauf3u</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_020807-zikauf3u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i6yf0xn7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003098495139241903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_021719-i6yf0xn7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/i6yf0xn7\" target=\"_blank\">woven-sweep-6</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b24aa1d0af433b941a60f3e050d0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce83ed7179d49e98d9ff55f3fa500b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1203aec965da400e96d2757fb337c435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040f8aef22cc4914adfdb1cb25818b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128fcce8a5654ec48f8d33acf64326c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5c02d14da44773bb2840d5b553f7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce02e377cbc6498d92f7b0e5004f3793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12db7b9738e04b2aaa3ec02281113fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700c2a7e96b94422ba1a221a82e71eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9538330906483843, 'ami': 0.9370087383055641, 'eval_loss': 0.23554124683141708}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3eea35309d748dbabb6780ee29a2c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.374 MB of 0.388 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966247…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▂▄▃▁▅▄▄▄▄▇▃▂▅▁▁▂▃▁▃▅▁▂▃▃▁▄▂▂</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>▄▆██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.19349</td></tr><tr><td>global_step</td><td>1450</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">woven-sweep-6</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/i6yf0xn7\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/i6yf0xn7</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_021719-i6yf0xn7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iy6mljou with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.870956977132281e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_022835-iy6mljou</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/iy6mljou\" target=\"_blank\">lunar-sweep-7</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675b2f86a8174e8fb86ed9aac923856f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4a4d0c20714c8db1b321c7a3c7524e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ddead8ffd14bcb8e355cf63301bec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffaccc2ba6e748c587fbe7bb8ec5056c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78eddb9f7d974b2489094c57a1b46bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae3b506607044c6a0419d89cfb5cf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d978ee712f6431b817d4aa59ed55631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e3234e433c46c9a6f6359fd40d9e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9611455867979579, 'ami': 0.9459633251796826, 'eval_loss': 0.1874447547257766}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e04c4a3116248b2831af723200b3c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.370 MB of 0.383 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966271…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▃▃▂▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.01854</td></tr><tr><td>global_step</td><td>1150</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lunar-sweep-7</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/iy6mljou\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/iy6mljou</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_022835-iy6mljou/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y52t3pju with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00012463072564736563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_023743-y52t3pju</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/y52t3pju\" target=\"_blank\">serene-sweep-8</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b53f5c572d245a2b4880a2a43bcefb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f0bc66815049ff87fe5ffeb1177267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e148b532124721a700d37f210b2b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fff37a8766442e394147903686900b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3ac0682b594ce694f77f9474911e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9725fe7e0b40ea97e96cdb18da57e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddca72d27155416a8343afd9e3de7578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b61bfcd9e749a5aaac2dde10d58ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665a0b056b41478ba5cbcec40d73594c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250fe1dbf6f34692bc6e9e82a410ab84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b401d436b34093afe57555d3a9f95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2dd443c1ab4f5d82a2822f1bc028b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9597762892163426, 'ami': 0.9431286678745745, 'eval_loss': 0.21220736638274798}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a643e1429b3c4abca4a8334a025a40be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.374 MB of 0.387 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966388…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▂▃▁▃▂▃▁▃▂▂▂▁▁▂▁▂▃▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.00484</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">serene-sweep-8</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/y52t3pju\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/y52t3pju</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_023743-y52t3pju/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 32giqvto with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.272330100086737e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_025509-32giqvto</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/32giqvto\" target=\"_blank\">vague-sweep-9</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4a214393414d8889bcade766246d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b1580533ed44cb8adaaf2112d699c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a863dab8c97f47ed8718ecc780464205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977e7899b36744b280945020639346d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b992b169914472c94ec9f04fa7ec75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6c46c06efb469db630f57fca01fcba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22f9484345040b9a50466763a2b5726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c01c55c2bbe41eeb067ff67239c744f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0395ec7a947346d7b5b149bfe56adb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab10ce3c26b04f828fcf6193fc4944ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90614b809c36490a9083ed38248a1db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e190f1645aea498d9a97cbcb9386738c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9648048733938206, 'ami': 0.9493645896331961, 'eval_loss': 0.2038693520979783}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e80ec9798d94ddeaa4d88d69fe8df38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.370 MB of 0.383 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966223…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▂▂▂▁▂▂▁▂▁▂▁▁▁▁▁▁▂▁▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.00428</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vague-sweep-9</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/32giqvto\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/32giqvto</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_025509-32giqvto/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vw53khx8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00017373839234189538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_031235-vw53khx8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/vw53khx8\" target=\"_blank\">fiery-sweep-10</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2275dd8d723c4e83b3ab18f12b152d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea83509f113647eda3e8e3f600f0c67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772c23ccb4434f13870ab19fe6dcd1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e133712b654224a34aced2cc35f3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fcce7348f9412bb6ca531ba950b523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16765a1297744a3baa55e50d57c370fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c62a73c16443dfacccf1f7cdabcbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162951ef7d0942009dc93d7d81c99d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caea9d6fa46d4c55a6f2b1947755c940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee64a25fb384e13a1fbe7916208f942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f393f807460a4b60a130fa58210098d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c32c7751eb841ac8fd9b9c780c4dee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.960687542010395, 'ami': 0.9441183086038055, 'eval_loss': 0.20238108667977078}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d89a92c6e248b589fd971c8bdcf091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.371 MB of 0.384 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966165…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▃▃▂▂▃▃▂▄▂▂▂▁▁▂▁▃▃▂▂▃▁▃▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.00601</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fiery-sweep-10</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/vw53khx8\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/vw53khx8</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_031235-vw53khx8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: os71fa1y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.810011401375808e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_033006-os71fa1y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/os71fa1y\" target=\"_blank\">confused-sweep-11</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7dc61f3c72441ab8587a50fca0a64d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af316be06514497ae3e0ed5d109d1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ddacecae6f401f80827fa45998c2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93577101e3a54c1881b237d9e6a39738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9953089f214fcda1fbcc75955ad807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d266dcd4e3ca488d9a5cc2778b04b53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f8440174294a4b9cf208048e6cfcf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9792cdb70b7b455fb299236aa3ee8852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9588682398247181, 'ami': 0.9426377521337587, 'eval_loss': 0.1978684279466003}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c485061fdb840e89bbe290a27ab08c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.370 MB of 0.383 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966275…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▂▂▂▂▂▂▁▁▃▁▁▂▁▁▁▁▁▂▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.06129</td></tr><tr><td>global_step</td><td>1150</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">confused-sweep-11</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/os71fa1y\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/os71fa1y</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_033006-os71fa1y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dx0tryu2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003961268883403955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_033925-dx0tryu2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/dx0tryu2\" target=\"_blank\">happy-sweep-12</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78ad669fb25451ba2996e8d245c5663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7667fcf30e9c4a8a80cba82dadf166e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7791f5be2e3641db8e795aa055401b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91aad30460344e6aa831f8b40228e777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8e8df60619448ebcdb496926a89be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb37c4c26164598a70828b87bb89197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06ed394fe294aa5a52d35b0e0865c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df55c0a391fd4c1bb9f6d637ffef51d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87a3aeb16014cccb25f54fc2c8cd4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ab93e7f2b84ad5ab0d7ae7025420ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108e45a673a94387b6e217624c12b7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9048271496211547, 'ami': 0.9047373432625235, 'eval_loss': 0.3705802379604877}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2720ccc95d42b68e4e1dbccaae8fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.382 MB of 0.395 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966473…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▅▂▄▅▄▅▇▄▅▇▆▅▅▆▃▄▇█▄█▄▄▅▅▅▄▆▄▄▃▃▂▂▇▁▃▂▁▂▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.14958</td></tr><tr><td>global_step</td><td>2000</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">happy-sweep-12</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/dx0tryu2\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/dx0tryu2</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_033925-dx0tryu2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vdyehpos with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00039221099083435205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_035451-vdyehpos</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/vdyehpos\" target=\"_blank\">laced-sweep-13</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056ed3b1df74401ba6d90efaad524866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a09c0c1dfa4045ba56e45eef2bc9f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d164056880844434b0882c140d07ceae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50da61f27cdb4acba43be4dc101dfaec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149d3cfb550049148d63185bc2783c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f02fa56aa8426eb0187d4574eddf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc37a51d4684f4392d08e9f7baf4a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f4739453d24b258a40202673e92957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c0d8ee78714f8a9e46ee6de3469e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd06af021ec4280a4c76de8a624c002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9314268152799057, 'ami': 0.9173459767388051, 'eval_loss': 0.3487178112837867}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8aba4d403d1485588666b932838d361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.383 MB of 0.396 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966088…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▄▁▃▃▂▂▃▂▄▄▆█▅▃▃▃▂▃▂▃▂▃▁▃▂▂▂▂▃▂▃▂▁▂</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.36899</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">laced-sweep-13</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/vdyehpos\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/vdyehpos</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_035451-vdyehpos/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ab9hfrua with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005310700628051459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_040809-ab9hfrua</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ab9hfrua\" target=\"_blank\">cerulean-sweep-14</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aec5d9112cc48b2bd90c4261978b75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487c48dd5ddc4aa68bb937d784d45cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8741ecf06d6b4f2485e003e3b7fea779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e586e41eb8743aa9956664c06261c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92914d15f8e94ead9c51d7bbdb8a4fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e50db65e8b43a0951c723f946a2dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ce8661d3d244f39480bd06b552870c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e46638133084e32abf2d34b75c5d14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053b73639b2b438d95202f6def0dfee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f074ee59a52c451c858a6fdb4717a826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe1461894f146d4bca4d6fc25af9d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68a384bb6584077b8d28fa61f6d3958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1362663765543517}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678fbfc8fd7a4770a54552c2a74c0d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.772846…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂▄▃▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.00122</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cerulean-sweep-14</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ab9hfrua\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ab9hfrua</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_040809-ab9hfrua/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ar0vv5gy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002534916555467257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_042545-ar0vv5gy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ar0vv5gy\" target=\"_blank\">upbeat-sweep-15</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a4eb5d509d422f9e78615a597030b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcfb992b322499b8185bcbe6b460280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8820f354938404abef13b55cfaf48f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13105cf73c544338b072b67b91f9907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96fb7c50f864cc39e7d5c7f90a37125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ca1352deb2497eac36fc911a443c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfaae53265a48ab8548ecf432a327aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b118d2e49ce43a0aaadd2865f992d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9470174551331998, 'ami': 0.9315967624757322, 'eval_loss': 0.23501073730360603}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499c656ca7804a6a8e835625a263b2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.374 MB of 0.387 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966039…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▂▄▅▃▂▃▃▃▂▄▂▃▂▁▂▂▃▁▂▃▁▂</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.13106</td></tr><tr><td>global_step</td><td>1150</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">upbeat-sweep-15</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ar0vv5gy\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ar0vv5gy</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_042545-ar0vv5gy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 88dfek1t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007014345476234125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_043458-88dfek1t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/88dfek1t\" target=\"_blank\">dutiful-sweep-16</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3baae600a99c49e88b3c0e402928393b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594f48d71a82424187ad68712def3d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17b958ca7794b7d93a06b68e987a15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9e4379854344fbb0d9f08fd7241aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cca8788c47b448e9d7a23e0f486a56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a390f2b64ca84e41aa42edb279b00d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6ad74844e14dbbb6f76a9c0c6fbd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50b1c5e709d473a8b496429239978af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f76f33c239d49d197a1de8c1acdceb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099d47fe492844a582e2b85dc1b9b9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a8f0aba47c40169fa474d8e1b8be7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd9dbf1aa734c838a6aaaf33a17dc77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1368252993449315}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa9c666d1394636941642e12304ceed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.773328…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂█▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▆█▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.00632</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dutiful-sweep-16</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/88dfek1t\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/88dfek1t</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_043458-88dfek1t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rnf5gldw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00047176628801410994\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_045225-rnf5gldw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/rnf5gldw\" target=\"_blank\">hopeful-sweep-17</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e434133b2d4a1cb8798f82a5b040f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31da41814f0487fb74c0d37f3a4471a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bf3d4f814142ba9053b7db5ecb7e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4aaf7c16a274de5b2dd3dc804715cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b00a1ca8a054abfbde675d34a51d268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f636ebb37be4762a5df241b8cff1ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e0a514fc9144c99caf4e2ff4f86e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec4fa25e81c44e1805d82bb990a105f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.152266184911048, 'ami': 0.12281068948595743, 'eval_loss': 2.929096906045868}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12aa0fda3c04ad384ef1ef09d6d8e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.047 MB of 0.059 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.792664…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▁▃▂▁▃▃▃▆▃▃▆▇▇█▇▇▇█▇▇█</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.20415</td></tr><tr><td>global_step</td><td>1150</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hopeful-sweep-17</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/rnf5gldw\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/rnf5gldw</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_045225-rnf5gldw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5kuhugwy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004418624808569479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_050137-5kuhugwy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/5kuhugwy\" target=\"_blank\">jolly-sweep-18</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f308dc43aa664fc8b9359d49846d5d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b254187b214878a4c6567a29d56ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b5bd2d18674010b9631ddae60888e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0437823142254527a4d1f16f19c2a1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1b9cd085724357a9a346f71e7bf033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd346c32fc1d4cb594de0437340526be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356bc3a9757f4bf988878b8f093a740a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050265b654014020a3f910a898ce1067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd57495d7ec74adcaccddc5695446464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d04c5b819f4f0dab7aed32720bfb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.136849713079708}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df365d06d53e438f81a63177e9ce42d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.772259…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▃▁▂▂▁▂▃▂▇▅█▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.00232</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">jolly-sweep-18</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/5kuhugwy\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/5kuhugwy</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_050137-5kuhugwy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xbjq5pvs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00013402885371610035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_051456-xbjq5pvs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/xbjq5pvs\" target=\"_blank\">hearty-sweep-19</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3821b4eb9cb5403984d902e485897e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c2d5ff61c54bb2b1b34ff1c4ee9bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60574c2b92674eaabf2dc612e6c8cd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551417e51c4f4d85b37cbc68a2cf4dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0584966646fd470a8ef0fbd8b97bebf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0b23bdacce463dae6fe6df104e6889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fabdca1112f4d63ab670556c66f8d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ab0b88cb13417887a9c2489a7dbbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2ecc95f5254ee0be6d5b648c2ee1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87db7aee902c47d6904d1374cdac1ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5da191f59e54caa82206570f2b31498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99848abe304040fa9e4f739410551fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.961611778647105, 'ami': 0.9448300917563679, 'eval_loss': 0.2138796566867132}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2961a92b17bf4d9e972c08f3bad8187a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.372 MB of 0.385 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966167…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▃▂▂▂▃▂▂▃▂▂▂▁▁▂▁▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.00517</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hearty-sweep-19</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/xbjq5pvs\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/xbjq5pvs</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_051456-xbjq5pvs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wrqf19fi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003430940990459976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_053223-wrqf19fi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/wrqf19fi\" target=\"_blank\">devout-sweep-20</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009da53b2116414d8cee1caa35186088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1199703dd95047a482ad289b59460bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60356e6f9cea408b9e156fe02452278d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb8756b9f004051a767b28f0d4f5a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffeb0d7c01d4eabb241bff7539b92d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc726265ba74522b4d904eadbb1694f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af38da71b7c94d59b5e32356093e92be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cd508950c94963895c19a964976de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a481720fec44b58f859f52584da141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54bdafbd70dc4210af1e6253e7a6691c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a1f4e3e58849ce9ba45d416b4f5836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef43f5dc92aa450abd04e892cde45136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9497023587734184, 'ami': 0.9336245139984738, 'eval_loss': 0.25812598420275035}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24493ad6b8124ef6a2f691ef8e0a0845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.380 MB of 0.393 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966512…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▆▂▄▅▃▄▄▃▃▅▂▃█▂▃▄▃▂▄▂▂▄▂▅▃▅▃▂▁▄▁▃▂▂▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.02567</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">devout-sweep-20</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/wrqf19fi\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/wrqf19fi</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_053223-wrqf19fi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1766ufoe with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006967472913577982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_054955-1766ufoe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/1766ufoe\" target=\"_blank\">apricot-sweep-21</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e261b2c8e5214ad094449ef66140037a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3749b3f4b7e247cd9de21656bcb11f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcac79ba449c464cbd42eae772118eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c8aa1dacaf406387a3e57ccddc3473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb29228186d4c1bb91f5b19ccd80655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02744dd088c7411eb1ba87bdc762da19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a968050019d044eabcb8cc8a17b7abff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0a3ad6d5314f9f86819225ac9317b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c92b235438144849dd4224374147521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbe32b0adbb407c9849cc1cf36ba15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71bce61993fe4463b471861b0127596d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1372343813840464}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2706f625812847acadc069d04e4b31a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.774994…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▁▃█▆▆▇▆▇▆▇▇▆▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇█▆▇▇▆▆▆▇▇▆▇▆</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.077</td></tr><tr><td>global_step</td><td>2000</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">apricot-sweep-21</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/1766ufoe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/1766ufoe</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_054955-1766ufoe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ojckzoen with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006342261229981194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_060521-ojckzoen</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ojckzoen\" target=\"_blank\">glorious-sweep-22</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6735211c815e4e07b345189cc1305066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901f672c24834a589d330024c138823c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0eac958664432e86d37c25aa2c93f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8477ba5e224293ae1fd0a30fd85120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b18e432234f493d82aef1c552883c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d830edafc9414e999731010accf58ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57404e4dc1b049958ceea5e3344b0f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df939c79d664839af6bf274a690c652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69a82c82bbb4311b6d94c2e1723c345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b8f788964445b5a905e7563682d94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1e17d9cb6e44e7ad8dbd6425a1c52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.26633133056196096, 'ami': 0.20100372119391208, 'eval_loss': 2.780355154443852}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27dded6813e949e385ba9c790146d687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.054 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.780277…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂▅█▇▇▆▇▆▇▇▇▆▇▇▆▆▆▇▆▇▇▇▇▇▇▆█▆▇▇▇▇▆█▆▅▆▆</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>2.68467</td></tr><tr><td>global_step</td><td>2000</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glorious-sweep-22</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ojckzoen\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ojckzoen</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_060521-ojckzoen/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a6mf2y31 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00018452368874427905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_062048-a6mf2y31</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/a6mf2y31\" target=\"_blank\">eager-sweep-23</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0a40d6d844464389304c3ee77c03c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a7a70e87f14b72a215ff190cf048ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da759a4402db46fea55d62062ef0311f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d0f1a00e844bf689066609e919d4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936c8822077b41ce9e3aa317d6360d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cc77a9db004f66869a424e9e6084c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b96d7f290e6456394233d0f035bf3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223be2fa9875471695ad34b3a42c97da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559099314d2d45ec987d36cc1b7beca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74e867701164fad9c3be66e085f2a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c8420f88134a61bde048b2aba475ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246bd5b8c06c428fb414839ef9e74d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9584059541301536, 'ami': 0.9415429508984836, 'eval_loss': 0.2265829444571664}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69cd769b03847beb0417ee2c1647160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.372 MB of 0.385 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966224…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▃▃▁▂▃▃▂▃▁▂▂▁▂▂▁▃▃▁▂▂▂▂▂▃▂▂▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.00773</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eager-sweep-23</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/a6mf2y31\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/a6mf2y31</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_062048-a6mf2y31/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8e4pmnyv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004275799835029318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_063818-8e4pmnyv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/8e4pmnyv\" target=\"_blank\">restful-sweep-24</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15051deb3c8f4180b1037b1204036350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8da338cfea44cb289d5fb2795de1d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38aa5d5a248749a9a97289d9317781be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f053a84e1164ae094e8005d538fd4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644f99adf9874abab8ea929bb3ac2503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451b143189af42f395bc2040f6cca89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e1229b687f40cfac6eb74526939da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a197a9d6a694bbb933d894ea6492640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa97f2cbd7445af91f21c459e60f1e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac953f06825e4bacb893cabe126b5865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9f099efb284abea453841c0373ac8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1368570966818896}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ce251749f54e43b9a169d12c616561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.772680…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂▂▁▁▂▂▃▂█▄▅▅▅▅▄▅▅▇▆▇▇▇▇▆▇▇█▇██▇▇▇█▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.07208</td></tr><tr><td>global_step</td><td>2000</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">restful-sweep-24</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/8e4pmnyv\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/8e4pmnyv</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_063818-8e4pmnyv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h97qqku7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006029985007237312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_065342-h97qqku7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/h97qqku7\" target=\"_blank\">dark-sweep-25</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a42bf4db324758a1cc4d08208f3f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52538fbaed824fc498225f3d175085a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8466d0a81b4204b7b8cfe3f5969a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d45458f3a940b3a9606cf331a7cc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd744680afaf46e38ed6a791ecd8e98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e29c0cb77fc45539640228e246cd63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84320502ecf74b978129ee35f1987ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702cd72a6c1d4c96b30e5e5ffa0a678a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65444cd3af94295b285df6e79a90a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.136835534957676}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c9688c6f4242aeaa500bb4f5ea1351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.772882…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂▃▄▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>▄▆██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.59735</td></tr><tr><td>global_step</td><td>1450</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dark-sweep-25</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/h97qqku7\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/h97qqku7</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_065342-h97qqku7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oxyy3mww with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002366925372643095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_070456-oxyy3mww</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/oxyy3mww\" target=\"_blank\">fine-sweep-26</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61881eb372a14406930c39d0bd17da34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171e314db6b6453bb258be49f6ece9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c105d0344b514d7d9d0373e8b198a1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca814d0979c9474094ef6f68ded90c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5441b2eea104554bf10737e1d0425b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af15d1c8c4a4b7c97079cc7831d463d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a969de8dd74b4a8d70c9c24bc73bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709278275b9341d69341dc09effaf50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcab70bad8f4fcb8381558b36aec3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f06b37402c4bfcb7f132e9b2f249cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9593298432975236, 'ami': 0.9430845259682438, 'eval_loss': 0.2047893114874453}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e618f0709d44689fd2ae9296319922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.373 MB of 0.386 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966378…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▂▃▃▂▅▄▃▂▁▄▂▄▂▁▂▁▂▁▃▄▁▂▂▃▂▃▁▂▃▁▂▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.04685</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fine-sweep-26</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/oxyy3mww\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/oxyy3mww</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_070456-oxyy3mww/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4dkarkiy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001986214915720442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_071813-4dkarkiy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/4dkarkiy\" target=\"_blank\">firm-sweep-27</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73fe232bfbd40b6b0095b4ed96fe693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a56c7fd4d0f4a31a59bbc0fc0139168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7566007e004a98889ab24ede7a6072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ca392b56fc4881be2d119f67f6de57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e374635c32145789cf551643dafe46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593a15a240244c9aa8326ac6cc753a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5b9974b1654a40a7e9902d40521518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9579587629855786, 'ami': 0.9413942048930919, 'eval_loss': 0.20787370048744983}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcce30842a246ac9e0b01f4f10f33a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.371 MB of 0.371 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▂▃▃▂▂▃▃▂▂▃▂▂▂▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▆▆▅▄▄▄▃▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.01703</td></tr><tr><td>global_step</td><td>850</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">firm-sweep-27</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/4dkarkiy\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/4dkarkiy</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_071813-4dkarkiy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gziozcyq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004110679681917317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_072522-gziozcyq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/gziozcyq\" target=\"_blank\">unique-sweep-28</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0df09b77d424c55a95ca8787fbec8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7092e7bcf0740f1aee47dbdb814a782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd6b50283104d189fc5cf4b2b42ce57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d32eaa705c54d0fbd889e419b359728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24bb8a2ad2545e7a943bab3a2f00119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4957bbbb828c418581363f627f9ad444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750c21b153f744d790303ecadca23a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f625a9215946c48beb8e33f427eff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b13f33ecbd4e7487220617329bde0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da69cb06699f4b119c1330e85ea15391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1485f5efa37549eab09163c1cd614035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f703d96a85b4b0c8ce1fa4440069349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.136756839621108}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adc99f4d68545e1a4d484d40cdc2bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.773844…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▃▁▁▃▂▁▃▃▃▄▃▅▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.00888</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">unique-sweep-28</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/gziozcyq\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/gziozcyq</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_072522-gziozcyq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cl8a2roq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006327580640080339\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_074253-cl8a2roq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/cl8a2roq\" target=\"_blank\">feasible-sweep-29</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8888a29bdd4569aab436f22c74a8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95f9ed0d0d24e8c918d45b7432f48f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48613ef438f47acb79b8e62b5082edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d99a0f18ac2434ab77e1c744e7cd5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacf528b80ee4f0c9e4df0964f2cf0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32aa658e8f0c42348a3266fcf6dbc5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4d2ed3215c472e97ba4aff5f552965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b360472408a94628924610756977c7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46abb922ac12406696a4040e6ce290e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef71c273d0ee4a96b1697eb06ccdab20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80572c8d9924a66899f4950a2071fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fb1d7447cd4ea1b57fce0350a2a5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1377672960668086}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f019cac72d334e819f9422b7c0d15908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.772910…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂▆▆▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>2.99329</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">feasible-sweep-29</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/cl8a2roq\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/cl8a2roq</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_074253-cl8a2roq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d0bd45on with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007484576858487095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_080021-d0bd45on</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/d0bd45on\" target=\"_blank\">silver-sweep-30</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d18829e56cb4cbcad9d79322ea372b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f5703d08e44cf6bf7499123bc1bbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15338592544a448cb33ad22286691613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29b17373c0a4d84a7648b38bf3a4863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44505df2239b44aeb00a2c822ef581d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba05d83e0cdc4559bf760cf11b442798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdaad1620bfb4162b9f7204b7a58e5f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5c07b5b22c44569d65170b22fc9a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16f83d004324999a4a2881e801ee7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9f6b002846415d947467d1055cb2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.137402847460455}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123cb0a8dac745888329ef26a3176c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.773547…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▃▄▆▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>2.99762</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">silver-sweep-30</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/d0bd45on\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/d0bd45on</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_080021-d0bd45on/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fxjxpifw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002768566016232417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_081339-fxjxpifw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/fxjxpifw\" target=\"_blank\">frosty-sweep-31</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c39608fc9824131b09fbfd7a05a17fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870b1a886ae14bbf8344843e9be66973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac4e3b18b23499a9b13e4c05c245fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616ffc561b5646649ea4dda1944e306c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea41189f9a9496a911bc76360f4576f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae27a45e05a4057a19c886dc87cdec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2dadf1003be40d1ac4fc38e39f63a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9479026207733511, 'ami': 0.930484873008817, 'eval_loss': 0.25134751886846274}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c829d32cd5419cae6bc22d6cce19b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.376 MB of 0.376 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▄▆▄▃▄▂▄▂▄▃▂▃▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▆▆▅▅▄▄▃▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.07149</td></tr><tr><td>global_step</td><td>850</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">frosty-sweep-31</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/fxjxpifw\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/fxjxpifw</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_081339-fxjxpifw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ytfxkadb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008507781052353599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_082047-ytfxkadb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ytfxkadb\" target=\"_blank\">smooth-sweep-32</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a4eda13041494f87a31969c42a8693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e018e6712dd9423bbb79c3c428795736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73890b8cb12d470e90f4a216e60b92c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811b75e3c09e42dcae88bf0f29d232ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9267a7e981d24c2eb62ad633b091dc6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7020e0f52fe04dfdb87a867219de4026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c614329119f447aaf469ebe8d193ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a36486b4da4dbdb83c4621bdd37fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5f69373b0140988c99a61742381de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a9135c68904936b2d9aa0bb4303219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.137676687175056}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ffcc3537c2497683f71538607bdd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.775153…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▁▅█▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.0054</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">smooth-sweep-32</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ytfxkadb\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ytfxkadb</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_082047-ytfxkadb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: isfdul8l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00012497515102096054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_083416-isfdul8l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/isfdul8l\" target=\"_blank\">deep-sweep-33</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922d7b26d3474bc986ed736428b57097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f2cb8354ad4638afb00cdb945c7483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928adc247db64798beb5d4c4b8af23d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252a71f2332a48619d58a16f3c3b589e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8489e40ce5c3417c8dd926bf24f7ef24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407dd09bdaeb4c3aa749c3c17c653584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b591c65263514e3584277fdeeb201d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1991ac7a52c24e3e9cc592b92f0c36b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514e2bfc60b149138cee7a163d777fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9634304766142839, 'ami': 0.9484892730904939, 'eval_loss': 0.1796872206928394}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f55b64e6a849a993ed988212f7431d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.370 MB of 0.383 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966280…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▂▃▂▂▃▃▂▂▃▁▂▂▁▁▁▁▁▁▂▁▁▂▂▁▂▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>▄▆██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.08928</td></tr><tr><td>global_step</td><td>1450</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">deep-sweep-33</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/isfdul8l\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/isfdul8l</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_083416-isfdul8l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fakufjhx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006076299536522934\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_084533-fakufjhx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/fakufjhx\" target=\"_blank\">sage-sweep-34</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a2e298089745ce8e6a2933a5ae5677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ceff28857a4e7bb149c11f7c4f7930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281c5c0801554a859acc604ea131c7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9469470f228a4a98b2838bb42f85bdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34dfa851bfe4957a1c3ad365ecabc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e87d839c9e4bc98e7a303b0c3f34d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0eb0fbb681e42229f1fea71dbad2457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2e8e3b032c4c85be2bfb420cf777fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bffe6de3c94c9a95711b4a3da5825e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0961a473c9c405eb3ea047b29f1fa22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b8ad020d784d8b970e483bf88a07da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b6ec614d7a433a964198b617c59fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1361413698425817}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c5ecd153db4d09a1e6eb73fdc22e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.774754…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▃▆▆▇▇▆▆▇▇▆▆▆▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.02179</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sage-sweep-34</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/fakufjhx\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/fakufjhx</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_084533-fakufjhx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g3yquf3b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006858696725961084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_090303-g3yquf3b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/g3yquf3b\" target=\"_blank\">eager-sweep-35</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e930944952744d2b7ea3dbf2b341445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a98f5a694254befa8ac703c8f8a7091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5882a5985eeb4509893460ac68237525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077cad45ac24418e882d6491e86b730b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70141335acaf4fa59eabb5ae1cecdd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ae68f34a3342f48d7a77b4e748223e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c914ad3a9e9e4c7abc95a79b09c7c9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c52db1d2374275aa7116e8933224ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1382094338997124}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6126f0f434484787bc8c88f16d870644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.040 MB of 0.052 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.772316…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▁▃▃▇██▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.22153</td></tr><tr><td>global_step</td><td>1150</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eager-sweep-35</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/g3yquf3b\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/g3yquf3b</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_090303-g3yquf3b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wzqlg7cm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006619281383279779\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_091217-wzqlg7cm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/wzqlg7cm\" target=\"_blank\">usual-sweep-36</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68fda7a3e0e4ae4bc121bffa4ecf677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7668072ad18d4d779e2a6d6a5d2f2ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381149178b0b4f49b1c5a2e87c2c3ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a68c33598c54b30bb8b8629ba12a6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31b04e9448f4332bbb722d5a43a4bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24aa696da0bd4c829d8166477a96e413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc71e096ecec4593afeb7c1f21c2d277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da2d2b38417469c9a75713ff2dc5e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9b0c30f3b64846b98404dca7e36912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a8d2999fdf4221a1500229603194cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f96529aa694494db540f607156fc344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.138184768637431}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5bb7e51b9a492e9a81cbed76063868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.043 MB of 0.055 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.779980…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂█▆▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▆▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.07376</td></tr><tr><td>global_step</td><td>2000</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">usual-sweep-36</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/wzqlg7cm\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/wzqlg7cm</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_091217-wzqlg7cm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gor1mn2c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.85640111066423e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_092741-gor1mn2c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/gor1mn2c\" target=\"_blank\">rural-sweep-37</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f06a67c259243679fcc409ebb72f5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658e2bd76fc04b1594abb381e5ce9b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d856e5a873f2425eb85386270dfcba9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf7b47ee9194039b2907fa12b6c63b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d730b6149e74d27acadd710d3de045a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a541307457c24c58b01938489702bd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc9c218ce154482b061efdc368caff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f934a1b1974eca88a53bebd5f141c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.959322693309557, 'ami': 0.9423185241967348, 'eval_loss': 0.19851486977586633}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d4ade343534e2aae69c59c3d4ad765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.370 MB of 0.383 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966249…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▂▂▂▁▂▂▂▁▃▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.06908</td></tr><tr><td>global_step</td><td>1150</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rural-sweep-37</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/gor1mn2c\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/gor1mn2c</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_092741-gor1mn2c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k601n3n6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00046924852416885103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_093659-k601n3n6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/k601n3n6\" target=\"_blank\">celestial-sweep-38</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36392e9c71f841e3a9b8470d688f9f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa5291271794e7aa125d3ae6aaaec0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36462bf2b34422aa5f3a904b8f669b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362444654f4c4a1584592954a69643e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4afe60cd8e5470285013b9e2f0b0a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e273bfdf1a4cb6b53416687664d286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74833b68bf749eb9997d13589f143e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff1b375e38d4428bcb69612b148b20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abf0f4e62cf44219c49d9b6e08c11a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b42321ff3d43699292e771bf359d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.10116538534729892, 'ami': 0.13829147959854018, 'eval_loss': 2.8992789045641922}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590b393991c742418742b4cf0d7636bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.044 MB of 0.056 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.782891…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▃▁▂▃▂▃▃▆▇▇██▇█▇█▇▇▇█▆▇▇▇▇▇███▇▇▆▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>2.81104</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">celestial-sweep-38</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/k601n3n6\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/k601n3n6</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_093659-k601n3n6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tfhdz1i3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 9.886895495178368e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_095018-tfhdz1i3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/tfhdz1i3\" target=\"_blank\">pretty-sweep-39</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629b8004838a4a9c92b4faf6e2ab3e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d200e2d8b9d44f729e0efa4b8dd275df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10f632462e742c68a5fbd13e70ea02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f349f79444d14b169e648b34f8850bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43dd9e20beaf48b5b434d8ebcd7cd4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7301233de3f48c1b8cf13510847939c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217e94bb0df045c08584d55e057be5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975d3b69a97446fca6c5b214df4c665c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427723e1c8cb41df93e686286777c95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8587d80347c64a06a1447c5799708064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6304b0f6d134da19e77f6136f251483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2697b1e323544b808b8e7b2935860416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9611453017472547, 'ami': 0.9443632189148035, 'eval_loss': 0.1992350105337056}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9285f533e0b4c3d8274b77f20b0596a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.370 MB of 0.383 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966323…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▃▂▂▁▂▂▂▂▂▂▁▁▁▂▁▁▂▁▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.00504</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pretty-sweep-39</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/tfhdz1i3\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/tfhdz1i3</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_095018-tfhdz1i3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6eqhrh0l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004469685415261515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_100758-6eqhrh0l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/6eqhrh0l\" target=\"_blank\">crimson-sweep-40</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb0f50ef46749199df30633c22227d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e42cb5057946f8bde9a93856c16fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c1eeab54dd40e9bc62888ee05f6ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7629eb93790493c94b8f7e5ff4370b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb7beb8fe274bf1a3b8fda337d941d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a936a565b042eb99437820889d80e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796bbd7217154193b57742f106d149d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dd0c267a8d4c009601e27fb9b5f2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9264118695984374, 'ami': 0.9131576171924638, 'eval_loss': 0.3477125859137663}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19389164e0d040fb965dd9fb13b85155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.394 MB of 0.394 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▆▂▄▅▃▅▆▆▇▃▅█▇▃▂▃▂▂▁▂▄▁▂</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.24831</td></tr><tr><td>global_step</td><td>1150</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">crimson-sweep-40</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/6eqhrh0l\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/6eqhrh0l</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_100758-6eqhrh0l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: la64zsce with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004145049117512149\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_101712-la64zsce</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/la64zsce\" target=\"_blank\">easy-sweep-41</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acea83ed4c1f45808376cf599925611d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc110e22ae2b4aa68fa9a2900f720a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24472b6fd4004e4a9d553032f196ebc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0be6fd5b4542c29582cdd537ae9d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8484ed5763eb4c15ac7461e9420839e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da285c5bb05446dbde0aed19d9752cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a579200c6fb415980ce0ed43fef0336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.931060524066268, 'ami': 0.9111913518414689, 'eval_loss': 0.3155591282289462}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fbe58c217d4bd4a1e57b7ba0edfa2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.378 MB of 0.378 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▆▃▄▅▃▃█▇▄▄▄▂▄▄▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▆▅▅▅▄▃▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.10437</td></tr><tr><td>global_step</td><td>850</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">easy-sweep-41</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/la64zsce\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/la64zsce</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_101712-la64zsce/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kbi7fbpg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005955665669356235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_102422-kbi7fbpg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/kbi7fbpg\" target=\"_blank\">proud-sweep-42</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7315a66e011345a3b3d90a77eed8ea91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0e59b902ca4fc6803f1c2744218434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef137d8d8eb74f24b8aa1bccfeda837d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1555d60512eb49bda98559885eed8b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff5496d189c4d008f79a5be6a4bb42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1672d904f71476d8cee437e355733fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce25ba0684eb4dac8ad878d47a8bd8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc58a80dc05406a82f3a3961df6f122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c964f257dfd447b1b5944a460725a6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3437ed448a9e4486bb337f2e70a999fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f09e0491da4bbd9b1291464b9beb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f594a495deb64d59a9bee7ad06c4c612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.1978342417604074, 'ami': 0.17841441226502103, 'eval_loss': 2.8211811285248327}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1336e6808bb0400baa62acb5d28925b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.054 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.777004…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▃▃▅██▇▇▇▇▇▇▇▇▇▆█▆▇▇▇▆▇▇█▇▇▆▆▆▇▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>2.77476</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">proud-sweep-42</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/kbi7fbpg\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/kbi7fbpg</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_102422-kbi7fbpg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jlqmnk5h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000270953734863853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_104202-jlqmnk5h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/jlqmnk5h\" target=\"_blank\">prime-sweep-43</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a7ea3d78a54c17bc914b503b069b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1932de2adfeb426f8de4d514b7c98c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cac2e9efa549e395f86766458e5296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b405c124d9140d7a3f929752fd4a066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7033d93d33454708b6f29b8feea0d176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95406db2de3b410bab5e65b70c9b324a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e516e8d45048f59246e51652324d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a07f67645240609c6c97d69d16b21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9510980370968434, 'ami': 0.9350184814927266, 'eval_loss': 0.24678905510513233}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee369ce3d6fa4f9fb0c7d244fa997e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.376 MB of 0.389 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966096…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▂▅▄▂▃▃▄▃▁▄▂▂▂▁▁▃▂▂▃▂▁▃</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.27751</td></tr><tr><td>global_step</td><td>1150</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">prime-sweep-43</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/jlqmnk5h\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/jlqmnk5h</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_104202-jlqmnk5h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vwi73t9p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006214322996545976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_105123-vwi73t9p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/vwi73t9p\" target=\"_blank\">young-sweep-44</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e19948e9bf4044a1cfc13924841364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0922df7a0aaa4da4b3d33e04241ac502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5814753d0949f6aa9a16ef40e922fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb1bb520fdb43ab9a80503e4148c85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9a865545d643368d9afd69d46c69c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822985d5954e429f8145fc32df77b210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02fbc0d849c434ea9372aabdadd204b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bc389a95024adbb2d500cc0df6a079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab684b3b18c421fa32d680a276d2e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f79b57e0ff4a80b309405984866754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1738454faf604bcbbc45502b03d5ec34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b05529cec4d47128740b594fcbb2ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1367961033103393}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46d86bf320a462da12a22d6f7accc09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.773259…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂▇▆▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>2.99973</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">young-sweep-44</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/vwi73t9p\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/vwi73t9p</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_105123-vwi73t9p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mirvafxs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008051021520519162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_110905-mirvafxs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/mirvafxs\" target=\"_blank\">glamorous-sweep-45</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cdedc638314410a2f714e4acc2f620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c11ac2241e46f0bbbe0aab02772916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204335fb039649a9b7afc6707b60981c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1781ec43cb4acbb45c79a59652d4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32feefe7e5eb4116b40d97481c9ea743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35504e18796f421cac417de076683d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596e3d444c1549738878ccd38bd40e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fbd640997e4bd9b1a451f887a3bb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a70cb5fdb345868abd52c436f8b129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4f3522d67947d6b284da1e92311f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde3bdc4fea34d5ca0537814ebd824b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6892ec3c4a34e148c89cd107b3f5300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.138149866943097}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a64353b407041d99030b8184f34872d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.773524…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▅█▆▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>2.99423</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glamorous-sweep-45</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/mirvafxs\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/mirvafxs</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_110905-mirvafxs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yc1019o4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008771261817184759\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_112640-yc1019o4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/yc1019o4\" target=\"_blank\">peach-sweep-46</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c75a3d2bcc4b9888289d18c536872a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6091acfbd1a14700bf87b005d8c8de23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2fa57c10d447409d1d1a613ce93b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63965fbf07a4fbfb3ccf613d0869e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610ff81edb49471ba1a55f57c0fb34db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207e995b2e314ca394270f5659468f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8e9d6015334936bd1bce2c85b86a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.139056291776834}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b872dce7b5bd47c5ae940a01419263d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.044 MB of 0.057 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.786265…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁██▇▇█▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▆▆▅▅▄▄▃▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.11572</td></tr><tr><td>global_step</td><td>850</td></tr><tr><td>lr</td><td>3e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">peach-sweep-46</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/yc1019o4\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/yc1019o4</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_112640-yc1019o4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s3w5kjwx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008898935927579957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_113349-s3w5kjwx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/s3w5kjwx\" target=\"_blank\">peachy-sweep-47</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f081e97614ae4d9cbc5c336df6af563a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6dc09cb66a41f8afab4f8a567a2e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d03cf5e4afc43e3ab94603257739158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24901f8558f5446987a02a80a6b16310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2923cc05c7324fdca49309a96bd79f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd307ddfcc740a488b5b96934dda5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5946e029204acd93ee449fe2135988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb571332c1194ae4b8820485d93b92c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1379746899162373}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b5e45168bd478fb5c4aa063d117f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.046 MB of 0.058 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.793110…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▁██▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.22598</td></tr><tr><td>global_step</td><td>1150</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">peachy-sweep-47</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/s3w5kjwx\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/s3w5kjwx</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_113349-s3w5kjwx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jjzv0kj2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008326130018841538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_114310-jjzv0kj2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/jjzv0kj2\" target=\"_blank\">exalted-sweep-48</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97e044e0f4d4165aa0a95adb6918d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b786c09f0e44e8a63f2a392f1baef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae6517cf8464a7a808406873488a713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836bdbd5f80a49acbfb54edf987673ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fb1b12d4144306a227a927be7ceb7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc89f959773e40b88225fbabe5c46c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d14fab91334c4ca485b39579c469bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.13934909273259}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f333f27947b44b14b069fb783b5394c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.041 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁██▆▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▃▆█▇▇▇▆▅▅▄▄▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.10229</td></tr><tr><td>global_step</td><td>850</td></tr><tr><td>lr</td><td>3e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">exalted-sweep-48</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/jjzv0kj2\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/jjzv0kj2</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_114310-jjzv0kj2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uhuqk967 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00034758927525203203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_115029-uhuqk967</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/uhuqk967\" target=\"_blank\">fluent-sweep-49</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f935166d1d443b2936f91a240e9fba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7520b4fb7640478fb28986c81a0eaae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb25720498145838f42dda150a10def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a732117fb853465d9fe14eb395947917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52710bf31d704752801bfd0eed02b18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381e66a8940c4fa5b69cfef440559743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49adc38eb984ead91057db261379112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1612ba0a4144bc69560ccc9fb29339a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9446958580416512, 'ami': 0.9262771285330316, 'eval_loss': 0.26390468053954985}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3011a0e8485d422e85f1209f0e1ca74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.375 MB of 0.388 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.965795…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▅▄▄▃▃▅▅▃▄▅▃▃▆▂▁▂▄▁▂▅▂▃</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.30806</td></tr><tr><td>global_step</td><td>1150</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fluent-sweep-49</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/uhuqk967\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/uhuqk967</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_115029-uhuqk967/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qztixgwc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007150727849711285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_115944-qztixgwc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/qztixgwc\" target=\"_blank\">fragrant-sweep-50</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbef066d16ab4031be9fe4273aae46a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38584df1e7b428fb14cd41110eff560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bab8b310adc43cd9fb81b33ebd44a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8844838425473aba420a372ddb638c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c710432044c345ef8071f85399f5faef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48620bb9554b42a0ae0b6fba2706ae46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcf3f77f21242588414ea778dc03b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c123c2a7734dfc84db900f69fd8bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e5ab3e43c34ec7a718b54d1e4f1bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83dee5b3381846d5b8b1e9bb6f340ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0798a52dbf624ab5ac7e3346d52bd635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28b08c9e86544f7a331e840ab1c4d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1369553398840204}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a792cc892e244855a151a847cef61159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.772168…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▁▃▅▆▇▇▇▆▇▇▇▆▆▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▆█▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.00345</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fragrant-sweep-50</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/qztixgwc\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/qztixgwc</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_115944-qztixgwc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4uicshy6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005375199262627289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_121717-4uicshy6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/4uicshy6\" target=\"_blank\">spring-sweep-51</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dda6512c5584b2aace87b783e0ef20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a8224454d8419eb580728f4cb48890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1251d5295a2d49fdb6a549b55be1e940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5833da46bf304103ba7a861253649e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bd9f85a59747e6b67bea4632b32a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b797918756e488581cf9dbeec151829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f835ccd2c24dc9aabe9341f69ad48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9394c7c27a4cd9b1a777182038c6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6985183dd0ad41b9a21aef4cd8aedfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f82dc101fb4ddc9640a5aaac9192ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.13782031921177}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84536db5f0f24c9da83fcbf0e3564372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.772747…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂▂▁▂▄▆▇▆▇▇▇▆▇▆▆▆▆█▇▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>2.99127</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">spring-sweep-51</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/4uicshy6\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/4uicshy6</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_121717-4uicshy6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uy58mgqe with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007095259903378637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_123034-uy58mgqe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/uy58mgqe\" target=\"_blank\">crimson-sweep-52</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc428276ec174de5a3521f4abe3ffe10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9aedf3180e45dcb494858fab7cf6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67452a5de13e40af8752006dbe09e747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa887a99170248cc9b76838d59e01490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90f8723af3248e480fea1fdd45fce4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e968c22f45468992290ad489bc339f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83246b22e75248f99bfdecc0bd3ba1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e4bcd691b441e1b6a54e14aab86c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be236f1f1ad4fdb8f1d10d273c97d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1363279573696174}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282c834515d442e592e6e3a1a928b686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.773451…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▃█▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>▄▆██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.57544</td></tr><tr><td>global_step</td><td>1450</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">crimson-sweep-52</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/uy58mgqe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/uy58mgqe</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_123034-uy58mgqe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ln2fo0r1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00016408443648388614\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_124149-ln2fo0r1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ln2fo0r1\" target=\"_blank\">olive-sweep-53</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee3df7de9e44ec5b8994746fe1c783c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d6967b7bdf4bac8ad81778561fca87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dd32ad020d4bcc93eb951099c4fba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9f325a374a416280dab1824a61abd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea98fb56ffc54f9799be4c4ded4a2ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a48dd6add54eab9465c5c3667be7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2e27650ae54f0583c6be5186338f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8076744bdee4c328708eb54cecf9057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e00746eeaaf461fb4ed1cb2094b7928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3978881b8abd4823aa339e440a8c7224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1c366a740d422c8887a3d38e99d034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3cd1d027bd44ffbe1349e43903e7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9556630050120086, 'ami': 0.9377909363115922, 'eval_loss': 0.22508973679489286}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06a01ca2ac145509f2625091af62ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.374 MB of 0.387 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966313…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▃▃▂▂▂▃▃▃▂▂▂▁▁▃▁▂▄▂▂▃▁▂▂▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.00687</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">olive-sweep-53</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ln2fo0r1\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ln2fo0r1</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_124149-ln2fo0r1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fvobc275 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006858754628600318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_125921-fvobc275</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/fvobc275\" target=\"_blank\">decent-sweep-54</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5be68803f3490e97ad62049387675e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f947c663d97841b68fd91ac366d70150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac5ca4be0ce47fe9b59edbbec2422f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb238187dce449aaac52bc73d4c4315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3a024866a7402ebbda6cd23630af22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7d0badc5f4494d9e7fde8e5963da5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a859d01952431eb4231f9d96dea08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5743c71e117a4da69c9d64191ec5fd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145b0a4071924f89bc32a471621d6abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.137379439835696}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329c124d46834835b38f5a5f2dcc8970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.054 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.777461…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▁▃█▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>▄▆██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.61621</td></tr><tr><td>global_step</td><td>1450</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">decent-sweep-54</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/fvobc275\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/fvobc275</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_125921-fvobc275/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jr7zi4hf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004821414021608861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_131039-jr7zi4hf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/jr7zi4hf\" target=\"_blank\">fallen-sweep-55</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d4e2bf9bf94964a169d3e43ae28f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e360cd452e84230bc197d1d4cee1e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23684c7250634a66adae451cce1a6d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2051d018ce4ed98a622d27e5f6c3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40462daacb5b49b680b51dd6862bec82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2708cb669c1c4bdba85be7c461af484c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5715b13c5de449aa175470d3830db54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9136577005597033, 'ami': 0.902022286879789, 'eval_loss': 0.3677181923102677}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2210b0143c964b8fb99edf8c3385381c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.382 MB of 0.382 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▄▂▃▄▂█▄▃▄▅▅▂▃▂▁▁▃</td></tr><tr><td>global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▃▆█▇▇▇▆▆▅▄▄▄▃▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.49265</td></tr><tr><td>global_step</td><td>850</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fallen-sweep-55</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/jr7zi4hf\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/jr7zi4hf</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_131039-jr7zi4hf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4pb5c9lx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002515444640377945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_131749-4pb5c9lx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/4pb5c9lx\" target=\"_blank\">giddy-sweep-56</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0456e1c661f148cdbc73ae3b8fe963a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e293bdb2acbd4450af2d21b0e622cf47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9366f9d8db6f45179c11d8f6ee78fa4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56964c5f8ce43558126f6025f87c664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b010e986cee147f7a4a99e575a9fa297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb861389524407c8118171c2ad53a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986c16b3ab9e437abe04c1dd2adf6280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2b510cea8e4df6af4814961d30d3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73168c387b5f4de4a15977b5ad09f03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6376dfc6bd7c4e11b3ed99943142593d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cc9281ecd54a83b3f36b6c5692c755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9533713690839742, 'ami': 0.9352474300468738, 'eval_loss': 0.2239077020039673}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8dd1b169ee4b75bbb9ab2d3e59e9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.374 MB of 0.387 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966032…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▄▄▂▂▅▃▅▂▄▅▃▃▁▁▂▄▃▃▃▃▃▄▃▁▅▃▂▂▃▂▁▂▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.01082</td></tr><tr><td>global_step</td><td>2000</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">giddy-sweep-56</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/4pb5c9lx\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/4pb5c9lx</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_131749-4pb5c9lx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ysy582m2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003138446538513223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_133327-ysy582m2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ysy582m2\" target=\"_blank\">laced-sweep-57</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af308b5619a48b994b89d659ed0e4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99909856f7b499089acb77534f2ec8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d86dff405b84e08903157f987ba5dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e53d0966f144314a48f2bd1da0f7d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c13c630ebab47dd8500bfeeef630671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabefdf2fe2a43e3bd88be00f7b310c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9d94ad43414c269c2d07bbfb2c673a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f4d7c9dfdf4b7ab7d72ed81611cfc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b32a904a71422abfa97f6cf2f1e363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb109344e6640d9a34a20d5ec033584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9488066862094802, 'ami': 0.9331592824211646, 'eval_loss': 0.2519177054519096}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e2a9b7a2ce4ad496a326ca03edc4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.379 MB of 0.392 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966651…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▄▅▅▂▅▃▂▃▅▅▄▃▄▂▁▂▄▂▂▂▂▂▃▃▂▄▂▂▂▃▂▁▂</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.16563</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">laced-sweep-57</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ysy582m2\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ysy582m2</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_133327-ysy582m2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: edxdz3jo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00020491691907887692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_134646-edxdz3jo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/edxdz3jo\" target=\"_blank\">eternal-sweep-58</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1598b849f49949f8a609694f3009fec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a470cd9fb01040d2af53d1ebf8b790d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce56320fa2464295bbc33df2817cbb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e8e58c5a0642528b8ede2d75108101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc625d368d204b14888bfa5c114c4694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7278f9744890433baee831dea739ea05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556a6ae7bf7f4f0da5730ff9e481e1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13f67d98ebc490691c46d88f0969fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8c7476867346e4b58c96743c077ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0c90834b6f47ce8d7ca3cef45e337c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9570388637293225, 'ami': 0.9409772533671599, 'eval_loss': 0.2063491550302997}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4418c4f45ed46ecb7fe517efaf87f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.373 MB of 0.386 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966493…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▂▄▃▅▃▃▁▃▃▃▂▂▃▁▁▁▃▁▂▄▂▂▂▃▁▂▂▂▂▁▂▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.01125</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eternal-sweep-58</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/edxdz3jo\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/edxdz3jo</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_134646-edxdz3jo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dp4kx8wd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007995786082712577\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_140012-dp4kx8wd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/dp4kx8wd\" target=\"_blank\">dauntless-sweep-59</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88816936ff4942a5872c81ab54534836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32410bdef98f4ab188bd2e76fdb07f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dfaee2599341198d7415dc3369b0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83477df05601426b9dbed8731fb1c795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47adaea3ad24e6c96e39cf8027f9d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24df76975844351827241b773f66b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429a3f023f0e4b8287314c0218f60839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e171c02412c84680899b2636177b4243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1cb0fa61d84f8aa7527bfd92608931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccd86b838c741e2bc6df41d635de91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c123cf37f624f809198005a6cb75af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.17223226023360533, 'ami': 0.22231922802380497, 'eval_loss': 2.733867254453836}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52264e92e15044b581fa33f645fa08aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.055 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.776384…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▃█▆▇▇▆▇▆▇▆▆▆▆▆▆▅▆▇▆▆▆▆▆▅▆▆▇▅▆▆▅▅▅▆▆▅▆▆</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>2.88094</td></tr><tr><td>global_step</td><td>2000</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dauntless-sweep-59</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/dp4kx8wd\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/dp4kx8wd</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_140012-dp4kx8wd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bwsclka3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006757641794882409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_141542-bwsclka3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/bwsclka3\" target=\"_blank\">leafy-sweep-60</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73276e4088e4d1f92fbdf93799b0554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb6ae85b06e43039e48e5496f43f733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271c20f76cf442a29e01e54b6c67edef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2f84c04dc34bf39177d840cc941f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485266499a64429b8ad5645c754b0185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f231c2ce730d4230b79273ead2b7730e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29a0174bd5140f4b1e2f444986e7f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e75da661ea4c89b9ccb5023c5eec3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f697c4820f1d4b388d5e47c077e6cf5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a30570356c493b84c18945bfc96081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9359addf7de44478a5308ce4bb3a319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfceb2ddd6f470d8e9f85e87d20ad8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1366657268550386}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5f9049cfd24b588cbc42242ad7186a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.773400…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▁▄▅▆▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.0101</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">leafy-sweep-60</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/bwsclka3\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/bwsclka3</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_141542-bwsclka3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j11jt7k7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005042796224162875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_143317-j11jt7k7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/j11jt7k7\" target=\"_blank\">worldly-sweep-61</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fe2727d0a1453093cd51bd767b42cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c093da45e5a547998e1ae79d5a601ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9c3c24beb5406589f233fd00adb56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6822d8a6c740d88138a730ab26c2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3851079f6df7429dbff004cb3c58604a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda3918c7bd3489891178e5679adb18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5acbe0b31644e1ca30d26e8cae4ad2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de396a936174e3c902f9555b2498a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e47fbc06d2d4f53aac0bd8f0383231d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1279df1a125c4dd0a6b678b445445cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1368914101132}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606c08fe9bef4d70b4551e9fb8dc64ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.054 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.778531…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂█▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>2.99478</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">worldly-sweep-61</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/j11jt7k7\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/j11jt7k7</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_143317-j11jt7k7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wmcy3yrh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00025689790794506583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_144640-wmcy3yrh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/wmcy3yrh\" target=\"_blank\">floral-sweep-62</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb44e98cd944681b94a4f805a5d4583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245307ecdda64cc98489eb2bc8666a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8973c78fed740498dbe47909c96c9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e9a44660354426988d26cb9f027bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033f8dc7252a4133b8e45dd6f40c5022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469b6ad83e7a4649a53962c8a07e6522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b49658b58824b618dccb030fa487e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376b674a227648d1ada1211358acc70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33ce9b9eaed4f82b2b2027c5d201bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9542944923052405, 'ami': 0.9365389275681413, 'eval_loss': 0.22084381107458545}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d504ee09293c419d90438e980340f280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.375 MB of 0.388 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966208…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▂▅▄▂▄▃▂▃▂▄▃▂▃▁▃▁▄▁▂▂▁▂▂▂▁▃▁▂</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>▄▆██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.16557</td></tr><tr><td>global_step</td><td>1450</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">floral-sweep-62</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/wmcy3yrh\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/wmcy3yrh</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_144640-wmcy3yrh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 78a3ajj3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007372544159636754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_145802-78a3ajj3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/78a3ajj3\" target=\"_blank\">feasible-sweep-63</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4718feaf7941689fc8c6fc05788cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4529c40b47644f5885023ade38799bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7c503cc7124f128bf76b41bd95ce98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269e15a5c3d44bdd814edd989c5afcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9461e9bb66419bbcd5e1924d884cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2bed14bafa489aa450742d329b797f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4588b66d5794cb79eeb227bfff0aa0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1397155551975944}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c6c2b7310144d78ddd761b39c4058c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.772575…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▅█▆▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▃▆█▇▇▆▆▅▅▄▄▃▃▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.091</td></tr><tr><td>global_step</td><td>850</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">feasible-sweep-63</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/78a3ajj3\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/78a3ajj3</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_145802-78a3ajj3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kuc35jxs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002477471278340822\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_150521-kuc35jxs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/kuc35jxs\" target=\"_blank\">zany-sweep-64</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f926469e3d1b45b29e302d6af511bdf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f0121729134fa6b0092a2255779ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2f71d94583437594c3a9bd34efc2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601f1d71785f40c5830128daf84d9898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5492726a60844950927f613b1a491ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c69a17c37b4518afbbfc78e7f085d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154420e877bc43f6b9921cb0c9ef2c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9561296406889028, 'ami': 0.9399329224012127, 'eval_loss': 0.2100685645675741}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5fe8fe44224daba4621994d4ab6631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.374 MB of 0.374 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▂▄▄▃▂▄▂▄▃▄▂▂▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▃▆█▇▇▆▆▅▅▄▄▃▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.08197</td></tr><tr><td>global_step</td><td>850</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">zany-sweep-64</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/kuc35jxs\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/kuc35jxs</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_150521-kuc35jxs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4hkmp5ux with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000591110777491831\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_151232-4hkmp5ux</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/4hkmp5ux\" target=\"_blank\">stilted-sweep-65</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbc40f91cfd4dce959a6bfbd411e050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b8960d9a3c4fc98ac7c88d815c04bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87b79c64d4246fa9d8ce22d2f4cf5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c43622e0a84b808b10ea4f7e5ceb3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92fbfba7a76457db4024f47f9e6d585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad7ca202aac4143a59d5a80a2275d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f9afdabe094dbdbc7eef9b7bac28ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e8896ed5e9454e879ad55d878d54b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b14497cdc74742a055310a843ed2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1371828690427277}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9cf100e5464066b0ad81a2b9af0dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.772015…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂▂▄██▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>▄▆██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.61603</td></tr><tr><td>global_step</td><td>1450</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">stilted-sweep-65</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/4hkmp5ux\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/4hkmp5ux</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_151232-4hkmp5ux/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: benyx979 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003658186457475479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_152353-benyx979</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/benyx979\" target=\"_blank\">ancient-sweep-66</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feec59b317a54e348d5053b2871b3d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd22fcd547c4c5689c039e215023b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7518ec265c754119b4338c4449115e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2d12776bea44ff9b15fa4f13a7e1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626e458703fe4ecaac1835607da641c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3cf23ff0b44191b4a96a5552ad58af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d2925864294d01a4fa0f1f33c38a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904699dd93f54007bef6883ff6243a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e12d36b0d6a474c87301ce0072a3c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.92416303869474, 'ami': 0.9232120430081848, 'eval_loss': 0.3023603077196993}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4329a24192d04e3ba94abe7ee8c53de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.380 MB of 0.393 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966240…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▄▁▂▄▂▃▂▁█▁▃▂▃▃▁▁▃▂▁▂▃▁▁▂▂▁▂▂▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>▄▆██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.23497</td></tr><tr><td>global_step</td><td>1450</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ancient-sweep-66</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/benyx979\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/benyx979</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_152353-benyx979/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6k5qo4bt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005960128316165774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_153519-6k5qo4bt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/6k5qo4bt\" target=\"_blank\">feasible-sweep-67</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad189f03da78405da70bc39e3659c608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183dcbc4c22942bbb9b5e074a0103fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e800b65ce7834233b3dffebfe21b85ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd790667ff44bd2b61baf1b37f3fcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39062737500a4d2abb3bdfbbfe537416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f844a3c65b4c8ca51300c16c77846d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8c640a70b044e89564680dce194311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c2d1fb27fd4ef3898921a2f6bcd95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af510f05d2544ba6992f501910452561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e439a8e7feb4f24bccbf22980efba8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.137602857707702}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272e1f1a237b45f6af571636b3c7e774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.773776…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂▆▆██▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.00287</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">feasible-sweep-67</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/6k5qo4bt\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/6k5qo4bt</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_153519-6k5qo4bt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qgd957ij with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000493000755825256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_154842-qgd957ij</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/qgd957ij\" target=\"_blank\">sunny-sweep-68</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe89091983343d597fa9537d05db07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ccd36328004c4abcf7d8467b6f47cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1c91d495df4ec4bf2d4212cbe30a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76815e7175b04528add386aa7598f8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d288dcb111054340befa3c711c614e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339446f44afa47189acc611f2d12a0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21015e28ab2b4627a9b6d2386431418b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d3db471dcd476b8c98fd8bfcb54490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42207647e4ce494197989b6b6a9e8e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b0ce3a4f2343bcaa4bee9ba0554f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.08202770582546572, 'ami': 0.05379581354829665, 'eval_loss': 3.0481613108382604}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4027e61356f74e18b2af88d0854077f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.043 MB of 0.055 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.783465…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂▃▃▄▄▄▄▆▆▆▆▇▇▇▇▇▇█▇█▇█▇▇▇▇█▇█▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>2.99866</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sunny-sweep-68</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/qgd957ij\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/qgd957ij</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_154842-qgd957ij/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: puvn5a6k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007124554052727861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_160212-puvn5a6k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/puvn5a6k\" target=\"_blank\">light-sweep-69</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af37245079a4268acd231cd142a8bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce332484e1142fa8f2145bad7719ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d989a2e334e2466fb1ce83015391ad23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4bd67373fb48a6b67bc8cf6a787486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d109318fc03e4e1a8d7ad94df758e25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b4b890d72446208c4e80e4a46a3814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ab23d9b89b43059ce91f703fcc4b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c323f9a604d243fdb3b3d25c2db82018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbad2afdf3d2455d87b7e7861f288b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 7:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd62b3d590af47da92b6d8101c8d9a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933ae14eab2e416baff682e15501e1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.137891967681675}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de87396feab4218a1c97102df248910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.773825…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▂▇▆▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▆▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.06348</td></tr><tr><td>global_step</td><td>2000</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">light-sweep-69</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/puvn5a6k\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/puvn5a6k</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_160212-puvn5a6k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7g5shclb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00017867317377297446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_161741-7g5shclb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/7g5shclb\" target=\"_blank\">stoic-sweep-70</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9413eb1bbcc04fe0858aec26f2492178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38df9af520f48919e7f52d7a9c31857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec768f6e5721408d88e9fad1a21e743d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd48db8d57f4e30aed4f596e6c08c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca906ae141744fd96fd07de4a26cab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298914d9e5594291b908d9b1dd6f0de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ded5dc0e85456ba863d83766c9a230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842d5dd3a1b14a5ba97a07c48c4f9c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be5e7bfc8e349a1a26a1776424f4f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0d42173fe041a2bb169d5584c54af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235d01065eff41b9a6cafb9704e6c02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc8509746754c2282661b8e8bff1e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9593259780851968, 'ami': 0.9442424666346853, 'eval_loss': 0.212325028332648}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2487bc5e5d0a45a788866b6e781e247c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.372 MB of 0.384 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966325…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▃▃▂▃▂▃▂▃▂▂▂▁▁▂▂▂▃▂▂▃▁▃▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.00809</td></tr><tr><td>global_step</td><td>2300</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">stoic-sweep-70</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/7g5shclb\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/7g5shclb</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_161741-7g5shclb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aosm8ut1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005572685890717437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_163530-aosm8ut1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/aosm8ut1\" target=\"_blank\">dry-sweep-71</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c6bfb4279e4e6999cdb12ca06513fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c82839f32a469f974b038a50c37d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b7cae46bfd479b96f5b9acf080029a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9f730c1b254bef9ebffa2d6f9361cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95004d54b2845e6aeefa27297f5bb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522294a20bca4d0984c213f2969926e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208af2668ce845649a99984121477659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cad1695714b4b49975a6b778727cb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c211d54f01a4828959da48dcd8ddacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa196b523344d1091f18b9350d9ac4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1375288602822424}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14db1696383a4edaab87176b252b7076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.772165…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▃▂▃▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.00418</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dry-sweep-71</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/aosm8ut1\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/aosm8ut1</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_163530-aosm8ut1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b5zj1obp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006620570530346445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_164851-b5zj1obp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/b5zj1obp\" target=\"_blank\">polished-sweep-72</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f65ba312ed94e549c9a3188ea0bef7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdac4fdb73b47a1a26b15148fd4bf9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc0398f6dab4c47a2cf2693345b4c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b40b9eac614ff5a799c34c2a734c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302c01d70e0a4335bf3386cc3725bd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e9811992054169bc7e5922795a231a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7915a0061d4246f298651b4e34b07abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1393551334892353}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa21adf8e1848cc9a58a91936ae2678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.042 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁▁▂█▆▇▇▆▇▆▇▇▇▆▇▇▆</td></tr><tr><td>global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▆▆▅▅▅▄▄▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.0817</td></tr><tr><td>global_step</td><td>850</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">polished-sweep-72</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/b5zj1obp\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/b5zj1obp</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_164851-b5zj1obp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k322bkrj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006086530756624818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_165602-k322bkrj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/k322bkrj\" target=\"_blank\">silvery-sweep-73</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e1b08ffa95418aad60ca85b65f85af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17dbe865744e4a9b86814d3b7c2576ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8205ed72c9d241cc881ddb8a738e3480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0533bb8b0c9044f0bd28c4e8bb6e76d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb11a8ced8f4e21a446a50372329b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7168d550fdc42f581e1c57da332b16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5cc6a5417f4817a6e94659f9ffd331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2dc2dcfd734c89bdeb393b9136f5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359af93cbf4144749ae5d3ed89be2341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58969bef745b4e0da4ae8d228d4f7542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1372874889177145}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b4b2a0c7154477bfde2ecf9fbc2404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.771956…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▂▁▃▂▅▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.01794</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">silvery-sweep-73</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/k322bkrj\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/k322bkrj</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_165602-k322bkrj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sj7y04bf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003937051763439773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_170923-sj7y04bf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/sj7y04bf\" target=\"_blank\">honest-sweep-74</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabd305b02fd4a1bbd36836f868f2e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad869ae19d94fae80b627147b6ead78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f610b4fcd34445db10c76dedb94cb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd80d73b93cb4419bfb0a26073567c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53317cc821214219beba66ddaa63f4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6bebe12a224d9d954924c3ed123c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58d984fa9d44eff8c89db9b43abc2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057415bc7a85479e88ee28578fe1bbce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be48cc119157461a8c9cb4b4058f1b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9220612165298335, 'ami': 0.9147448078505956, 'eval_loss': 0.32281066437613515}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df31c718a3340dab92321e716ffbd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.381 MB of 0.394 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966361…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▂▅▆▄▄██▅▄▆▆█▆▇▄▂▅▁▆▅▄▃▅▄▁▅▂▃</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>▄▆██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.36383</td></tr><tr><td>global_step</td><td>1450</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">honest-sweep-74</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/sj7y04bf\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/sj7y04bf</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_170923-sj7y04bf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bwdl0ilc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002666860784228903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_172042-bwdl0ilc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/bwdl0ilc\" target=\"_blank\">exalted-sweep-75</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76d858bc1a84d5d910060f21fdb8923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd43f4a962fc4702973b23bf606c0493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9308845a799e4396ad5792f2d5862f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aaa993060d24baca6a8e62448955046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f68eddf0ab47aabbef64243f84ebbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d19ef7f5e3413a97b70910bbf8b941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f8bab59d8e4cb8a8d0a6c4e2457df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ac7e62fdc74dcbbf35e62f0c94dd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e0f24fd16a4f22831ace287d56c212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52681717e5484e489716c75845adfeba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9520028181957036, 'ami': 0.9342177453430729, 'eval_loss': 0.2212831990607723}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fdea6ab3d8417e90b798651245063c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.373 MB of 0.386 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966299…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▄▅▃▃▃▂▄▃▄▂▃▂▂▂▂▂▁▂▆▂▁▃▄▁▄▂▂▂▂▁▁▂</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.18708</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">exalted-sweep-75</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/bwdl0ilc\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/bwdl0ilc</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_172042-bwdl0ilc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uzicssoz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 9.577651273890828e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_173404-uzicssoz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/uzicssoz\" target=\"_blank\">treasured-sweep-76</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3feed08637af4ff68e0bee648981aa25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd260132a693499e8f00d3c7463b10d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4496c6269674be39e07553306b55642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8c0b021fbc4bd7821b5940fe50c671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f4ae05372f42a593f0e92ac1f99ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246a53d610d04edfb5eab76a57772f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef329aba75bb423b8c388bd2a43e96d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88c48f5c955478cbd420f1ebdb33ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9505260f1849bd924586d38022ea60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9634395649428668, 'ami': 0.949053997732589, 'eval_loss': 0.1826502616001978}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a22bf26a4bb49c79d54e73357d91080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.371 MB of 0.384 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966547…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▃▂▂▂▂▂▂▁▃▂▂▁▁▁▂▁▁▁▂▁▁▂▂▁▂▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>▄▆██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.06265</td></tr><tr><td>global_step</td><td>1450</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">treasured-sweep-76</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/uzicssoz\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/uzicssoz</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_173404-uzicssoz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: enl5mtso with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00031375545686235923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_174522-enl5mtso</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/enl5mtso\" target=\"_blank\">kind-sweep-77</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27209ac7f6942ec93ccf37b4b51f6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2a4f2fc83d43edb8d28adb9452ce25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535bfcd7aecb44a7ad5ca078194822b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924ff42a4c244004bc10b4e83bb62f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd547c7970a459b882cbc66e95c700b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3949269c90484a84bc672a829451b3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4536216affb8416f9b88e613f32b1483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d66aae407f46ae997bb384f92a6557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c32f0328f06482190f7c0eff700c5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6a6753b8ab454d9130dbd043a883b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9497097991805807, 'ami': 0.9314266676792398, 'eval_loss': 0.2406806273968359}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bcea0a36f94d27b1403a5b59a6b06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.376 MB of 0.389 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966260…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▄▄▃▅▄▅▃▄▇▃▄▂▂▂▄▄▄▄▇▃▂▃▄▁▄▂▃▂▃▃▁▃</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>▃▆███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.2761</td></tr><tr><td>global_step</td><td>1700</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">kind-sweep-77</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/enl5mtso\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/enl5mtso</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_174522-enl5mtso/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ft1xobgr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006220907997780212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_175846-ft1xobgr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/runs/ft1xobgr\" target=\"_blank\">eager-sweep-78</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20tuning/sweeps/mrohyjpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c670d48b69de4c5790a3ebcb9d7dcf50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c704dd27b3bc43e8a4e9564f3a75bf34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0514437869c54403b4267e9d74eda25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbba873f30d84ea7b290439c5297ca56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 8:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LczNROeZZ04"
   },
   "source": [
    "### Random Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ch0j2leGDx-I"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "sweep_config = {\n",
    "    \"name\": \"roberta-base random\",\n",
    "    \"method\": \"random\",\n",
    "    #\"metric\": {\"name\": \"adjusted_mutual_info_score\", \"goal\": \"maximize\"},\n",
    "    \n",
    "    \"parameters\": {\n",
    "        \"num_train_epochs\": {\"distribution\": \"int_uniform\", \"min\": 1, \"max\": 10},\n",
    "        \"learning_rate\": {\"distribution\": \"uniform\", \"min\": 5e-5, \"max\": 5e-4},\n",
    "        \"train_batch_size\": {\"distribution\": \"int_uniform\", \"min\": 4, \"max\": 128}\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EM9DXzlGUuwp",
    "outputId": "50ceac7e-b96e-4606-e80d-65e8a961cfb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 5ruo7rm4\n",
      "Sweep URL: https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/sweeps/5ruo7rm4\n"
     ]
    }
   ],
   "source": [
    "# Random search sweep\n",
    "import wandb\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "random_sweep_id = wandb.sweep(sweep_config, project=\"roberta-base random tuning\")\n",
    "\n",
    "random_tuning_model_args = ClassificationArgs(manual_seed=42, \n",
    "                                       reprocess_input_data=True, overwrite_output_dir=True, wandb_project=\"roberta-base random tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Xxq-a6KX_xY"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "def train():\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init()\n",
    "\n",
    "    # Create a TransformerModel\n",
    "    model = ClassificationModel(\n",
    "        \"roberta\",\n",
    "        \"roberta-base\",\n",
    "        use_cuda=True,\n",
    "        num_labels=n_labels,\n",
    "        args=random_tuning_model_args,\n",
    "        sweep_config=wandb.config,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.train_model(X_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval_model(X_val, ami=adjusted_mutual_info_score)\n",
    "\n",
    "    # Sync wandb\n",
    "    wandb.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b892601c62264e1ba1d19ef6cfddb300",
      "0429539436304082bcec8ec900802443",
      "b59ceb85667147bca4b1ad4a9028840f",
      "3e5f0598a8ea462cbc8dd36fadf49a16",
      "9dfd0adc464242f39894056cb80ae321",
      "7723904944684b08b4e822397d7e85c9",
      "54c124099cd049f5bf91c9d408e7e78f",
      "fe539cb41376430aa2324324109a7bd4",
      "7b3608215f9540d68bd4110d330fcf10",
      "4a63d392f4d846dc81b44f7fba67dab9",
      "11bfa62f0f41432281ad89c44309d50f",
      "82ac14421d0d4ae59bccf0ee938c9d36",
      "b6119e13f2b44c46a978caa27a2bca75",
      "fa9d733dbad54bdc852cd259045438d8",
      "8803003f32fc4cdcb3b344b230a09f8d",
      "8f926d4914ac414495e2716dfbac609a",
      "6db83ac68b55439e91e85d20b72b8d6b",
      "9f080b1a8e5442d59d0ca7a5013c47c1",
      "6d7638a617864cc481298b02e4deeaf0",
      "431242ef260b40cc86a52c01baafd4c2",
      "413880e4c7f24cdcbe81370a1bc587c3",
      "864dd3ae24cb497e9c5895d9741f96ac",
      "64c98978f8364d4386f2072d90ce3d78",
      "326825eee3f84e6fab4cc54c64a328e0",
      "44efe433aa494364866bd26d1cc4ef21",
      "2ca0f52354954a7cad4bafe3cdadb98f",
      "94f9e66914b44c9aa69b8eaabb47981b",
      "7c04b77159454817b0782bb15c9bdf58",
      "3aeab1cd53db47bc9915deb2d049c69a",
      "533eafb33a7145e0b6b52360ca272d03",
      "385077018087412896febe2b3e452d4f",
      "d4d85c8a28eb4363b8123c7489c79ad0",
      "21660a1458384c7f82dd773ccc97030a",
      "2e0c4a47881944d79c77270329924074",
      "ec92a1dd8cd04d41ac880630b89404c7",
      "1843c6db5936445db529f19d4a676068",
      "b81955186b2f4314943f4b9d9e2f697c",
      "ae70bb09c1c84eca928a8b6b83a04e5e",
      "3541870bb26a40cea71ff055bfd2c22f",
      "b46daecf1c7f49f1a50993fb68e30ef7",
      "c4b70a9292d844f4bee8bfbada19bbf4",
      "c0cbee120b444ae3920cec59cfef72fc",
      "429bce12341f479c8b2ba2bdc65b2d26",
      "754c495143764ae89969c68684238564",
      "59749b9f4d7e4932b7af306b5378a2d7",
      "f16b382689174958a403f5f407183282",
      "a17c852e4ad94172ac0ac6edfbe79cc6",
      "8174d974de4f416183387abd13fce9fe",
      "7358841c8a5a4898b182cc09cdac5caa",
      "a3ada3806b8d4de89ef55c26aca0ab7b",
      "b03b915089e244fca7f8a54a19e5c6d5",
      "c2ffb39cbca04b55b7a5b7cea985f190",
      "cd7468fcc9e548a78e82664e052e35e8",
      "825d6ff2bf954470bbf2efbc89b8079b",
      "3672afb0d8a9450381d6901de3d26040",
      "9828ee19508148249c6ab4a640fcf4f1",
      "b9655c4b278c472caa755413a1efb0b5",
      "9b47331dfbce4f8c846722edcc2fb9a2",
      "bc474f4112a946f38d18f4879f5540b4",
      "c5cfab3959f94bfd96d44630f95737ad",
      "2817b9c8a222459a8bd79dbca4541eb2",
      "17fbd36cc3c047eebfb7ff1c3d33e771",
      "d20bef459ce54a2093344ad865fc751a",
      "d59e348956b7452c9b02c66a271ac38b",
      "f0a40b1bcebf4fdfb024e232af166464",
      "928e530ad35a47b49329c3d97428823c",
      "a7b40073e6b848c18394928a01928eb0",
      "b86ae72ecae84548be6f343db3c38a13",
      "cd1f0017804c4869adad7ff0e6421435",
      "039b8b513ff046ff98d065adb6244530",
      "d48b1c8fc88142c6987e1ab663d2ab3e",
      "09c33833ea664170b4e993e01fe26276",
      "63e87929ab204bbab58ff8783378373a",
      "ec5fd40fb3c4447a86ad813cbeb4d274",
      "cd158be12dcf4579acae8a90452ecbc6",
      "eb13df0c71114ab38ab508df0acf7481",
      "19cfd3e897ec42edbf7b6d63a03df5d3",
      "50f1759d7f7f4639ae65f1cef4bbb8d0",
      "59dac7a7b5114b72831ccfaf5fb8b4fe",
      "99008722ad66426bb77246d45df3856d",
      "256dbf0babd7408f91fccfeb74a34526",
      "7786dc431f374073ab040995c3120471",
      "9baa158c0ad64d62aa441a8d6144b6ae",
      "a24650c11e8a4f2e8b63fd6755e8aa2a",
      "2b90df40f2794386bb5573e238434d9d",
      "e5bbcdae5bf24de28988c23decead016",
      "2eaa088e65284fa98a84fe83f387c091",
      "83bd20cd8c1a405f958b20264085651b",
      "43778e3ac68b4554bc9590c07d69886c",
      "d31d2708ee8b40d3bf30c5df62a860ba",
      "be2ed175f0c74064bea717fc3272c343",
      "1612f3c6c22245e2a3edd86c3025e95c",
      "163fa88957e84e648297ac4b8f57450c",
      "a04ee04974f5425e978cc625a6887566",
      "f5207c83a0044bdf976467244ae2a38a",
      "01dc6f55965a46c1ae216525813db4ee",
      "4e3f904c0cea4416902132cd2c53ead5",
      "d4a942ce592c426896a93a618619ef44",
      "fb2c1419de31460fa0c4a1836392c138",
      "649d6d95c72a48ff9f16dd442f0e060c",
      "0457629a730c4917b44ad78cdd4e27b0",
      "243bc3c716714a52ad068de03156a375",
      "54ca77e19de640d094f41efc198ddfbe",
      "af4f4061acdb4561ac1b5f6ea62cab06",
      "dbe85111084d4f8ba1eedac58008934d",
      "fdc208fa33fe4deaa964f2e358dad0b6",
      "766b550c120748968190adacc28528ef",
      "cc8c6976f2fd4c0389f26f8795f6de4e",
      "1b5624d5d1d14900932bba3fc413bf5d",
      "0d2d2bcfaa2c4123923d294b542bb2c1",
      "6b2f63df8bcb490792982586043efde1",
      "56246c8650554d5d8b1f6449d04c9732",
      "3240b5fdc5cc43b6b5d35a57486d7daa",
      "4ed660c1a52b46c791129d9530393508",
      "a7ec60c810d84ed2bf3e024ee5eb858a",
      "062f4e9a47614883901d2190ca259000",
      "f7334d934f90418db8cedbf1a94379e1",
      "91ceb13391e2479793237dd1cc09fce5",
      "3533e349f6944cee861aa92f465584b9",
      "0300be21052e407fa101b85f447f4534",
      "e62a1e8253134546a5b2fe5fdef13fc2",
      "b315d4e6badd47af90d5ff315cf8f934",
      "574fe7b4f5c643a49f3815f7550b7b7f",
      "75339d500d1d4ffaa39b303b668febdf",
      "df546e5703af40d8966a7af10c15a80f",
      "8c81db78db88449ba00c00f216ffe0ec",
      "40a4e1ac05854f1bb05470a179e3ad56",
      "d154fd8c0cbd4412a18fab2217f0c8d3",
      "bacf0071a1074ab08781df0fe31d69f2",
      "950b2b369d874a48a68d8f75de248ada",
      "b52b95e7daba40caa5f862410e8761b2",
      "1de9437a88c5412580b4fc01459a4b56",
      "27206aff9382467e999a9002b24508db",
      "7a88f232c24243cfb2c497b92673850f",
      "172d6a45230f4559bf7789a489eb839f",
      "3031e6b128054661999339f00ef0bc8a",
      "f33a9a3cfcee477989f8b3aea157a8c6",
      "5f1269067b354c7bb916a37dd0ddd0d2",
      "78df627bc4a342fab0c9a0f8ec33b140",
      "df9ca9dc46124a08bc4ed63589ce10d8",
      "e5daf5d8dfcb4604b10c600c3a9e4829",
      "d6c32811c2bc4e4a93eb16ca65960173",
      "aa71f50ed8c54da48266ce5fbab901a9",
      "85d471c6f1c040d38289ac2f2978b41f",
      "459b9de3ebfe48d589f9dd62b54b47ce",
      "57bb72b555c84a01b8d1f60223e738f4",
      "4cccad730db14a3db6d805316463b9e2",
      "820bb5ec14084d818f0a38bbeaec7bbb",
      "05e2503a728e4f4783431921a9e903cb",
      "438131655e38436fa2938c2812a0e228",
      "e6536eb1739a4794a2b3a976d7525f21",
      "c7f823b2e7404c408059071ebe23a358",
      "b050c7bc18d5494e9307e2507324c06b",
      "5cd0b41bfaf24622bf8be644212c8b78",
      "50440f5b2f9c45e7b8bc1f6de389d0b3",
      "1ad6bccb58854059b8a6a305316aa606",
      "9cf9aca6b8dc48d0af5936c1b8f16b0b",
      "f30274f74c244bcba4b552f679f6f577",
      "9fc2654272514984be103267fb05392c",
      "13198472e65a47fea7893e3649a37d11",
      "a6d25ac8526d4f24b150ee4d8bef857b",
      "deff2554b8174dc094566595237504b9",
      "ce08f80639c843c0ab28b9295ff89560",
      "5e86308416e84415b7f320498b74045b",
      "0e70709cf0cb4762b40d6c17b80ee0e0",
      "02b69eb7c52f440290f4c63149ad2e08",
      "d0c4a0c170674accaef4d399bfe10144",
      "7196514f9e4e4803af17713f95d2476c",
      "0ae7afca77874d5897d2832953046ff9",
      "c4e3112cdddc450cbd418dfe1aa4ee90",
      "2d20f39c0d8f446abdd1e1c4447b3500",
      "e6cf40b33a4046d3a9dca3e78a35511b",
      "404455179281471cb30e39f4385d1aa2",
      "d2d954c5fbe14af4a99beb65c1ae2878",
      "ec35674f2ea04eb19102f4635b55191f",
      "f4b1793570b04be485dd7da23c610f06",
      "d5c711afbffa448494d98eefe9bad6c2",
      "75affd0ea53f4742ab9a9c5687388e10",
      "d2552346d1b646e68fc45c4c616236b1",
      "4c95e61043ec43ba93addf08bf06ba02",
      "b7769f940fe0454e820ff097974896c9",
      "2bbaf39f4e5348998e510c024609b19b",
      "6886603812c4432d83f4d324e12c74be",
      "3b9f2cdf0fea477e9ac8e83895bbd218",
      "37111ae52e434e0aadd1356cc7f83308",
      "f7ba840bb11e436bab0ea9d888b19088",
      "ec17c425d2254b5d97d01f0281575f39",
      "7ee064c0409a47a2bf4991935bcb6162",
      "e30245e4253f44f792eefba3cf161ac0",
      "f5ab41e921a0429abc9199d0b767a28a",
      "742b22f104df459ca7848ff7145c0388",
      "fe08c84f0fd64f3f920fe1ed58645755",
      "b7da4f24270d48b296f534c497bae802",
      "c75a313fc92244a1aace9a47a3008106",
      "46acb3e4023d45b99cdfb3b481e030f8",
      "1c60bc2adb3c47f6b7b01af2b53bea2d",
      "aed6b43652d94db7af3a7c36d23097a8",
      "fd316180a7464387a927bbeab542ec5d",
      "df2d13a2135f41adadc03d6b37a20511",
      "9124493e0ce349d491028c0693fc28b4",
      "b796446d1bd64a3e8e770b98af4af5b1",
      "64095b91a1ef44d187708ec7f962a30b",
      "de650a7f8be8487cb884c06be0c8a127",
      "519cc46d52704df98d6dfd44aa10d1c5",
      "92524784556b42a8affdc1032b8c17a1",
      "673f9518ee5d476aad738a41e397bb38",
      "3c7ca934a9664210bdfe09c1522cab2e",
      "e8f3ba8b31e74fa5b828364b0b67badc",
      "dccc0bdf898a45fd9ca710a30e405896",
      "3fcf6f1cc9134c6f8930d6f49443e993",
      "dd759c59b4eb439a95dcb695aad36ce0",
      "6340f6e596084d508f74f1115e3a0f43",
      "6d3de0ec6d0349cdbc4ce4e3de2d6f54",
      "f5fa121038aa45259425103f7708cb3f",
      "c01ec4d675814775b2ddd091c62c2f5b",
      "de4ccd59d8b6438ab4e0d0c486f3e7d3",
      "069def1263304371ae7e101cdf5a8906",
      "01466f047acd4b50add9521229bf2569",
      "bf17336f643a491f81360005cda6caa1",
      "b0bdc2d975bc4968830048f772017bd3",
      "a6e9993f617a419abdf786b3bcf57ed1",
      "8be96b416f6e4152a8e7e78399efe057",
      "fac04784ea924e2b9d3f6e3f4ac02577",
      "6c8463109fef4ce59010e5f7bd6cd388",
      "b234670743da4b048f33e25609fc798a",
      "43beddd72e654cf19e73d817aa9e015e",
      "4dbaa38561a84e24bad4316c85de4dc4",
      "2e859aa260bd409fae9bb620054e9996",
      "310c5649bfa145dab7d760ac5d9d55d4",
      "5d00e1a2e8a74c51aa66dbb7a5a18228",
      "ef7a30b336fd41399bbcc9f2c5636038",
      "4f424bdefa58485e958183e8b701657b",
      "f0bae22b8184488a9954f4f052ea96c1",
      "0ee30fb99aa143148cff8f9d56656d7f",
      "268aa988df634895b59c73c1679a451b",
      "39ba136b567f4e34b644433cc084e227",
      "247b98c6a6f04322a297451ea133e560",
      "5aa38f96452f48c88cfeec9eab77f4b5",
      "b85c71f41c0a47e4899010ac133d3271",
      "d0da025d89944043a2b4f35794253aab",
      "e6f7379f55d1493aa47767f7fcaad0ff",
      "9f9ce02f2a5a4dab9e47fb48ef1ec88d",
      "571ddc2e409b438297ef9a25c43fcd72",
      "071cbd2a8c4f469c8f2c9fc91465639b",
      "848d78a9cfca4022b7467158a964d7d9",
      "11ad7573736b4b768a6a5d4c73e5ba55",
      "60ab5b0788dd472aaf6cf33d4cf875c2",
      "caa86e4928c446cba6de02a890a4eca1",
      "3b71990e2e174624a2eb71a13323403c",
      "08dfd8f790d84b72868f135192ee7b89",
      "653f2aac8d0245f09a0a215e36faeacf",
      "eed6bb99d1de45b28f13b9f9439686d3",
      "5342ec1a88fa49d688a375e71e0588cf",
      "7843f285358e431fa520b150b2501f53",
      "6049bcf1ebba483b991fa7da544b7419",
      "606d24ff8cbb472993b4ed847d885d2b",
      "3eb5cfde68d4461f874198ad59e16f21",
      "386fdf83a08a431cad8cc1a53fefa457",
      "0dbb1556190e469bb0367d2d4a466116",
      "726e0a30785c41f7b52f7bfe159db3f3",
      "3712243d35d341a688801b45f2f957ca",
      "fe4a8ddd586f459db9db72e9fe8b5ef2",
      "ad1fe0f15e8f4b278dff46fa4af2792e",
      "cf8660710fe5419ab8ca929c78c04404",
      "d31e9c7973f24756a9b42e05f086c027",
      "612b88714cfe4fbbb6b1ab86e660b6da",
      "5ac98d7bd16c439ab58b6df47597a937",
      "3d5a590e82124b29b5619c6179a25e40",
      "76ad6f75f96741ea9489f56e7ef225dd",
      "288b5c363adf430fb25d1b12e9417551",
      "b56e8616bf424ccda416975f41e34194",
      "fdbda8c14d7240348f070af9a974b532",
      "113c2bd2dcd745c6ad5b51990fba6317",
      "3729b746094f476385f50b746b292826",
      "2cad1e71c82a438aaaf8c83fae76f8b2",
      "3ac0f653d1834d33afc78cc1109a0ca4",
      "1f7a2fe54f254faaaf82e8695f651a2e",
      "471026ca7e0546939317c86566b0ab50",
      "1128b5821ade4e489e11aa361f7f0a8a",
      "1dafe72587374d2b8a4510eed6ba9564",
      "c5cbadb5d32e407e8ff7a37426e5fa05",
      "bf1ef894b9204ea6b4d04843fdff82f6",
      "126875fe9def4303951e20e4f5baf475",
      "861b5edacfa64be497cb656cce9ff148",
      "4015ba450fc14866a1a0450241557297",
      "646da2bc65e14d42a06a4e7fb4f54f8e",
      "3210f12aec3d4ee18bdcca705abd8bb1",
      "66b20bb83d2b4c26b583c7e99629da79",
      "124d9baadc524a87bfb02efde8b6931b",
      "3713b1f802904645ac2a2576a7d1a7ee",
      "d16f11b5bbbc41da8bfbca45a3dabbb0",
      "0018ee0072df4d13a5b089ff576477e4",
      "e46e0999f2f045a896f248041ffce735",
      "3887e5dd34cb455eac66ac86b17a1a21",
      "a980be4c082948a99eed920c99c83187",
      "0f606344e2f5438287d11b0e623f32ec",
      "f14dd929a0d24e898b3096904a280850",
      "d81a51790b4741878253d988182c2875",
      "caed4d139f9444c1aa839d384eae8234",
      "58a5f4eecabe478093cbfbbc1a1d676b",
      "0be320629ea8450bb0ba2d869f744856",
      "c6203c26ff33479890fe779c519b094a",
      "40e550fc319a4745a66e58e0079efd34",
      "43bfd167da79498a8065790563036ff0",
      "102b28a5384b42b3ae649111bf21ce83",
      "0eb69469f55b4d9f9a07d7acf6f40321",
      "9ecd887129af4f8e94b47984d5eb5748",
      "3c309d71d51848efb9b86aceccbd7a61",
      "4e738d1bc5ae4ab988ba24960d23f8c6",
      "c68b61af544c4c2f8b87220c88bd12cf",
      "eff883670c184031aa00f53fbb57bfca",
      "4db7ff5976c947bd9cc4b827705ffe6f",
      "138150e50747483cb69ec0696166012d",
      "323acfd06a2a4c3eb7a38174767db175",
      "72677abea93d44eb976f140858cfce8f",
      "03866c8432fb4e66a3ff12e403259c0a",
      "7629255a472243ee85380df2d380d0db",
      "b22c33a2810b41f88f3a3c27271de1d9",
      "9bda6681b1ac43cb8b639a5635c07783",
      "9fe6305390f64eaeb7c03787c7754e49",
      "ae980e115c2645d4aad88f57647cc3a9",
      "bd9954dfe76c476e8a912b5aa9e2d90b",
      "26be7e51abea4ef9a06ab155b85d0e5f",
      "95cfe101e5fc415cba2e98ff5d1e9f53",
      "d43e70b4535a4eed8fcffcbb9499d2dc",
      "1655540909c4455c94e663a170ade328",
      "ec76953093c4402a84066b2b47865430",
      "97ea35d3c475461c86e0d34fb4be1520",
      "8b6fc2502c134fb8a050e8f613577f8b",
      "3b666446b077403a978ac9fc33f2b50c",
      "1235628f073140cea4db40138d2ba226",
      "6aff909ad8914772a8e6271419b208ad",
      "45c6a8badec041ecab8aeee53e3f5513",
      "8e5d802a347b48fcbb179455c8aa9bf9",
      "a4cc7c663edf474cbc38f78eda98554b",
      "ddf073e50cf14324b5e87d3e9e813053",
      "dd5086372f5347ca83f02fc605796f04",
      "419a6f25425c4fc6a9faf6edaf832a98",
      "e4664010fb314a7bb694afb4257984d0",
      "9b1c2a48f3d64d42b7f731dba5f502a2",
      "2224757892eb4116a29b2e1c1d7b6d92",
      "77db7a6264124d20b2e825b8dc1b719d",
      "eee7928a750e41b48dfc25ba03d8efaa",
      "0b0af0bd2b6f4d0e9cf21a5d93358821",
      "bb34f509d1634345b5db3cc278aa7dc8",
      "467cad5545aa4a11a91527c3972a195b",
      "22fc6699e79b4c978e17b6569033c388",
      "b520b2277d6f4dba949348243c406669",
      "bfe01f56118140e0ae5a558215161fce",
      "fef8a04e0eb948a98841ae4a707e6505",
      "11261440cda74309ae1f9f1acfc89d07",
      "7b69ae7e7d364926bffc744c409f45ca",
      "bd025faa61e8454e89999cf757bbde69",
      "beed698116d74abe97ca253ddde23ce0",
      "0fe9432a13f94f64be56a8ea433dc748",
      "d9080062ebcb4d878ba7e737099bdca6",
      "441af958424d435cb8d695d6e1d6f1c2",
      "63b8a063cc5a4b0cb90d328d67ebc626",
      "772494d54d6344489f82886079422162",
      "834310019ae840deba25b905be7788ab",
      "6381b9591ca645bd839e8c1f6fc1c7d9",
      "e243443cd838498b9a51357d70eaced5",
      "e8ed4bc5b5e849b1be8bad2ea07a403c",
      "dce30229577544ac9755984dddcb9d94",
      "581f9322dc40404c8561703dd4fc0a5c",
      "2d1a8e90dcc046ec95da058dccb4b92a",
      "2d6eb49ff8444e0ba86f9783c46b0ac1",
      "8873cbb46430435b8cbd3d53da4ba05a",
      "ed71f188e67b4319b904d7f778615e95",
      "dc904533875f498dba55e59a4584d065",
      "fbb8fb85522d4704840294a18fbbb66a",
      "c2bd040cfee44c82ac4d48f7080e0bf0",
      "077f1cd170944e76923d64aa3344eaab",
      "49a8cd3d36064b1284e9e49a1f6e2e8c",
      "7170fb7552fe42d49be86af312ed822c",
      "aba81630e9bd4fc99876cfd6137cd075",
      "1b2100a140fa4d0d90c8868158cf8c58",
      "fb320eff45104fdf9e1085aa83c266df",
      "5c89ab7b247e4c9fa69f066b16284137",
      "2f5227ce24414c1595033cfedfc71c68",
      "e7b2e309688d4ef9ae8fc70fb16501ab",
      "c1e5151e2f11460a8fe55cf18602f5e6",
      "51a69556678548f494b5ffb4684e7b54",
      "b0045e3014f54e01bd78433bd4dcf1f3",
      "05f7d7175c614ba492c7fa69f0babd33",
      "9767df8b4412494598572d246d5f9ed8",
      "5afbd899ce8a439f94ccdd47240c60ba",
      "ed5f36d833ca42fd9a8c8f5b30511052",
      "e6c937ffa59e4c1fac8f42ddefbc11f1",
      "a99614fe87424ac29c0c58b81ba4c98f",
      "0080b1f938664418b9b60d4f88028a87",
      "071e10c8482549e3a6bf78d98543c9ce",
      "f29d97b0d495464e894e78fc5f35e921",
      "5ef51078a27e4cbc9c454b648caec5df",
      "b591d31f6b7341fab4e441578af71689",
      "edb1ac2300a44329bee01c53fc63d1a9",
      "8c55d38faa764f1784aff5d3d1eca01b",
      "3670e2b4d36944be85fb651df5019eab",
      "bf0955995bf24bd3b488a64f8d7e84d8",
      "9982883c8af3418a8de6f79a2abde433",
      "dbbfec06685a42e1872c97f09eb6caa8",
      "26cf00e5a7c143c8b9f8ba1250a97b54",
      "2282954bc55b4c42b208fb059dc2793f",
      "5d4010f5186e4ab3846c32238a8f2038",
      "02565ee6e15f429e901f2795ddd8f925",
      "1b36084df36c4e58979c68dca07fc1ab"
     ]
    },
    "id": "bIgc5wS_XmNN",
    "outputId": "d44ef7bc-f3be-490f-9337-f7069e62b1b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:wandb.agents.pyagent:Starting sweep agent: entity=None, project=None, count=15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0ngqwz9r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00019781020001691433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkqmdjoh\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_192057-0ngqwz9r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/runs/0ngqwz9r\" target=\"_blank\">polar-sweep-1</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/sweeps/5ruo7rm4\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/sweeps/5ruo7rm4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b892601c62264e1ba1d19ef6cfddb300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ac14421d0d4ae59bccf0ee938c9d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c98978f8364d4386f2072d90ce3d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 9:   0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0c4a47881944d79c77270329924074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 9:   0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59749b9f4d7e4932b7af306b5378a2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 9:   0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9828ee19508148249c6ab4a640fcf4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 9:   0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b40073e6b848c18394928a01928eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 9:   0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f1759d7f7f4639ae65f1cef4bbb8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 9:   0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43778e3ac68b4554bc9590c07d69886c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 9:   0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649d6d95c72a48ff9f16dd442f0e060c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 9:   0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2f63df8bcb490792982586043efde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 8 of 9:   0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b315d4e6badd47af90d5ff315cf8f934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27206aff9382467e999a9002b24508db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb.plots.* functions are deprecated and will be removed in a future release. Please use wandb.plot.* instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9606883628338033, 'ami': 0.9448997307579698, 'eval_loss': 0.19714433192899547}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d471c6f1c040d38289ac2f2978b41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.374 MB of 0.387 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.966496…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▆▃▃▄▄▂▃▂▃▂▂▃▁▃▁▁▁▁▁▂▁▂▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>lr</td><td>▆██▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.01111</td></tr><tr><td>global_step</td><td>1200</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">polar-sweep-1</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/runs/0ngqwz9r\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/runs/0ngqwz9r</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_192057-0ngqwz9r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xqtwzm04 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000641393208117172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_193850-xqtwzm04</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/runs/xqtwzm04\" target=\"_blank\">brisk-sweep-2</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/sweeps/5ruo7rm4\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/sweeps/5ruo7rm4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f823b2e7404c408059071ebe23a358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce08f80639c843c0ab28b9295ff89560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d954c5fbe14af4a99beb65c1ae2878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 6:   0%|          | 0/1329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37111ae52e434e0aadd1356cc7f83308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 6:   0%|          | 0/1329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c60bc2adb3c47f6b7b01af2b53bea2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 6:   0%|          | 0/1329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7ca934a9664210bdfe09c1522cab2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 6:   0%|          | 0/1329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01466f047acd4b50add9521229bf2569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 6:   0%|          | 0/1329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310c5649bfa145dab7d760ac5d9d55d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 6:   0%|          | 0/1329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0da025d89944043a2b4f35794253aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653f2aac8d0245f09a0a215e36faeacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'ami': 4.888130006349623e-17, 'eval_loss': 3.1376760161619415}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4a8ddd586f459db9db72e9fe8b5ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.772229…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▅▆▇▅▇▆▇▄▆▇▆▅▅▅█▁▅▃▇▆▅▆▂▂▆▆▆▅▅▆▅▃▇▄▆▆▇▅▅█</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>3.27818</td></tr><tr><td>global_step</td><td>7950</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">brisk-sweep-2</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/runs/xqtwzm04\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/runs/xqtwzm04</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_193850-xqtwzm04/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wxyfup05 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000804301783144908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_195744-wxyfup05</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/runs/wxyfup05\" target=\"_blank\">resilient-sweep-3</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/sweeps/5ruo7rm4\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/sweeps/5ruo7rm4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288b5c363adf430fb25d1b12e9417551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cbadb5d32e407e8ff7a37426e5fa05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0018ee0072df4d13a5b089ff576477e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e550fc319a4745a66e58e0079efd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323acfd06a2a4c3eb7a38174767db175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43e70b4535a4eed8fcffcbb9499d2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8576770346689931, 'ami': 0.8671167288709922, 'eval_loss': 0.5257061573443135}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf073e50cf14324b5e87d3e9e813053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.383 MB of 0.383 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▅▄▄▂▁▁</td></tr><tr><td>global_step</td><td>▁▂▃▅▆▇█</td></tr><tr><td>lr</td><td>▆█▇▅▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.54381</td></tr><tr><td>global_step</td><td>350</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">resilient-sweep-3</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/runs/wxyfup05\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/runs/wxyfup05</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_195744-wxyfup05/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wv5jxikh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.29721295758908e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 97\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220415_200231-wv5jxikh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/runs/wv5jxikh\" target=\"_blank\">cosmic-sweep-4</a></strong> to <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/sweeps/5ruo7rm4\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/sweeps/5ruo7rm4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0af0bd2b6f4d0e9cf21a5d93358821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe9432a13f94f64be56a8ea433dc748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1a8e90dcc046ec95da058dccb4b92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2100a140fa4d0d90c8868158cf8c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_37_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5f36d833ca42fd9a8c8f5b30511052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.934213727992426, 'ami': 0.9251004381152229, 'eval_loss': 0.33129377596566767}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0955995bf24bd3b488a64f8d7e84d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.371 MB of 0.371 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>▁</td></tr><tr><td>global_step</td><td>▁</td></tr><tr><td>lr</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>1.23687</td></tr><tr><td>global_step</td><td>50</td></tr><tr><td>lr</td><td>5e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cosmic-sweep-4</strong>: <a href=\"https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/runs/wv5jxikh\" target=\"_blank\">https://wandb.ai/kqmdjoh/roberta-base%20no-batch%20random%20tuning/runs/wv5jxikh</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220415_200231-wv5jxikh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tygi5tkn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004979562748154357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 85\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(random_sweep_id, train, count=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_aHQllU39tG"
   },
   "source": [
    "# Make Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "1ff8f633151f485182d1aa853bfa0df4",
      "2fa26af94f354545be5d0adf5d931bc1",
      "59bf718314ca4a39ae04d28e9fe3add8",
      "d474c93e3fc64025813261ddae221655",
      "e2778e0836d34283ba0c60bc5d1a9a8f",
      "e78f1ae8db164b439c8ff7b0029e2c8a",
      "0985bb7119d74409a6369dcbd19d2966",
      "a083a712e90e4cedbdc3c792708cdb47",
      "97c6ebe466ff4c62a8361a8d4f03e341",
      "7235bca8041f473b8a48d277550070d4",
      "a92ba1abd9a4459b95fb744657aeb060",
      "15abaee4719d4971b37e276e19d5f4ec",
      "f034d778223b444393f3c16cdea89ea4",
      "d037576af91347f080227b95aaa8dbab",
      "62c76a0bf16c479d915c243cfa1743ea",
      "2061e87facf540979a30484c926b3c32",
      "b9a23c6ad8c6496bbaa3a2a36f44c132",
      "cf271e69736f49e0bce265d6a0cd9281",
      "34751c460c7d469aa729a0449490d040",
      "9337289a1bad414d8da7548005997a22",
      "1ff3927edcca4cf1ab47c029bf5a7c7b",
      "b5c7a4d01009470ebc610cb2c7ffe5a2"
     ]
    },
    "id": "ZbfcGvOymagj",
    "outputId": "3f85fc80-0a72-41d3-8b55-f9ad6c351a52"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff8f633151f485182d1aa853bfa0df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2906 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15abaee4719d4971b37e276e19d5f4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = df_test['message'].rename('text')\n",
    "predictions, raw_outputs = model.predict(X_test.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UJS4EiLnaUp"
   },
   "outputs": [],
   "source": [
    "transformed_predictions = labelEncoder.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBREJD6KrTaO"
   },
   "source": [
    "## Write predictions to zip for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WtmgdLCrSOQ",
    "outputId": "5f1d2b8a-4921-43c1-86f1-c8cf09193841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id                 label\n",
      "0  12123  reportbrokensoftware\n",
      "1    244      orderpizzaintent\n",
      "2   8221           replacecard\n",
      "3  12856    startserviceintent\n",
      "4  12108         expensereport\n"
     ]
    }
   ],
   "source": [
    "my_submission = pd.DataFrame({'Id': df_test['id'], 'label': transformed_predictions})\n",
    "print(my_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IFCywfEsDuH"
   },
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip', archive_name='coda_submission.csv')\n",
    "my_submission.to_csv('robertabase_grammarfixed_submission.zip', index=False, compression=compression_opts)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6KIFr_uwrM3I",
    "G_Q3r-RYZUd5",
    "4LczNROeZZ04"
   ],
   "name": "EarlyStopping_Roberta_SimpleTransformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
