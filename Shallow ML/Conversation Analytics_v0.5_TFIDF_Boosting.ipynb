{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c23786",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a6490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251fc733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11623 entries, 0 to 11622\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       11623 non-null  int64 \n",
      " 1   message  11623 non-null  object\n",
      " 2   label    11623 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 272.5+ KB\n",
      "None\n",
      "      id                                            message  \\\n",
      "0   8793    hi i want change my address from my credit card   \n",
      "1   3083  i need 4 fruit maple oatmeal 3 cold brew froze...   \n",
      "2   5932        i wish to travel next month domestic airway   \n",
      "3  12077                   i need reimbursement my expenses   \n",
      "4   6608              i need a copy of insurance for my car   \n",
      "\n",
      "                 label  \n",
      "0        updateaddress  \n",
      "1     orderdrinkintent  \n",
      "2           bookflight  \n",
      "3        expensereport  \n",
      "4  getproofofinsurance  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"public_data.csv\")\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd35e9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9298,)\n",
      "(9298,)\n",
      "(2325,)\n",
      "(2325,)\n"
     ]
    }
   ],
   "source": [
    "X = df['message']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc743357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4887a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "def remove_unwanted_chars(df):\n",
    "    return df.apply(lambda x: unidecode.unidecode(x))\n",
    "\n",
    "def remove_numbers(df):\n",
    "    return df.apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "def tokenize_message(df):\n",
    "    return df.apply(lambda x: word_tokenize(x))\n",
    "\n",
    "def remove_stopwords(df):\n",
    "    return df.apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "\n",
    "def lemmatize_message(df):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return df.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bbc344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make FunctionTransformers for custom preprocessing functions\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "preprocess_pipe = Pipeline([('removeunwanted', FunctionTransformer(remove_unwanted_chars)),\n",
    "                            ('removenumbers', FunctionTransformer(remove_numbers)),\n",
    "                            ('tokenize', FunctionTransformer(tokenize_message)),\n",
    "                            ('removestopwords', FunctionTransformer(remove_stopwords)),\n",
    "                            ('lemmatize', FunctionTransformer(lemmatize_message))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e707ba0",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba6cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'iterations': 3000,\n",
    "    'learning_rate': 0.01,\n",
    "    'verbose': 500,\n",
    "    'random_state': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ff60167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.5065087\ttotal: 428ms\tremaining: 21m 24s\n",
      "500:\tlearn: 0.9104903\ttotal: 1m 51s\tremaining: 9m 16s\n",
      "1000:\tlearn: 0.6580553\ttotal: 3m 42s\tremaining: 7m 25s\n",
      "1500:\tlearn: 0.5620362\ttotal: 5m 27s\tremaining: 5m 27s\n",
      "2000:\tlearn: 0.5191066\ttotal: 7m 12s\tremaining: 3m 35s\n",
      "2500:\tlearn: 0.4936887\ttotal: 8m 59s\tremaining: 1m 47s\n",
      "2999:\tlearn: 0.4758789\ttotal: 10m 42s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 Pipeline(steps=[('removeunwanted',\n",
       "                                  FunctionTransformer(func=<function remove_unwanted_chars at 0x0000027046CABD30>)),\n",
       "                                 ('removenumbers',\n",
       "                                  FunctionTransformer(func=<function remove_numbers at 0x0000027046CABCA0>)),\n",
       "                                 ('tokenize',\n",
       "                                  FunctionTransformer(func=<function tokenize_message at 0x0000027046CABEE0>)),\n",
       "                                 ('removestopwords',\n",
       "                                  FunctionTransformer(func=<function remove_stopwords at 0x0000027046CABF70>)),\n",
       "                                 ('lemmatize',\n",
       "                                  FunctionTransformer(func=<function lemmatize_message at 0x0000027046CBD040>))])),\n",
       "                ('vec',\n",
       "                 TfidfVectorizer(max_df=0.8, max_features=300, min_df=0.01,\n",
       "                                 ngram_range=[1, 1], stop_words='english')),\n",
       "                ('clf',\n",
       "                 <catboost.core.CatBoostClassifier object at 0x0000027041784490>)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=.01, max_df=.8, ngram_range=[1,1], max_features=300, stop_words='english')\n",
    "\n",
    "pipe = Pipeline([('preprocess', preprocess_pipe),\n",
    "                 ('vec', vectorizer),\n",
    "                 ('clf', CatBoostClassifier(**catboost_params))])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d7e21f",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fae70da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 41   0   0 ...   0   0   0]\n",
      " [  0   1   0 ...   0   0   0]\n",
      " [  0   0 182 ...   0   0   1]\n",
      " ...\n",
      " [  0   0   0 ...  69   0   0]\n",
      " [  0   0   1 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   7]]\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "           bookflight       0.95      0.98      0.96        42\n",
      "          changeorder       0.50      0.20      0.29         5\n",
      " changeseatassignment       0.88      0.95      0.91       192\n",
      "         checkbalance       0.98      0.98      0.98        50\n",
      "     checkclaimstatus       1.00      0.96      0.98        90\n",
      "checkoffereligibility       0.55      1.00      0.71         6\n",
      "    checkserverstatus       0.90      0.90      0.90        30\n",
      "         closeaccount       0.93      0.70      0.80        20\n",
      "        disputecharge       0.95      0.43      0.59        42\n",
      "        expensereport       0.97      0.96      0.97        77\n",
      "      getboardingpass       1.00      0.99      1.00       114\n",
      " getinformationintent       0.78      0.78      0.78        32\n",
      "        getpromotions       0.00      0.00      0.00         3\n",
      "  getproofofinsurance       0.99      0.99      0.99       192\n",
      "     getroutingnumber       0.93      0.93      0.93        14\n",
      "          getseatinfo       0.78      0.52      0.62        48\n",
      " orderbreakfastintent       0.00      0.00      0.00         7\n",
      "    orderburgerintent       0.81      0.59      0.69        59\n",
      "          orderchecks       1.00      0.75      0.86         8\n",
      "   orderdessertintent       0.81      0.28      0.42        60\n",
      "     orderdrinkintent       0.49      0.92      0.64       151\n",
      "     orderpizzaintent       0.95      0.88      0.91       203\n",
      "     ordersaladintent       0.85      0.90      0.88        52\n",
      "      ordersideintent       0.00      0.00      0.00        23\n",
      "       providereceipt       0.00      0.00      0.00         1\n",
      "          replacecard       1.00      0.60      0.75        15\n",
      "    reportbrokenphone       1.00      0.91      0.95        69\n",
      " reportbrokensoftware       0.95      0.90      0.93        69\n",
      "       reportlostcard       0.77      1.00      0.87        73\n",
      "       softwareupdate       0.96      0.95      0.95        55\n",
      "           startorder       0.73      0.80      0.76        56\n",
      "   startserviceintent       0.98      0.99      0.98       330\n",
      "            stoporder       0.00      0.00      0.00         3\n",
      "        transfermoney       0.95      0.95      0.95        43\n",
      "        updateaddress       0.99      1.00      0.99        69\n",
      " upgradeserviceintent       0.00      0.00      0.00         5\n",
      "      viewbillsintent       0.64      0.41      0.50        17\n",
      "\n",
      "             accuracy                           0.88      2325\n",
      "            macro avg       0.73      0.68      0.69      2325\n",
      "         weighted avg       0.88      0.88      0.87      2325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "pred_val = pipe.predict(X_val)\n",
    "pred_val = pred_val.reshape(-1)\n",
    "print(confusion_matrix(y_val, pred_val))\n",
    "print(classification_report(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf6363",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c8bdb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.5077941\ttotal: 187ms\tremaining: 9m 20s\n",
      "500:\tlearn: 0.9316720\ttotal: 1m 28s\tremaining: 7m 19s\n",
      "1000:\tlearn: 0.6751859\ttotal: 2m 54s\tremaining: 5m 47s\n",
      "1500:\tlearn: 0.5736263\ttotal: 4m 20s\tremaining: 4m 19s\n",
      "2000:\tlearn: 0.5272155\ttotal: 5m 50s\tremaining: 2m 54s\n",
      "2500:\tlearn: 0.4999535\ttotal: 7m 20s\tremaining: 1m 27s\n",
      "2999:\tlearn: 0.4817012\ttotal: 8m 49s\tremaining: 0us\n",
      "0:\tlearn: 3.5118956\ttotal: 182ms\tremaining: 9m 6s\n",
      "500:\tlearn: 0.9303100\ttotal: 1m 29s\tremaining: 7m 25s\n",
      "1000:\tlearn: 0.6732082\ttotal: 2m 58s\tremaining: 5m 56s\n",
      "1500:\tlearn: 0.5721931\ttotal: 4m 31s\tremaining: 4m 30s\n",
      "2000:\tlearn: 0.5286861\ttotal: 6m 8s\tremaining: 3m 4s\n",
      "2500:\tlearn: 0.5031695\ttotal: 7m 41s\tremaining: 1m 32s\n",
      "2999:\tlearn: 0.4840802\ttotal: 9m 22s\tremaining: 0us\n",
      "0:\tlearn: 3.5094488\ttotal: 193ms\tremaining: 9m 40s\n",
      "500:\tlearn: 0.9325688\ttotal: 1m 28s\tremaining: 7m 21s\n",
      "1000:\tlearn: 0.6768367\ttotal: 3m 2s\tremaining: 6m 4s\n",
      "1500:\tlearn: 0.5762421\ttotal: 4m 43s\tremaining: 4m 42s\n",
      "2000:\tlearn: 0.5300739\ttotal: 6m 35s\tremaining: 3m 17s\n",
      "2500:\tlearn: 0.5039376\ttotal: 8m 11s\tremaining: 1m 38s\n",
      "2999:\tlearn: 0.4846195\ttotal: 9m 44s\tremaining: 0us\n",
      "0:\tlearn: 3.5078738\ttotal: 170ms\tremaining: 8m 28s\n",
      "500:\tlearn: 0.9400342\ttotal: 1m 29s\tremaining: 7m 26s\n",
      "1000:\tlearn: 0.6831541\ttotal: 2m 57s\tremaining: 5m 54s\n",
      "1500:\tlearn: 0.5849139\ttotal: 4m 27s\tremaining: 4m 26s\n",
      "2000:\tlearn: 0.5385813\ttotal: 6m 2s\tremaining: 3m 1s\n",
      "2500:\tlearn: 0.5124851\ttotal: 7m 31s\tremaining: 1m 30s\n",
      "2999:\tlearn: 0.4939273\ttotal: 8m 56s\tremaining: 0us\n",
      "0:\tlearn: 3.5215768\ttotal: 198ms\tremaining: 9m 53s\n",
      "500:\tlearn: 0.9254821\ttotal: 1m 29s\tremaining: 7m 24s\n",
      "1000:\tlearn: 0.6717767\ttotal: 2m 57s\tremaining: 5m 55s\n",
      "1500:\tlearn: 0.5720856\ttotal: 4m 26s\tremaining: 4m 26s\n",
      "2000:\tlearn: 0.5269334\ttotal: 5m 55s\tremaining: 2m 57s\n",
      "2500:\tlearn: 0.5000751\ttotal: 7m 24s\tremaining: 1m 28s\n",
      "2999:\tlearn: 0.4801528\ttotal: 8m 58s\tremaining: 0us\n",
      "Scores: [nan, nan, nan, nan, nan]\n",
      "Mean score: nan\n",
      "+/-2 std. dev. range within mean: (nan, nan)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "ami_scores = cross_val_score(pipe, X_train, y_train, scoring='adjusted_mutual_info_score', cv=5)\n",
    "\n",
    "# Calculate mean and standard deviation of scores\n",
    "avg_ami = ami_scores.mean()\n",
    "stddev_ami = ami_scores.std()\n",
    "\n",
    "# Print results\n",
    "print(\"Scores:\", [round(score, 4) for score in ami_scores])\n",
    "print(f\"Mean score: {round(avg_ami, 4)}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg_ami - 2*stddev_ami:.4f}, {avg_ami + 2*stddev_ami:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b300323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI: 0.8204243276265076\n",
      "AMI: 0.8583743543840325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "ari = adjusted_rand_score(y_val, pred_val)\n",
    "ami = adjusted_mutual_info_score(y_val, pred_val, average_method='arithmetic')\n",
    "\n",
    "print(\"ARI: {}\".format(ari))\n",
    "print(\"AMI: {}\".format(ami))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f83469a",
   "metadata": {},
   "source": [
    "## Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b40e14d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2906 entries, 0 to 2905\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       2906 non-null   int64 \n",
      " 1   message  2906 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 45.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12123</td>\n",
       "      <td>i have problem in excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244</td>\n",
       "      <td>i need \\t pesto drizzle over grilled chicken c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8221</td>\n",
       "      <td>need to help order a new card as the old one e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12856</td>\n",
       "      <td>i need internet plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12108</td>\n",
       "      <td>my are report travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            message\n",
       "0  12123                            i have problem in excel\n",
       "1    244  i need \\t pesto drizzle over grilled chicken c...\n",
       "2   8221  need to help order a new card as the old one e...\n",
       "3  12856                               i need internet plan\n",
       "4  12108                               my are report travel"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('input_data.csv')\n",
    "df_test.info()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65eb1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = pipe.predict(df_test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "def846b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = pred_test.reshape(-1) # reshape to 1D for predictions with Catboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "743204a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id               label\n",
      "0  12123    orderdrinkintent\n",
      "1    244   orderburgerintent\n",
      "2   8221         replacecard\n",
      "3  12856  startserviceintent\n",
      "4  12108       expensereport\n"
     ]
    }
   ],
   "source": [
    "my_submission = pd.DataFrame({'Id': df_test['id'], 'label': pred_test})\n",
    "print(my_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76233f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip', archive_name='coda_submission.csv')\n",
    "my_submission.to_csv('coda_submission.zip', index=False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51439316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
